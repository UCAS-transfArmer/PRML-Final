Epoch [0], last_lr: 0.00473, train_loss: 2.4192, val_loss: 6.3123, val_acc: 0.1657
Epoch [1], last_lr: 0.00544, train_loss: 1.9201, val_loss: 1.7589, val_acc: 0.3237
Epoch [2], last_lr: 0.00660, train_loss: 1.6306, val_loss: 1.5229, val_acc: 0.4261
Epoch [3], last_lr: 0.00820, train_loss: 1.4572, val_loss: 1.4536, val_acc: 0.4653
Epoch [4], last_lr: 0.01024, train_loss: 1.2987, val_loss: 1.1609, val_acc: 0.5729
Epoch [5], last_lr: 0.01268, train_loss: 1.1357, val_loss: 1.1672, val_acc: 0.5883
Epoch [6], last_lr: 0.01549, train_loss: 0.9988, val_loss: 1.0971, val_acc: 0.6206
Epoch [7], last_lr: 0.01866, train_loss: 0.8765, val_loss: 0.9681, val_acc: 0.6535
Epoch [8], last_lr: 0.02214, train_loss: 0.7655, val_loss: 1.0243, val_acc: 0.6585
Epoch [9], last_lr: 0.02590, train_loss: 0.6824, val_loss: 0.8018, val_acc: 0.7408
Epoch [10], last_lr: 0.02989, train_loss: 0.5930, val_loss: 0.6887, val_acc: 0.7706
Epoch [11], last_lr: 0.03407, train_loss: 0.5237, val_loss: 0.6435, val_acc: 0.7806
Epoch [12], last_lr: 0.03840, train_loss: 0.4747, val_loss: 0.5634, val_acc: 0.8158
Epoch [13], last_lr: 0.04282, train_loss: 0.4324, val_loss: 0.7221, val_acc: 0.7858
Epoch [14], last_lr: 0.04730, train_loss: 0.4081, val_loss: 0.6390, val_acc: 0.8008
Epoch [15], last_lr: 0.05177, train_loss: 0.3713, val_loss: 0.7734, val_acc: 0.7839
Epoch [16], last_lr: 0.05619, train_loss: 0.3516, val_loss: 1.1126, val_acc: 0.7158
Epoch [17], last_lr: 0.06051, train_loss: 0.3284, val_loss: 0.8152, val_acc: 0.7795
Epoch [18], last_lr: 0.06469, train_loss: 0.3069, val_loss: 0.6001, val_acc: 0.8151
Epoch [19], last_lr: 0.06868, train_loss: 0.2897, val_loss: 0.5150, val_acc: 0.8384
Epoch [20], last_lr: 0.07243, train_loss: 0.2684, val_loss: 0.6909, val_acc: 0.7972
Epoch [21], last_lr: 0.07591, train_loss: 0.2651, val_loss: 0.7480, val_acc: 0.7819
Epoch [22], last_lr: 0.07907, train_loss: 0.2423, val_loss: 0.5901, val_acc: 0.8358
Epoch [23], last_lr: 0.08188, train_loss: 0.2331, val_loss: 0.4166, val_acc: 0.8726
Epoch [24], last_lr: 0.08431, train_loss: 0.2236, val_loss: 0.6025, val_acc: 0.8251
Epoch [25], last_lr: 0.08634, train_loss: 0.2138, val_loss: 0.4074, val_acc: 0.8735
Epoch [26], last_lr: 0.08793, train_loss: 0.1978, val_loss: 0.5105, val_acc: 0.8450
Epoch [27], last_lr: 0.08908, train_loss: 0.1805, val_loss: 0.4591, val_acc: 0.8665
Epoch [28], last_lr: 0.08977, train_loss: 0.1744, val_loss: 0.4304, val_acc: 0.8789
Epoch [29], last_lr: 0.09000, train_loss: 0.1649, val_loss: 0.7149, val_acc: 0.8146
Epoch [30], last_lr: 0.08995, train_loss: 0.1618, val_loss: 0.4038, val_acc: 0.8828
Epoch [31], last_lr: 0.08982, train_loss: 0.1530, val_loss: 0.5047, val_acc: 0.8583
Epoch [32], last_lr: 0.08959, train_loss: 0.1386, val_loss: 0.4485, val_acc: 0.8757
Epoch [33], last_lr: 0.08927, train_loss: 0.1338, val_loss: 0.4816, val_acc: 0.8722
Epoch [34], last_lr: 0.08886, train_loss: 0.1211, val_loss: 0.4163, val_acc: 0.8877
Epoch [35], last_lr: 0.08837, train_loss: 0.1152, val_loss: 0.3974, val_acc: 0.8924
Epoch [36], last_lr: 0.08778, train_loss: 0.1125, val_loss: 0.4634, val_acc: 0.8790
Epoch [37], last_lr: 0.08712, train_loss: 0.1086, val_loss: 0.3528, val_acc: 0.9021
Epoch [38], last_lr: 0.08636, train_loss: 0.0981, val_loss: 0.3997, val_acc: 0.8897
Epoch [39], last_lr: 0.08553, train_loss: 0.0960, val_loss: 0.3676, val_acc: 0.9082
Epoch [40], last_lr: 0.08461, train_loss: 0.0952, val_loss: 0.4752, val_acc: 0.8830
Epoch [41], last_lr: 0.08361, train_loss: 0.0854, val_loss: 0.4823, val_acc: 0.8883
Epoch [42], last_lr: 0.08253, train_loss: 0.0904, val_loss: 0.3747, val_acc: 0.9075
Epoch [43], last_lr: 0.08138, train_loss: 0.0887, val_loss: 0.4267, val_acc: 0.8977
Epoch [44], last_lr: 0.08016, train_loss: 0.0734, val_loss: 0.5471, val_acc: 0.8769
Epoch [45], last_lr: 0.07886, train_loss: 0.0768, val_loss: 0.4491, val_acc: 0.8903
Epoch [46], last_lr: 0.07750, train_loss: 0.0633, val_loss: 0.4219, val_acc: 0.8998
Epoch [47], last_lr: 0.07607, train_loss: 0.0575, val_loss: 0.4302, val_acc: 0.9100
Epoch [48], last_lr: 0.07458, train_loss: 0.0647, val_loss: 0.3781, val_acc: 0.9076
Epoch [49], last_lr: 0.07302, train_loss: 0.0601, val_loss: 0.4539, val_acc: 0.9046
Epoch [50], last_lr: 0.07142, train_loss: 0.0569, val_loss: 0.3822, val_acc: 0.9098
Epoch [51], last_lr: 0.06976, train_loss: 0.0529, val_loss: 0.5474, val_acc: 0.8890
Epoch [52], last_lr: 0.06805, train_loss: 0.0522, val_loss: 0.4536, val_acc: 0.9032
Epoch [53], last_lr: 0.06629, train_loss: 0.0424, val_loss: 0.3951, val_acc: 0.9174
Epoch [54], last_lr: 0.06449, train_loss: 0.0403, val_loss: 0.4438, val_acc: 0.9062
Epoch [55], last_lr: 0.06265, train_loss: 0.0351, val_loss: 0.4218, val_acc: 0.9170
Epoch [56], last_lr: 0.06077, train_loss: 0.0344, val_loss: 0.4314, val_acc: 0.9102
Epoch [57], last_lr: 0.05887, train_loss: 0.0359, val_loss: 0.3770, val_acc: 0.9214
Epoch [58], last_lr: 0.05693, train_loss: 0.0325, val_loss: 0.4057, val_acc: 0.9177
Epoch [59], last_lr: 0.05497, train_loss: 0.0285, val_loss: 0.4078, val_acc: 0.9148
Epoch [60], last_lr: 0.05299, train_loss: 0.0262, val_loss: 0.4228, val_acc: 0.9230
Epoch [61], last_lr: 0.05100, train_loss: 0.0262, val_loss: 0.4106, val_acc: 0.9182
Epoch [62], last_lr: 0.04899, train_loss: 0.0283, val_loss: 0.3958, val_acc: 0.9230
Epoch [63], last_lr: 0.04698, train_loss: 0.0204, val_loss: 0.4892, val_acc: 0.9179
Epoch [64], last_lr: 0.04496, train_loss: 0.0181, val_loss: 0.4204, val_acc: 0.9259
Epoch [65], last_lr: 0.04294, train_loss: 0.0182, val_loss: 0.3895, val_acc: 0.9273
Epoch [66], last_lr: 0.04093, train_loss: 0.0142, val_loss: 0.4305, val_acc: 0.9240
Epoch [67], last_lr: 0.03892, train_loss: 0.0137, val_loss: 0.3906, val_acc: 0.9294
Epoch [68], last_lr: 0.03692, train_loss: 0.0123, val_loss: 0.4639, val_acc: 0.9261
Epoch [69], last_lr: 0.03495, train_loss: 0.0103, val_loss: 0.4174, val_acc: 0.9311
Epoch [70], last_lr: 0.03299, train_loss: 0.0083, val_loss: 0.3907, val_acc: 0.9313
Epoch [71], last_lr: 0.03106, train_loss: 0.0091, val_loss: 0.4089, val_acc: 0.9322
Epoch [72], last_lr: 0.02915, train_loss: 0.0079, val_loss: 0.4133, val_acc: 0.9361
Epoch [73], last_lr: 0.02728, train_loss: 0.0060, val_loss: 0.4645, val_acc: 0.9288
Epoch [74], last_lr: 0.02544, train_loss: 0.0050, val_loss: 0.4127, val_acc: 0.9339
Epoch [75], last_lr: 0.02364, train_loss: 0.0049, val_loss: 0.4351, val_acc: 0.9338
Epoch [76], last_lr: 0.02188, train_loss: 0.0042, val_loss: 0.3998, val_acc: 0.9357
Epoch [77], last_lr: 0.02018, train_loss: 0.0035, val_loss: 0.3995, val_acc: 0.9371
Epoch [78], last_lr: 0.01852, train_loss: 0.0034, val_loss: 0.4155, val_acc: 0.9368
Epoch [79], last_lr: 0.01691, train_loss: 0.0032, val_loss: 0.4209, val_acc: 0.9358
Epoch [80], last_lr: 0.01536, train_loss: 0.0021, val_loss: 0.3997, val_acc: 0.9390
Epoch [81], last_lr: 0.01387, train_loss: 0.0014, val_loss: 0.3969, val_acc: 0.9398
Epoch [82], last_lr: 0.01245, train_loss: 0.0020, val_loss: 0.4043, val_acc: 0.9391
Epoch [83], last_lr: 0.01109, train_loss: 0.0014, val_loss: 0.4005, val_acc: 0.9400
Epoch [84], last_lr: 0.00979, train_loss: 0.0014, val_loss: 0.4081, val_acc: 0.9392
Epoch [85], last_lr: 0.00857, train_loss: 0.0011, val_loss: 0.4094, val_acc: 0.9418
Epoch [86], last_lr: 0.00742, train_loss: 0.0008, val_loss: 0.4111, val_acc: 0.9413
Epoch [87], last_lr: 0.00635, train_loss: 0.0007, val_loss: 0.4109, val_acc: 0.9421
Epoch [88], last_lr: 0.00535, train_loss: 0.0008, val_loss: 0.4122, val_acc: 0.9407
Epoch [89], last_lr: 0.00444, train_loss: 0.0007, val_loss: 0.4126, val_acc: 0.9420
Epoch [90], last_lr: 0.00361, train_loss: 0.0005, val_loss: 0.4153, val_acc: 0.9414
Epoch [91], last_lr: 0.00286, train_loss: 0.0004, val_loss: 0.4149, val_acc: 0.9414
Epoch [92], last_lr: 0.00219, train_loss: 0.0006, val_loss: 0.4194, val_acc: 0.9420
Epoch [93], last_lr: 0.00161, train_loss: 0.0005, val_loss: 0.4166, val_acc: 0.9418
Epoch [94], last_lr: 0.00112, train_loss: 0.0004, val_loss: 0.4175, val_acc: 0.9418
Epoch [95], last_lr: 0.00072, train_loss: 0.0006, val_loss: 0.4174, val_acc: 0.9420
Epoch [96], last_lr: 0.00040, train_loss: 0.0004, val_loss: 0.4179, val_acc: 0.9423
Epoch [97], last_lr: 0.00018, train_loss: 0.0006, val_loss: 0.4190, val_acc: 0.9419
Epoch [98], last_lr: 0.00004, train_loss: 0.0008, val_loss: 0.4172, val_acc: 0.9422
Epoch [99], last_lr: 0.00000, train_loss: 0.0005, val_loss: 0.4177, val_acc: 0.9421
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

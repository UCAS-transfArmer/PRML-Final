Epoch [0], last_lr: 0.00053, train_loss: 2.2056, val_loss: 2.0755, val_acc: 0.2477
Epoch [1], last_lr: 0.00060, train_loss: 1.7032, val_loss: 1.7696, val_acc: 0.3627
Epoch [2], last_lr: 0.00073, train_loss: 1.4394, val_loss: 1.3474, val_acc: 0.5093
Epoch [3], last_lr: 0.00091, train_loss: 1.2457, val_loss: 1.4102, val_acc: 0.5260
Epoch [4], last_lr: 0.00114, train_loss: 1.0831, val_loss: 1.1207, val_acc: 0.6063
Epoch [5], last_lr: 0.00141, train_loss: 0.9225, val_loss: 0.9096, val_acc: 0.6840
Epoch [6], last_lr: 0.00172, train_loss: 0.8095, val_loss: 0.8582, val_acc: 0.7083
Epoch [7], last_lr: 0.00207, train_loss: 0.7242, val_loss: 0.7898, val_acc: 0.7317
Epoch [8], last_lr: 0.00246, train_loss: 0.6490, val_loss: 0.8027, val_acc: 0.7333
Epoch [9], last_lr: 0.00288, train_loss: 0.5815, val_loss: 0.9028, val_acc: 0.7046
Epoch [10], last_lr: 0.00332, train_loss: 0.5242, val_loss: 0.8696, val_acc: 0.7327
Epoch [11], last_lr: 0.00379, train_loss: 0.4755, val_loss: 0.5875, val_acc: 0.8026
Epoch [12], last_lr: 0.00427, train_loss: 0.4235, val_loss: 0.6013, val_acc: 0.8031
Epoch [13], last_lr: 0.00476, train_loss: 0.3978, val_loss: 0.6989, val_acc: 0.7816
Epoch [14], last_lr: 0.00526, train_loss: 0.3746, val_loss: 0.7021, val_acc: 0.7809
Epoch [15], last_lr: 0.00575, train_loss: 0.3507, val_loss: 0.7074, val_acc: 0.7946
Epoch [16], last_lr: 0.00624, train_loss: 0.3208, val_loss: 0.5298, val_acc: 0.8353
Epoch [17], last_lr: 0.00672, train_loss: 0.3030, val_loss: 0.5098, val_acc: 0.8446
Epoch [18], last_lr: 0.00719, train_loss: 0.2971, val_loss: 0.4333, val_acc: 0.8542
Epoch [19], last_lr: 0.00763, train_loss: 0.2608, val_loss: 0.5304, val_acc: 0.8324
Epoch [20], last_lr: 0.00805, train_loss: 0.2456, val_loss: 0.5665, val_acc: 0.8245
Epoch [21], last_lr: 0.00843, train_loss: 0.2348, val_loss: 0.5457, val_acc: 0.8381
Epoch [22], last_lr: 0.00879, train_loss: 0.2178, val_loss: 0.5274, val_acc: 0.8468
Epoch [23], last_lr: 0.00910, train_loss: 0.2064, val_loss: 0.5796, val_acc: 0.8294
Epoch [24], last_lr: 0.00937, train_loss: 0.1947, val_loss: 0.4772, val_acc: 0.8488
Epoch [25], last_lr: 0.00959, train_loss: 0.1804, val_loss: 0.4009, val_acc: 0.8791
Epoch [26], last_lr: 0.00977, train_loss: 0.1649, val_loss: 0.3801, val_acc: 0.8840
Epoch [27], last_lr: 0.00990, train_loss: 0.1566, val_loss: 0.4494, val_acc: 0.8835
Epoch [28], last_lr: 0.00997, train_loss: 0.1438, val_loss: 0.4046, val_acc: 0.8846
Epoch [29], last_lr: 0.01000, train_loss: 0.1395, val_loss: 0.4178, val_acc: 0.8795
Epoch [30], last_lr: 0.00999, train_loss: 0.1240, val_loss: 0.3354, val_acc: 0.9045
Epoch [31], last_lr: 0.00998, train_loss: 0.1076, val_loss: 0.4276, val_acc: 0.8818
Epoch [32], last_lr: 0.00995, train_loss: 0.1108, val_loss: 0.5439, val_acc: 0.8668
Epoch [33], last_lr: 0.00992, train_loss: 0.0992, val_loss: 0.4632, val_acc: 0.8793
Epoch [34], last_lr: 0.00987, train_loss: 0.0967, val_loss: 0.4303, val_acc: 0.8925
Epoch [35], last_lr: 0.00982, train_loss: 0.0901, val_loss: 0.5077, val_acc: 0.8782
Epoch [36], last_lr: 0.00975, train_loss: 0.0795, val_loss: 0.4202, val_acc: 0.8912
Epoch [37], last_lr: 0.00968, train_loss: 0.0780, val_loss: 0.4138, val_acc: 0.8924
Epoch [38], last_lr: 0.00960, train_loss: 0.0715, val_loss: 0.4016, val_acc: 0.8979
Epoch [39], last_lr: 0.00950, train_loss: 0.0663, val_loss: 0.3448, val_acc: 0.9083
Epoch [40], last_lr: 0.00940, train_loss: 0.0606, val_loss: 0.3536, val_acc: 0.9049
Epoch [41], last_lr: 0.00929, train_loss: 0.0575, val_loss: 0.5314, val_acc: 0.8802
Epoch [42], last_lr: 0.00917, train_loss: 0.0649, val_loss: 0.3972, val_acc: 0.9057
Epoch [43], last_lr: 0.00904, train_loss: 0.0517, val_loss: 0.3797, val_acc: 0.9100
Epoch [44], last_lr: 0.00891, train_loss: 0.0524, val_loss: 0.3698, val_acc: 0.9128
Epoch [45], last_lr: 0.00876, train_loss: 0.0433, val_loss: 0.4314, val_acc: 0.9018
Epoch [46], last_lr: 0.00861, train_loss: 0.0436, val_loss: 0.3782, val_acc: 0.9152
Epoch [47], last_lr: 0.00845, train_loss: 0.0423, val_loss: 0.3685, val_acc: 0.9197
Epoch [48], last_lr: 0.00829, train_loss: 0.0418, val_loss: 0.4058, val_acc: 0.9082
Epoch [49], last_lr: 0.00811, train_loss: 0.0373, val_loss: 0.4141, val_acc: 0.9113
Epoch [50], last_lr: 0.00794, train_loss: 0.0381, val_loss: 0.3557, val_acc: 0.9213
Epoch [51], last_lr: 0.00775, train_loss: 0.0322, val_loss: 0.3606, val_acc: 0.9191
Epoch [52], last_lr: 0.00756, train_loss: 0.0277, val_loss: 0.5323, val_acc: 0.8982
Epoch [53], last_lr: 0.00737, train_loss: 0.0290, val_loss: 0.4473, val_acc: 0.9073
Epoch [54], last_lr: 0.00717, train_loss: 0.0277, val_loss: 0.4466, val_acc: 0.9102
Epoch [55], last_lr: 0.00696, train_loss: 0.0218, val_loss: 0.3720, val_acc: 0.9277
Epoch [56], last_lr: 0.00675, train_loss: 0.0230, val_loss: 0.3850, val_acc: 0.9192
Epoch [57], last_lr: 0.00654, train_loss: 0.0198, val_loss: 0.4059, val_acc: 0.9190
Epoch [58], last_lr: 0.00633, train_loss: 0.0206, val_loss: 0.3911, val_acc: 0.9257
Epoch [59], last_lr: 0.00611, train_loss: 0.0192, val_loss: 0.3872, val_acc: 0.9256
Epoch [60], last_lr: 0.00589, train_loss: 0.0204, val_loss: 0.4011, val_acc: 0.9197
Epoch [61], last_lr: 0.00567, train_loss: 0.0159, val_loss: 0.4193, val_acc: 0.9220
Epoch [62], last_lr: 0.00544, train_loss: 0.0105, val_loss: 0.3781, val_acc: 0.9293
Epoch [63], last_lr: 0.00522, train_loss: 0.0084, val_loss: 0.3923, val_acc: 0.9295
Epoch [64], last_lr: 0.00500, train_loss: 0.0084, val_loss: 0.3723, val_acc: 0.9318
Epoch [65], last_lr: 0.00477, train_loss: 0.0089, val_loss: 0.3661, val_acc: 0.9317
Epoch [66], last_lr: 0.00455, train_loss: 0.0085, val_loss: 0.4035, val_acc: 0.9295
Epoch [67], last_lr: 0.00432, train_loss: 0.0078, val_loss: 0.4039, val_acc: 0.9286
Epoch [68], last_lr: 0.00410, train_loss: 0.0063, val_loss: 0.4056, val_acc: 0.9311
Epoch [69], last_lr: 0.00388, train_loss: 0.0063, val_loss: 0.4113, val_acc: 0.9325
Epoch [70], last_lr: 0.00367, train_loss: 0.0068, val_loss: 0.4055, val_acc: 0.9338
Epoch [71], last_lr: 0.00345, train_loss: 0.0047, val_loss: 0.3997, val_acc: 0.9344
Epoch [72], last_lr: 0.00324, train_loss: 0.0036, val_loss: 0.3992, val_acc: 0.9351
Epoch [73], last_lr: 0.00303, train_loss: 0.0032, val_loss: 0.3931, val_acc: 0.9378
Epoch [74], last_lr: 0.00283, train_loss: 0.0027, val_loss: 0.3945, val_acc: 0.9340
Epoch [75], last_lr: 0.00263, train_loss: 0.0028, val_loss: 0.4116, val_acc: 0.9350
Epoch [76], last_lr: 0.00243, train_loss: 0.0020, val_loss: 0.3961, val_acc: 0.9354
Epoch [77], last_lr: 0.00224, train_loss: 0.0019, val_loss: 0.4103, val_acc: 0.9371
Epoch [78], last_lr: 0.00206, train_loss: 0.0019, val_loss: 0.4024, val_acc: 0.9381
Epoch [79], last_lr: 0.00188, train_loss: 0.0011, val_loss: 0.4016, val_acc: 0.9384
Epoch [80], last_lr: 0.00171, train_loss: 0.0012, val_loss: 0.4110, val_acc: 0.9376
Epoch [81], last_lr: 0.00154, train_loss: 0.0012, val_loss: 0.4152, val_acc: 0.9385
Epoch [82], last_lr: 0.00138, train_loss: 0.0007, val_loss: 0.4079, val_acc: 0.9392
Epoch [83], last_lr: 0.00123, train_loss: 0.0007, val_loss: 0.4060, val_acc: 0.9401
Epoch [84], last_lr: 0.00109, train_loss: 0.0005, val_loss: 0.4090, val_acc: 0.9396
Epoch [85], last_lr: 0.00095, train_loss: 0.0008, val_loss: 0.4075, val_acc: 0.9405
Epoch [86], last_lr: 0.00082, train_loss: 0.0004, val_loss: 0.4119, val_acc: 0.9404
Epoch [87], last_lr: 0.00071, train_loss: 0.0004, val_loss: 0.4094, val_acc: 0.9400
Epoch [88], last_lr: 0.00059, train_loss: 0.0005, val_loss: 0.4099, val_acc: 0.9395
Epoch [89], last_lr: 0.00049, train_loss: 0.0002, val_loss: 0.4157, val_acc: 0.9405
Epoch [90], last_lr: 0.00040, train_loss: 0.0003, val_loss: 0.4173, val_acc: 0.9398
Epoch [91], last_lr: 0.00032, train_loss: 0.0003, val_loss: 0.4166, val_acc: 0.9399
Epoch [92], last_lr: 0.00024, train_loss: 0.0002, val_loss: 0.4168, val_acc: 0.9401
Epoch [93], last_lr: 0.00018, train_loss: 0.0002, val_loss: 0.4190, val_acc: 0.9404
Epoch [94], last_lr: 0.00012, train_loss: 0.0003, val_loss: 0.4201, val_acc: 0.9410
Epoch [95], last_lr: 0.00008, train_loss: 0.0001, val_loss: 0.4203, val_acc: 0.9410
Epoch [96], last_lr: 0.00004, train_loss: 0.0003, val_loss: 0.4187, val_acc: 0.9408
Epoch [97], last_lr: 0.00002, train_loss: 0.0002, val_loss: 0.4201, val_acc: 0.9407
Epoch [98], last_lr: 0.00000, train_loss: 0.0003, val_loss: 0.4187, val_acc: 0.9408
Epoch [99], last_lr: 0.00000, train_loss: 0.0003, val_loss: 0.4182, val_acc: 0.9409
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

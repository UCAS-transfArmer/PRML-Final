Epoch [0], last_lr: 0.00043, train_loss: 2.1922, val_loss: 4.2516, val_acc: 0.1480
Epoch [1], last_lr: 0.00051, train_loss: 1.8792, val_loss: 2.8473, val_acc: 0.1945
Epoch [2], last_lr: 0.00064, train_loss: 1.7638, val_loss: 1.8759, val_acc: 0.2757
Epoch [3], last_lr: 0.00082, train_loss: 1.6298, val_loss: 2.6782, val_acc: 0.2438
Epoch [4], last_lr: 0.00104, train_loss: 1.5486, val_loss: 1.9960, val_acc: 0.3245
Epoch [5], last_lr: 0.00132, train_loss: 1.4334, val_loss: 6.1708, val_acc: 0.2433
Epoch [6], last_lr: 0.00163, train_loss: 1.3645, val_loss: 2.6083, val_acc: 0.3722
Epoch [7], last_lr: 0.00199, train_loss: 1.2463, val_loss: 4.3560, val_acc: 0.3032
Epoch [8], last_lr: 0.00238, train_loss: 1.1352, val_loss: 1.7269, val_acc: 0.4989
Epoch [9], last_lr: 0.00280, train_loss: 1.0775, val_loss: 2.7436, val_acc: 0.4240
Epoch [10], last_lr: 0.00325, train_loss: 1.0329, val_loss: 1.6368, val_acc: 0.5272
Epoch [11], last_lr: 0.00372, train_loss: 0.9761, val_loss: 3.7457, val_acc: 0.3346
Epoch [12], last_lr: 0.00421, train_loss: 0.9379, val_loss: 2.0011, val_acc: 0.5101
Epoch [13], last_lr: 0.00470, train_loss: 0.8829, val_loss: 2.9430, val_acc: 0.4127
Epoch [14], last_lr: 0.00521, train_loss: 0.8450, val_loss: 1.5118, val_acc: 0.5681
Epoch [15], last_lr: 0.00571, train_loss: 0.7972, val_loss: 1.4797, val_acc: 0.5830
Epoch [16], last_lr: 0.00620, train_loss: 0.7682, val_loss: 1.0940, val_acc: 0.6448
Epoch [17], last_lr: 0.00669, train_loss: 0.7467, val_loss: 1.3755, val_acc: 0.6065
Epoch [18], last_lr: 0.00716, train_loss: 0.7118, val_loss: 1.0290, val_acc: 0.6561
Epoch [19], last_lr: 0.00761, train_loss: 0.6874, val_loss: 2.3897, val_acc: 0.5588
Epoch [20], last_lr: 0.00803, train_loss: 0.6582, val_loss: 1.8422, val_acc: 0.5838
Epoch [21], last_lr: 0.00842, train_loss: 0.6275, val_loss: 0.9383, val_acc: 0.7156
Epoch [22], last_lr: 0.00877, train_loss: 0.5826, val_loss: 1.1275, val_acc: 0.6592
Epoch [23], last_lr: 0.00909, train_loss: 0.5599, val_loss: 1.1358, val_acc: 0.6799
Epoch [24], last_lr: 0.00936, train_loss: 0.5322, val_loss: 0.8569, val_acc: 0.7300
Epoch [25], last_lr: 0.00959, train_loss: 0.4984, val_loss: 1.0732, val_acc: 0.6843
Epoch [26], last_lr: 0.00977, train_loss: 0.4675, val_loss: 0.8903, val_acc: 0.7363
Epoch [27], last_lr: 0.00990, train_loss: 0.4589, val_loss: 1.0445, val_acc: 0.7132
Epoch [28], last_lr: 0.00997, train_loss: 0.4295, val_loss: 0.7558, val_acc: 0.7657
Epoch [29], last_lr: 0.01000, train_loss: 0.4108, val_loss: 0.9237, val_acc: 0.7262
Epoch [30], last_lr: 0.00999, train_loss: 0.3887, val_loss: 1.0783, val_acc: 0.7084
Epoch [31], last_lr: 0.00998, train_loss: 0.3540, val_loss: 0.8936, val_acc: 0.7499
Epoch [32], last_lr: 0.00995, train_loss: 0.3375, val_loss: 1.1110, val_acc: 0.7206
Epoch [33], last_lr: 0.00992, train_loss: 0.3170, val_loss: 0.8479, val_acc: 0.7609
Epoch [34], last_lr: 0.00987, train_loss: 0.3114, val_loss: 1.2237, val_acc: 0.6914
Epoch [35], last_lr: 0.00982, train_loss: 0.2836, val_loss: 0.7961, val_acc: 0.7735
Epoch [36], last_lr: 0.00975, train_loss: 0.2658, val_loss: 0.8643, val_acc: 0.7632
Epoch [37], last_lr: 0.00968, train_loss: 0.2497, val_loss: 0.8792, val_acc: 0.7800
Epoch [38], last_lr: 0.00960, train_loss: 0.2408, val_loss: 2.8856, val_acc: 0.5629
Epoch [39], last_lr: 0.00950, train_loss: 0.2225, val_loss: 0.8227, val_acc: 0.7799
Epoch [40], last_lr: 0.00940, train_loss: 0.2054, val_loss: 1.1644, val_acc: 0.7482
Epoch [41], last_lr: 0.00929, train_loss: 0.1878, val_loss: 0.8203, val_acc: 0.7952
Epoch [42], last_lr: 0.00917, train_loss: 0.1803, val_loss: 0.8152, val_acc: 0.7785
Epoch [43], last_lr: 0.00904, train_loss: 0.1542, val_loss: 0.7725, val_acc: 0.7892
Epoch [44], last_lr: 0.00891, train_loss: 0.1420, val_loss: 0.8490, val_acc: 0.7860
Epoch [45], last_lr: 0.00876, train_loss: 0.1399, val_loss: 0.8186, val_acc: 0.8018
Epoch [46], last_lr: 0.00861, train_loss: 0.1292, val_loss: 0.9751, val_acc: 0.7775
Epoch [47], last_lr: 0.00845, train_loss: 0.1150, val_loss: 0.9848, val_acc: 0.7770
Epoch [48], last_lr: 0.00829, train_loss: 0.1188, val_loss: 1.0537, val_acc: 0.7646
Epoch [49], last_lr: 0.00811, train_loss: 0.1173, val_loss: 1.1134, val_acc: 0.7758
Epoch [50], last_lr: 0.00794, train_loss: 0.1006, val_loss: 0.9879, val_acc: 0.7801
Epoch [51], last_lr: 0.00775, train_loss: 0.0890, val_loss: 0.9991, val_acc: 0.7898
Epoch [52], last_lr: 0.00756, train_loss: 0.0752, val_loss: 0.9585, val_acc: 0.7980
Epoch [53], last_lr: 0.00737, train_loss: 0.0809, val_loss: 0.9124, val_acc: 0.7990
Epoch [54], last_lr: 0.00717, train_loss: 0.0765, val_loss: 1.0275, val_acc: 0.7912
Epoch [55], last_lr: 0.00696, train_loss: 0.0553, val_loss: 1.2237, val_acc: 0.7778
Epoch [56], last_lr: 0.00675, train_loss: 0.0589, val_loss: 1.1140, val_acc: 0.7865
Epoch [57], last_lr: 0.00654, train_loss: 0.0592, val_loss: 1.0677, val_acc: 0.7896
Epoch [58], last_lr: 0.00633, train_loss: 0.0495, val_loss: 1.3796, val_acc: 0.7630
Epoch [59], last_lr: 0.00611, train_loss: 0.0525, val_loss: 1.2521, val_acc: 0.7623
Epoch [60], last_lr: 0.00589, train_loss: 0.0417, val_loss: 0.9969, val_acc: 0.8098
Epoch [61], last_lr: 0.00567, train_loss: 0.0411, val_loss: 1.0237, val_acc: 0.7969
Epoch [62], last_lr: 0.00544, train_loss: 0.0401, val_loss: 1.0782, val_acc: 0.8109
Epoch [63], last_lr: 0.00522, train_loss: 0.0276, val_loss: 1.0351, val_acc: 0.8139
Epoch [64], last_lr: 0.00500, train_loss: 0.0239, val_loss: 1.1014, val_acc: 0.8110
Epoch [65], last_lr: 0.00477, train_loss: 0.0155, val_loss: 1.0388, val_acc: 0.8255
Epoch [66], last_lr: 0.00455, train_loss: 0.0103, val_loss: 1.1075, val_acc: 0.8197
Epoch [67], last_lr: 0.00432, train_loss: 0.0097, val_loss: 1.1878, val_acc: 0.8202
Epoch [68], last_lr: 0.00410, train_loss: 0.0143, val_loss: 1.1351, val_acc: 0.8198
Epoch [69], last_lr: 0.00388, train_loss: 0.0115, val_loss: 1.2079, val_acc: 0.8162
Epoch [70], last_lr: 0.00367, train_loss: 0.0062, val_loss: 1.1249, val_acc: 0.8280
Epoch [71], last_lr: 0.00345, train_loss: 0.0038, val_loss: 1.1135, val_acc: 0.8273
Epoch [72], last_lr: 0.00324, train_loss: 0.0030, val_loss: 1.2358, val_acc: 0.8205
Epoch [73], last_lr: 0.00303, train_loss: 0.0018, val_loss: 1.1412, val_acc: 0.8332
Epoch [74], last_lr: 0.00283, train_loss: 0.0010, val_loss: 1.1578, val_acc: 0.8300
Epoch [75], last_lr: 0.00263, train_loss: 0.0005, val_loss: 1.1479, val_acc: 0.8323
Epoch [76], last_lr: 0.00243, train_loss: 0.0003, val_loss: 1.1602, val_acc: 0.8325
Epoch [77], last_lr: 0.00224, train_loss: 0.0002, val_loss: 1.1638, val_acc: 0.8321
Epoch [78], last_lr: 0.00206, train_loss: 0.0002, val_loss: 1.1695, val_acc: 0.8333
Epoch [79], last_lr: 0.00188, train_loss: 0.0002, val_loss: 1.1715, val_acc: 0.8332
Epoch [80], last_lr: 0.00171, train_loss: 0.0001, val_loss: 1.1705, val_acc: 0.8333
Epoch [81], last_lr: 0.00154, train_loss: 0.0001, val_loss: 1.1744, val_acc: 0.8346
Epoch [82], last_lr: 0.00138, train_loss: 0.0001, val_loss: 1.1757, val_acc: 0.8338
Epoch [83], last_lr: 0.00123, train_loss: 0.0001, val_loss: 1.1787, val_acc: 0.8338
Epoch [84], last_lr: 0.00109, train_loss: 0.0001, val_loss: 1.1834, val_acc: 0.8334
Epoch [85], last_lr: 0.00095, train_loss: 0.0001, val_loss: 1.1847, val_acc: 0.8336
Epoch [86], last_lr: 0.00082, train_loss: 0.0001, val_loss: 1.1908, val_acc: 0.8331
Epoch [87], last_lr: 0.00071, train_loss: 0.0001, val_loss: 1.1884, val_acc: 0.8334
Epoch [88], last_lr: 0.00059, train_loss: 0.0001, val_loss: 1.1906, val_acc: 0.8341
Epoch [89], last_lr: 0.00049, train_loss: 0.0001, val_loss: 1.1935, val_acc: 0.8339
Epoch [90], last_lr: 0.00040, train_loss: 0.0001, val_loss: 1.1926, val_acc: 0.8325
Epoch [91], last_lr: 0.00032, train_loss: 0.0001, val_loss: 1.1921, val_acc: 0.8334
Epoch [92], last_lr: 0.00024, train_loss: 0.0001, val_loss: 1.1910, val_acc: 0.8343
Epoch [93], last_lr: 0.00018, train_loss: 0.0001, val_loss: 1.1920, val_acc: 0.8338
Epoch [94], last_lr: 0.00012, train_loss: 0.0001, val_loss: 1.1939, val_acc: 0.8345
Epoch [95], last_lr: 0.00008, train_loss: 0.0001, val_loss: 1.1916, val_acc: 0.8340
Epoch [96], last_lr: 0.00004, train_loss: 0.0001, val_loss: 1.1956, val_acc: 0.8334
Epoch [97], last_lr: 0.00002, train_loss: 0.0001, val_loss: 1.1933, val_acc: 0.8339
Epoch [98], last_lr: 0.00000, train_loss: 0.0001, val_loss: 1.1941, val_acc: 0.8339
Epoch [99], last_lr: 0.00000, train_loss: 0.0001, val_loss: 1.1946, val_acc: 0.8331
Saved final model to ./saves/cnn_cifar10_final_ep100_step4900.pth

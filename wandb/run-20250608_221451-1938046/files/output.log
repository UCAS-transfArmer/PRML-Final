Epoch [0], last_lr: 0.00043, train_loss: 1.6781, val_loss: 1.5343, val_acc: 0.4499
Epoch [1], last_lr: 0.00051, train_loss: 1.2070, val_loss: 1.2960, val_acc: 0.5466
Epoch [2], last_lr: 0.00064, train_loss: 0.9647, val_loss: 0.9596, val_acc: 0.6567
Epoch [3], last_lr: 0.00082, train_loss: 0.8334, val_loss: 0.9020, val_acc: 0.6839
Epoch [4], last_lr: 0.00104, train_loss: 0.7090, val_loss: 0.8886, val_acc: 0.7185
Epoch [5], last_lr: 0.00132, train_loss: 0.6097, val_loss: 0.7193, val_acc: 0.7642
Epoch [6], last_lr: 0.00163, train_loss: 0.5369, val_loss: 1.2034, val_acc: 0.6375
Epoch [7], last_lr: 0.00199, train_loss: 0.4946, val_loss: 0.6951, val_acc: 0.7841
Epoch [8], last_lr: 0.00238, train_loss: 0.4428, val_loss: 0.6574, val_acc: 0.7818
Epoch [9], last_lr: 0.00280, train_loss: 0.4095, val_loss: 0.5044, val_acc: 0.8345
Epoch [10], last_lr: 0.00325, train_loss: 0.3837, val_loss: 0.6325, val_acc: 0.8060
Epoch [11], last_lr: 0.00372, train_loss: 0.3635, val_loss: 0.9030, val_acc: 0.7476
Epoch [12], last_lr: 0.00421, train_loss: 0.3329, val_loss: 0.6765, val_acc: 0.8010
Epoch [13], last_lr: 0.00470, train_loss: 0.3168, val_loss: 0.7696, val_acc: 0.7798
Epoch [14], last_lr: 0.00521, train_loss: 0.3032, val_loss: 0.4676, val_acc: 0.8515
Epoch [15], last_lr: 0.00571, train_loss: 0.2809, val_loss: 0.6849, val_acc: 0.8177
Epoch [16], last_lr: 0.00620, train_loss: 0.2560, val_loss: 0.4072, val_acc: 0.8693
Epoch [17], last_lr: 0.00669, train_loss: 0.2520, val_loss: 0.7515, val_acc: 0.7910
Epoch [18], last_lr: 0.00716, train_loss: 0.2331, val_loss: 0.5896, val_acc: 0.8317
Epoch [19], last_lr: 0.00761, train_loss: 0.2122, val_loss: 0.3874, val_acc: 0.8786
Epoch [20], last_lr: 0.00803, train_loss: 0.2082, val_loss: 0.5794, val_acc: 0.8349
Epoch [21], last_lr: 0.00842, train_loss: 0.1908, val_loss: 0.5003, val_acc: 0.8552
Epoch [22], last_lr: 0.00877, train_loss: 0.1801, val_loss: 0.5020, val_acc: 0.8575
Epoch [23], last_lr: 0.00909, train_loss: 0.1739, val_loss: 0.5503, val_acc: 0.8418
Epoch [24], last_lr: 0.00936, train_loss: 0.1521, val_loss: 0.6120, val_acc: 0.8384
Epoch [25], last_lr: 0.00959, train_loss: 0.1589, val_loss: 0.5130, val_acc: 0.8514
Epoch [26], last_lr: 0.00977, train_loss: 0.1372, val_loss: 0.3486, val_acc: 0.8982
Epoch [27], last_lr: 0.00990, train_loss: 0.1275, val_loss: 0.4173, val_acc: 0.8829
Epoch [28], last_lr: 0.00997, train_loss: 0.1252, val_loss: 0.3413, val_acc: 0.8997
Epoch [29], last_lr: 0.01000, train_loss: 0.1154, val_loss: 0.3953, val_acc: 0.8868
Epoch [30], last_lr: 0.00999, train_loss: 0.1046, val_loss: 0.4163, val_acc: 0.8885
Epoch [31], last_lr: 0.00998, train_loss: 0.0949, val_loss: 0.3991, val_acc: 0.8954
Epoch [32], last_lr: 0.00995, train_loss: 0.0862, val_loss: 0.4623, val_acc: 0.8860
Epoch [33], last_lr: 0.00992, train_loss: 0.0866, val_loss: 0.3611, val_acc: 0.9055
Epoch [34], last_lr: 0.00987, train_loss: 0.0857, val_loss: 0.3933, val_acc: 0.8951
Epoch [35], last_lr: 0.00982, train_loss: 0.0730, val_loss: 0.4055, val_acc: 0.8997
Epoch [36], last_lr: 0.00975, train_loss: 0.0630, val_loss: 0.4393, val_acc: 0.8949
Epoch [37], last_lr: 0.00968, train_loss: 0.0669, val_loss: 0.4095, val_acc: 0.9001
Epoch [38], last_lr: 0.00960, train_loss: 0.0547, val_loss: 0.3686, val_acc: 0.9109
Epoch [39], last_lr: 0.00950, train_loss: 0.0576, val_loss: 0.3606, val_acc: 0.9107
Epoch [40], last_lr: 0.00940, train_loss: 0.0563, val_loss: 0.3617, val_acc: 0.9142
Epoch [41], last_lr: 0.00929, train_loss: 0.0477, val_loss: 0.3649, val_acc: 0.9097
Epoch [42], last_lr: 0.00917, train_loss: 0.0464, val_loss: 0.3767, val_acc: 0.9112
Epoch [43], last_lr: 0.00904, train_loss: 0.0444, val_loss: 0.4123, val_acc: 0.9080
Epoch [44], last_lr: 0.00891, train_loss: 0.0440, val_loss: 0.3947, val_acc: 0.9075
Epoch [45], last_lr: 0.00876, train_loss: 0.0411, val_loss: 0.3424, val_acc: 0.9218
Epoch [46], last_lr: 0.00861, train_loss: 0.0387, val_loss: 0.4200, val_acc: 0.9080
Epoch [47], last_lr: 0.00845, train_loss: 0.0372, val_loss: 0.4616, val_acc: 0.9067
Epoch [48], last_lr: 0.00829, train_loss: 0.0368, val_loss: 0.3668, val_acc: 0.9158
Epoch [49], last_lr: 0.00811, train_loss: 0.0327, val_loss: 0.3438, val_acc: 0.9259
Epoch [50], last_lr: 0.00794, train_loss: 0.0273, val_loss: 0.3925, val_acc: 0.9138
Epoch [51], last_lr: 0.00775, train_loss: 0.0257, val_loss: 0.3849, val_acc: 0.9243
Epoch [52], last_lr: 0.00756, train_loss: 0.0252, val_loss: 0.4061, val_acc: 0.9166
Epoch [53], last_lr: 0.00737, train_loss: 0.0282, val_loss: 0.5465, val_acc: 0.8926
Epoch [54], last_lr: 0.00717, train_loss: 0.0283, val_loss: 0.3572, val_acc: 0.9227
Epoch [55], last_lr: 0.00696, train_loss: 0.0252, val_loss: 0.3756, val_acc: 0.9218
Epoch [56], last_lr: 0.00675, train_loss: 0.0184, val_loss: 0.3505, val_acc: 0.9263
Epoch [57], last_lr: 0.00654, train_loss: 0.0153, val_loss: 0.3830, val_acc: 0.9275
Epoch [58], last_lr: 0.00633, train_loss: 0.0152, val_loss: 0.3787, val_acc: 0.9233
Epoch [59], last_lr: 0.00611, train_loss: 0.0165, val_loss: 0.3814, val_acc: 0.9218
Epoch [60], last_lr: 0.00589, train_loss: 0.0131, val_loss: 0.3642, val_acc: 0.9286
Epoch [61], last_lr: 0.00567, train_loss: 0.0132, val_loss: 0.3796, val_acc: 0.9241
Epoch [62], last_lr: 0.00544, train_loss: 0.0116, val_loss: 0.3451, val_acc: 0.9326
Epoch [63], last_lr: 0.00522, train_loss: 0.0112, val_loss: 0.4073, val_acc: 0.9239
Epoch [64], last_lr: 0.00500, train_loss: 0.0115, val_loss: 0.3816, val_acc: 0.9268
Epoch [65], last_lr: 0.00477, train_loss: 0.0108, val_loss: 0.3626, val_acc: 0.9298
Epoch [66], last_lr: 0.00455, train_loss: 0.0068, val_loss: 0.3658, val_acc: 0.9296
Epoch [67], last_lr: 0.00432, train_loss: 0.0080, val_loss: 0.3984, val_acc: 0.9291
Epoch [68], last_lr: 0.00410, train_loss: 0.0068, val_loss: 0.3719, val_acc: 0.9325
Epoch [69], last_lr: 0.00388, train_loss: 0.0053, val_loss: 0.3669, val_acc: 0.9310
Epoch [70], last_lr: 0.00367, train_loss: 0.0054, val_loss: 0.3752, val_acc: 0.9343
Epoch [71], last_lr: 0.00345, train_loss: 0.0036, val_loss: 0.3627, val_acc: 0.9329
Epoch [72], last_lr: 0.00324, train_loss: 0.0030, val_loss: 0.3713, val_acc: 0.9347
Epoch [73], last_lr: 0.00303, train_loss: 0.0023, val_loss: 0.3910, val_acc: 0.9346
Epoch [74], last_lr: 0.00283, train_loss: 0.0020, val_loss: 0.3678, val_acc: 0.9376
Epoch [75], last_lr: 0.00263, train_loss: 0.0019, val_loss: 0.3662, val_acc: 0.9396
Epoch [76], last_lr: 0.00243, train_loss: 0.0016, val_loss: 0.3727, val_acc: 0.9386
Epoch [77], last_lr: 0.00224, train_loss: 0.0012, val_loss: 0.3664, val_acc: 0.9411
Epoch [78], last_lr: 0.00206, train_loss: 0.0011, val_loss: 0.3736, val_acc: 0.9398
Epoch [79], last_lr: 0.00188, train_loss: 0.0010, val_loss: 0.3701, val_acc: 0.9401
Epoch [80], last_lr: 0.00171, train_loss: 0.0011, val_loss: 0.3695, val_acc: 0.9411
Epoch [81], last_lr: 0.00154, train_loss: 0.0006, val_loss: 0.3726, val_acc: 0.9396
Epoch [82], last_lr: 0.00138, train_loss: 0.0007, val_loss: 0.3717, val_acc: 0.9398
Epoch [83], last_lr: 0.00123, train_loss: 0.0006, val_loss: 0.3703, val_acc: 0.9411
Epoch [84], last_lr: 0.00109, train_loss: 0.0005, val_loss: 0.3693, val_acc: 0.9409
Epoch [85], last_lr: 0.00095, train_loss: 0.0004, val_loss: 0.3683, val_acc: 0.9414
Epoch [86], last_lr: 0.00082, train_loss: 0.0004, val_loss: 0.3694, val_acc: 0.9414
Epoch [87], last_lr: 0.00071, train_loss: 0.0005, val_loss: 0.3695, val_acc: 0.9411
Epoch [88], last_lr: 0.00059, train_loss: 0.0003, val_loss: 0.3689, val_acc: 0.9416
Epoch [89], last_lr: 0.00049, train_loss: 0.0003, val_loss: 0.3672, val_acc: 0.9421
Epoch [90], last_lr: 0.00040, train_loss: 0.0002, val_loss: 0.3682, val_acc: 0.9417
Epoch [91], last_lr: 0.00032, train_loss: 0.0003, val_loss: 0.3662, val_acc: 0.9414
Epoch [92], last_lr: 0.00024, train_loss: 0.0003, val_loss: 0.3658, val_acc: 0.9421
Epoch [93], last_lr: 0.00018, train_loss: 0.0002, val_loss: 0.3668, val_acc: 0.9423
Epoch [94], last_lr: 0.00012, train_loss: 0.0003, val_loss: 0.3661, val_acc: 0.9420
Epoch [95], last_lr: 0.00008, train_loss: 0.0004, val_loss: 0.3662, val_acc: 0.9422
Epoch [96], last_lr: 0.00004, train_loss: 0.0003, val_loss: 0.3649, val_acc: 0.9428
Epoch [97], last_lr: 0.00002, train_loss: 0.0002, val_loss: 0.3658, val_acc: 0.9422
Epoch [98], last_lr: 0.00000, train_loss: 0.0003, val_loss: 0.3668, val_acc: 0.9422
Epoch [99], last_lr: 0.00000, train_loss: 0.0002, val_loss: 0.3660, val_acc: 0.9421
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

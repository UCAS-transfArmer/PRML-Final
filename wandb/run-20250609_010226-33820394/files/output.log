Epoch [0], last_lr: 0.00043, train_loss: 1.6771, val_loss: 1.5055, val_acc: 0.4619
Epoch [1], last_lr: 0.00051, train_loss: 1.2583, val_loss: 1.3839, val_acc: 0.5353
Epoch [2], last_lr: 0.00064, train_loss: 1.0309, val_loss: 1.2799, val_acc: 0.5700
Epoch [3], last_lr: 0.00082, train_loss: 0.8931, val_loss: 0.8976, val_acc: 0.6899
Epoch [4], last_lr: 0.00104, train_loss: 0.7890, val_loss: 1.0766, val_acc: 0.6573
Epoch [5], last_lr: 0.00132, train_loss: 0.7050, val_loss: 0.8373, val_acc: 0.7266
Epoch [6], last_lr: 0.00163, train_loss: 0.6294, val_loss: 1.4594, val_acc: 0.6185
Epoch [7], last_lr: 0.00199, train_loss: 0.5671, val_loss: 0.8968, val_acc: 0.7263
Epoch [8], last_lr: 0.00238, train_loss: 0.5293, val_loss: 0.7112, val_acc: 0.7720
Epoch [9], last_lr: 0.00280, train_loss: 0.4858, val_loss: 0.7290, val_acc: 0.7792
Epoch [10], last_lr: 0.00325, train_loss: 0.4612, val_loss: 0.7158, val_acc: 0.7846
Epoch [11], last_lr: 0.00372, train_loss: 0.4458, val_loss: 1.3809, val_acc: 0.6642
Epoch [12], last_lr: 0.00421, train_loss: 0.4217, val_loss: 0.7210, val_acc: 0.7806
Epoch [13], last_lr: 0.00470, train_loss: 0.3823, val_loss: 0.7146, val_acc: 0.7914
Epoch [14], last_lr: 0.00521, train_loss: 0.3748, val_loss: 0.5310, val_acc: 0.8297
Epoch [15], last_lr: 0.00571, train_loss: 0.3492, val_loss: 0.6845, val_acc: 0.7958
Epoch [16], last_lr: 0.00620, train_loss: 0.3409, val_loss: 0.7548, val_acc: 0.7869
Epoch [17], last_lr: 0.00669, train_loss: 0.3266, val_loss: 0.4273, val_acc: 0.8616
Epoch [18], last_lr: 0.00716, train_loss: 0.3053, val_loss: 0.6560, val_acc: 0.8085
Epoch [19], last_lr: 0.00761, train_loss: 0.2968, val_loss: 0.5372, val_acc: 0.8387
Epoch [20], last_lr: 0.00803, train_loss: 0.2858, val_loss: 0.6903, val_acc: 0.7991
Epoch [21], last_lr: 0.00842, train_loss: 0.2617, val_loss: 0.5054, val_acc: 0.8498
Epoch [22], last_lr: 0.00877, train_loss: 0.2612, val_loss: 0.8163, val_acc: 0.7824
Epoch [23], last_lr: 0.00909, train_loss: 0.2438, val_loss: 0.4273, val_acc: 0.8665
Epoch [24], last_lr: 0.00936, train_loss: 0.2227, val_loss: 0.4511, val_acc: 0.8584
Epoch [25], last_lr: 0.00959, train_loss: 0.2116, val_loss: 0.4882, val_acc: 0.8542
Epoch [26], last_lr: 0.00977, train_loss: 0.2020, val_loss: 0.5155, val_acc: 0.8484
Epoch [27], last_lr: 0.00990, train_loss: 0.1961, val_loss: 0.5276, val_acc: 0.8529
Epoch [28], last_lr: 0.00997, train_loss: 0.1841, val_loss: 0.4473, val_acc: 0.8732
Epoch [29], last_lr: 0.01000, train_loss: 0.1767, val_loss: 0.3715, val_acc: 0.8829
Epoch [30], last_lr: 0.00999, train_loss: 0.1552, val_loss: 0.4206, val_acc: 0.8843
Epoch [31], last_lr: 0.00998, train_loss: 0.1526, val_loss: 0.4476, val_acc: 0.8744
Epoch [32], last_lr: 0.00995, train_loss: 0.1444, val_loss: 0.4593, val_acc: 0.8755
Epoch [33], last_lr: 0.00992, train_loss: 0.1320, val_loss: 0.4209, val_acc: 0.8794
Epoch [34], last_lr: 0.00987, train_loss: 0.1298, val_loss: 0.4538, val_acc: 0.8777
Epoch [35], last_lr: 0.00982, train_loss: 0.1161, val_loss: 0.4163, val_acc: 0.8875
Epoch [36], last_lr: 0.00975, train_loss: 0.1194, val_loss: 0.3756, val_acc: 0.8941
Epoch [37], last_lr: 0.00968, train_loss: 0.1120, val_loss: 0.3729, val_acc: 0.8997
Epoch [38], last_lr: 0.00960, train_loss: 0.1050, val_loss: 0.3832, val_acc: 0.8920
Epoch [39], last_lr: 0.00950, train_loss: 0.0990, val_loss: 0.4134, val_acc: 0.8923
Epoch [40], last_lr: 0.00940, train_loss: 0.0930, val_loss: 0.4144, val_acc: 0.8930
Epoch [41], last_lr: 0.00929, train_loss: 0.0878, val_loss: 0.3757, val_acc: 0.8981
Epoch [42], last_lr: 0.00917, train_loss: 0.0842, val_loss: 0.4022, val_acc: 0.8973
Epoch [43], last_lr: 0.00904, train_loss: 0.0793, val_loss: 0.4389, val_acc: 0.8925
Epoch [44], last_lr: 0.00891, train_loss: 0.0847, val_loss: 0.3715, val_acc: 0.9050
Epoch [45], last_lr: 0.00876, train_loss: 0.0668, val_loss: 0.3823, val_acc: 0.9059
Epoch [46], last_lr: 0.00861, train_loss: 0.0690, val_loss: 0.4217, val_acc: 0.8927
Epoch [47], last_lr: 0.00845, train_loss: 0.0644, val_loss: 0.4312, val_acc: 0.8980
Epoch [48], last_lr: 0.00829, train_loss: 0.0641, val_loss: 0.4344, val_acc: 0.8983
Epoch [49], last_lr: 0.00811, train_loss: 0.0577, val_loss: 0.4353, val_acc: 0.9016
Epoch [50], last_lr: 0.00794, train_loss: 0.0530, val_loss: 0.3842, val_acc: 0.9076
Epoch [51], last_lr: 0.00775, train_loss: 0.0504, val_loss: 0.4206, val_acc: 0.9062
Epoch [52], last_lr: 0.00756, train_loss: 0.0482, val_loss: 0.5318, val_acc: 0.8927
Epoch [53], last_lr: 0.00737, train_loss: 0.0474, val_loss: 0.3793, val_acc: 0.9113
Epoch [54], last_lr: 0.00717, train_loss: 0.0378, val_loss: 0.4164, val_acc: 0.9095
Epoch [55], last_lr: 0.00696, train_loss: 0.0412, val_loss: 0.3991, val_acc: 0.9098
Epoch [56], last_lr: 0.00675, train_loss: 0.0392, val_loss: 0.4202, val_acc: 0.9042
Epoch [57], last_lr: 0.00654, train_loss: 0.0364, val_loss: 0.3529, val_acc: 0.9208
Epoch [58], last_lr: 0.00633, train_loss: 0.0319, val_loss: 0.4727, val_acc: 0.9038
Epoch [59], last_lr: 0.00611, train_loss: 0.0278, val_loss: 0.3865, val_acc: 0.9182
Epoch [60], last_lr: 0.00589, train_loss: 0.0261, val_loss: 0.4043, val_acc: 0.9165
Epoch [61], last_lr: 0.00567, train_loss: 0.0231, val_loss: 0.3882, val_acc: 0.9191
Epoch [62], last_lr: 0.00544, train_loss: 0.0234, val_loss: 0.3926, val_acc: 0.9194
Epoch [63], last_lr: 0.00522, train_loss: 0.0206, val_loss: 0.4304, val_acc: 0.9156
Epoch [64], last_lr: 0.00500, train_loss: 0.0180, val_loss: 0.3942, val_acc: 0.9224
Epoch [65], last_lr: 0.00477, train_loss: 0.0178, val_loss: 0.3926, val_acc: 0.9229
Epoch [66], last_lr: 0.00455, train_loss: 0.0182, val_loss: 0.4146, val_acc: 0.9211
Epoch [67], last_lr: 0.00432, train_loss: 0.0168, val_loss: 0.3780, val_acc: 0.9256
Epoch [68], last_lr: 0.00410, train_loss: 0.0125, val_loss: 0.3861, val_acc: 0.9260
Epoch [69], last_lr: 0.00388, train_loss: 0.0107, val_loss: 0.4002, val_acc: 0.9256
Epoch [70], last_lr: 0.00367, train_loss: 0.0103, val_loss: 0.3925, val_acc: 0.9274
Epoch [71], last_lr: 0.00345, train_loss: 0.0090, val_loss: 0.4043, val_acc: 0.9267
Epoch [72], last_lr: 0.00324, train_loss: 0.0086, val_loss: 0.4131, val_acc: 0.9268
Epoch [73], last_lr: 0.00303, train_loss: 0.0075, val_loss: 0.4570, val_acc: 0.9235
Epoch [74], last_lr: 0.00283, train_loss: 0.0075, val_loss: 0.4077, val_acc: 0.9283
Epoch [75], last_lr: 0.00263, train_loss: 0.0068, val_loss: 0.4141, val_acc: 0.9279
Epoch [76], last_lr: 0.00243, train_loss: 0.0045, val_loss: 0.3899, val_acc: 0.9329
Epoch [77], last_lr: 0.00224, train_loss: 0.0031, val_loss: 0.4134, val_acc: 0.9316
Epoch [78], last_lr: 0.00206, train_loss: 0.0028, val_loss: 0.3984, val_acc: 0.9340
Epoch [79], last_lr: 0.00188, train_loss: 0.0018, val_loss: 0.4032, val_acc: 0.9340
Epoch [80], last_lr: 0.00171, train_loss: 0.0018, val_loss: 0.4018, val_acc: 0.9354
Epoch [81], last_lr: 0.00154, train_loss: 0.0018, val_loss: 0.4200, val_acc: 0.9331
Epoch [82], last_lr: 0.00138, train_loss: 0.0016, val_loss: 0.4188, val_acc: 0.9324
Epoch [83], last_lr: 0.00123, train_loss: 0.0010, val_loss: 0.4283, val_acc: 0.9329
Epoch [84], last_lr: 0.00109, train_loss: 0.0015, val_loss: 0.4192, val_acc: 0.9339
Epoch [85], last_lr: 0.00095, train_loss: 0.0011, val_loss: 0.4170, val_acc: 0.9343
Epoch [86], last_lr: 0.00082, train_loss: 0.0012, val_loss: 0.4134, val_acc: 0.9332
Epoch [87], last_lr: 0.00071, train_loss: 0.0011, val_loss: 0.4135, val_acc: 0.9345
Epoch [88], last_lr: 0.00059, train_loss: 0.0009, val_loss: 0.4075, val_acc: 0.9360
Epoch [89], last_lr: 0.00049, train_loss: 0.0005, val_loss: 0.4089, val_acc: 0.9352
Epoch [90], last_lr: 0.00040, train_loss: 0.0006, val_loss: 0.4051, val_acc: 0.9361
Epoch [91], last_lr: 0.00032, train_loss: 0.0005, val_loss: 0.4072, val_acc: 0.9363
Epoch [92], last_lr: 0.00024, train_loss: 0.0007, val_loss: 0.4080, val_acc: 0.9365
Epoch [93], last_lr: 0.00018, train_loss: 0.0005, val_loss: 0.4088, val_acc: 0.9367
Epoch [94], last_lr: 0.00012, train_loss: 0.0004, val_loss: 0.4075, val_acc: 0.9359
Epoch [95], last_lr: 0.00008, train_loss: 0.0004, val_loss: 0.4080, val_acc: 0.9359
Epoch [96], last_lr: 0.00004, train_loss: 0.0004, val_loss: 0.4070, val_acc: 0.9362
Epoch [97], last_lr: 0.00002, train_loss: 0.0005, val_loss: 0.4079, val_acc: 0.9364
Epoch [98], last_lr: 0.00000, train_loss: 0.0004, val_loss: 0.4089, val_acc: 0.9368
Epoch [99], last_lr: 0.00000, train_loss: 0.0005, val_loss: 0.4068, val_acc: 0.9373
Saved final model to ./saves/cnn_cifar10_final_ep100_step4900.pth

Epoch [0], last_lr: 0.00043, train_loss: 1.6440, val_loss: 1.4034, val_acc: 0.4874
Epoch [1], last_lr: 0.00051, train_loss: 1.1738, val_loss: 1.1250, val_acc: 0.5967
Epoch [2], last_lr: 0.00064, train_loss: 0.9432, val_loss: 0.9806, val_acc: 0.6598
Epoch [3], last_lr: 0.00082, train_loss: 0.7833, val_loss: 0.9652, val_acc: 0.6605
Epoch [4], last_lr: 0.00104, train_loss: 0.6750, val_loss: 0.8539, val_acc: 0.7163
Epoch [5], last_lr: 0.00132, train_loss: 0.5858, val_loss: 1.0398, val_acc: 0.6960
Epoch [6], last_lr: 0.00163, train_loss: 0.5150, val_loss: 0.6191, val_acc: 0.7965
Epoch [7], last_lr: 0.00199, train_loss: 0.4750, val_loss: 1.3620, val_acc: 0.6519
Epoch [8], last_lr: 0.00238, train_loss: 0.4365, val_loss: 0.7987, val_acc: 0.7551
Epoch [9], last_lr: 0.00280, train_loss: 0.3966, val_loss: 0.7438, val_acc: 0.7696
Epoch [10], last_lr: 0.00325, train_loss: 0.3648, val_loss: 0.7248, val_acc: 0.7905
Epoch [11], last_lr: 0.00372, train_loss: 0.3387, val_loss: 0.7648, val_acc: 0.7775
Epoch [12], last_lr: 0.00421, train_loss: 0.3193, val_loss: 0.4653, val_acc: 0.8433
Epoch [13], last_lr: 0.00470, train_loss: 0.3107, val_loss: 0.6815, val_acc: 0.7985
Epoch [14], last_lr: 0.00521, train_loss: 0.2885, val_loss: 0.8251, val_acc: 0.7689
Epoch [15], last_lr: 0.00571, train_loss: 0.2673, val_loss: 0.4812, val_acc: 0.8540
Epoch [16], last_lr: 0.00620, train_loss: 0.2538, val_loss: 0.4370, val_acc: 0.8637
Epoch [17], last_lr: 0.00669, train_loss: 0.2453, val_loss: 0.5048, val_acc: 0.8479
Epoch [18], last_lr: 0.00716, train_loss: 0.2241, val_loss: 0.4381, val_acc: 0.8650
Epoch [19], last_lr: 0.00761, train_loss: 0.2118, val_loss: 0.5545, val_acc: 0.8412
Epoch [20], last_lr: 0.00803, train_loss: 0.2004, val_loss: 0.5249, val_acc: 0.8564
Epoch [21], last_lr: 0.00842, train_loss: 0.1873, val_loss: 0.5878, val_acc: 0.8375
Epoch [22], last_lr: 0.00877, train_loss: 0.1799, val_loss: 0.5761, val_acc: 0.8482
Epoch [23], last_lr: 0.00909, train_loss: 0.1640, val_loss: 0.5780, val_acc: 0.8378
Epoch [24], last_lr: 0.00936, train_loss: 0.1606, val_loss: 0.3663, val_acc: 0.8953
Epoch [25], last_lr: 0.00959, train_loss: 0.1450, val_loss: 0.3594, val_acc: 0.8923
Epoch [26], last_lr: 0.00977, train_loss: 0.1416, val_loss: 0.3751, val_acc: 0.8899
Epoch [27], last_lr: 0.00990, train_loss: 0.1293, val_loss: 0.5043, val_acc: 0.8651
Epoch [28], last_lr: 0.00997, train_loss: 0.1181, val_loss: 0.3824, val_acc: 0.8937
Epoch [29], last_lr: 0.01000, train_loss: 0.1131, val_loss: 0.3816, val_acc: 0.8924
Epoch [30], last_lr: 0.00999, train_loss: 0.0995, val_loss: 0.4055, val_acc: 0.8949
Epoch [31], last_lr: 0.00998, train_loss: 0.0983, val_loss: 0.4478, val_acc: 0.8882
Epoch [32], last_lr: 0.00995, train_loss: 0.0927, val_loss: 0.3643, val_acc: 0.9042
Epoch [33], last_lr: 0.00992, train_loss: 0.0824, val_loss: 0.3845, val_acc: 0.9014
Epoch [34], last_lr: 0.00987, train_loss: 0.0764, val_loss: 0.3585, val_acc: 0.9050
Epoch [35], last_lr: 0.00982, train_loss: 0.0744, val_loss: 0.4372, val_acc: 0.8952
Epoch [36], last_lr: 0.00975, train_loss: 0.0729, val_loss: 0.4295, val_acc: 0.9003
Epoch [37], last_lr: 0.00968, train_loss: 0.0717, val_loss: 0.3871, val_acc: 0.9044
Epoch [38], last_lr: 0.00960, train_loss: 0.0602, val_loss: 0.3376, val_acc: 0.9201
Epoch [39], last_lr: 0.00950, train_loss: 0.0629, val_loss: 0.3570, val_acc: 0.9097
Epoch [40], last_lr: 0.00940, train_loss: 0.0574, val_loss: 0.3512, val_acc: 0.9108
Epoch [41], last_lr: 0.00929, train_loss: 0.0474, val_loss: 0.4548, val_acc: 0.9007
Epoch [42], last_lr: 0.00917, train_loss: 0.0504, val_loss: 0.4028, val_acc: 0.9055
Epoch [43], last_lr: 0.00904, train_loss: 0.0437, val_loss: 0.3554, val_acc: 0.9157
Epoch [44], last_lr: 0.00891, train_loss: 0.0461, val_loss: 0.3667, val_acc: 0.9147
Epoch [45], last_lr: 0.00876, train_loss: 0.0467, val_loss: 0.3800, val_acc: 0.9164
Epoch [46], last_lr: 0.00861, train_loss: 0.0365, val_loss: 0.3954, val_acc: 0.9156
Epoch [47], last_lr: 0.00845, train_loss: 0.0330, val_loss: 0.4009, val_acc: 0.9153
Epoch [48], last_lr: 0.00829, train_loss: 0.0362, val_loss: 0.4229, val_acc: 0.9092
Epoch [49], last_lr: 0.00811, train_loss: 0.0335, val_loss: 0.3612, val_acc: 0.9194
Epoch [50], last_lr: 0.00794, train_loss: 0.0290, val_loss: 0.4345, val_acc: 0.9102
Epoch [51], last_lr: 0.00775, train_loss: 0.0257, val_loss: 0.3752, val_acc: 0.9253
Epoch [52], last_lr: 0.00756, train_loss: 0.0201, val_loss: 0.3843, val_acc: 0.9215
Epoch [53], last_lr: 0.00737, train_loss: 0.0229, val_loss: 0.4087, val_acc: 0.9214
Epoch [54], last_lr: 0.00717, train_loss: 0.0248, val_loss: 0.3498, val_acc: 0.9263
Epoch [55], last_lr: 0.00696, train_loss: 0.0224, val_loss: 0.4214, val_acc: 0.9173
Epoch [56], last_lr: 0.00675, train_loss: 0.0231, val_loss: 0.3811, val_acc: 0.9257
Epoch [57], last_lr: 0.00654, train_loss: 0.0204, val_loss: 0.3438, val_acc: 0.9287
Epoch [58], last_lr: 0.00633, train_loss: 0.0176, val_loss: 0.3877, val_acc: 0.9240
Epoch [59], last_lr: 0.00611, train_loss: 0.0204, val_loss: 0.3933, val_acc: 0.9265
Epoch [60], last_lr: 0.00589, train_loss: 0.0163, val_loss: 0.4501, val_acc: 0.9138
Epoch [61], last_lr: 0.00567, train_loss: 0.0141, val_loss: 0.3862, val_acc: 0.9285
Epoch [62], last_lr: 0.00544, train_loss: 0.0110, val_loss: 0.4124, val_acc: 0.9267
Epoch [63], last_lr: 0.00522, train_loss: 0.0113, val_loss: 0.3897, val_acc: 0.9276
Epoch [64], last_lr: 0.00500, train_loss: 0.0107, val_loss: 0.4067, val_acc: 0.9281
Epoch [65], last_lr: 0.00477, train_loss: 0.0084, val_loss: 0.3727, val_acc: 0.9340
Epoch [66], last_lr: 0.00455, train_loss: 0.0073, val_loss: 0.3735, val_acc: 0.9335
Epoch [67], last_lr: 0.00432, train_loss: 0.0061, val_loss: 0.3605, val_acc: 0.9368
Epoch [68], last_lr: 0.00410, train_loss: 0.0051, val_loss: 0.3609, val_acc: 0.9372
Epoch [69], last_lr: 0.00388, train_loss: 0.0040, val_loss: 0.3697, val_acc: 0.9360
Epoch [70], last_lr: 0.00367, train_loss: 0.0033, val_loss: 0.3671, val_acc: 0.9391
Epoch [71], last_lr: 0.00345, train_loss: 0.0039, val_loss: 0.3982, val_acc: 0.9349
Epoch [72], last_lr: 0.00324, train_loss: 0.0023, val_loss: 0.3617, val_acc: 0.9403
Epoch [73], last_lr: 0.00303, train_loss: 0.0022, val_loss: 0.3791, val_acc: 0.9402
Epoch [74], last_lr: 0.00283, train_loss: 0.0020, val_loss: 0.3875, val_acc: 0.9377
Epoch [75], last_lr: 0.00263, train_loss: 0.0018, val_loss: 0.3727, val_acc: 0.9378
Epoch [76], last_lr: 0.00243, train_loss: 0.0010, val_loss: 0.3726, val_acc: 0.9396
Epoch [77], last_lr: 0.00224, train_loss: 0.0008, val_loss: 0.3724, val_acc: 0.9401
Epoch [78], last_lr: 0.00206, train_loss: 0.0010, val_loss: 0.3749, val_acc: 0.9390
Epoch [79], last_lr: 0.00188, train_loss: 0.0012, val_loss: 0.3685, val_acc: 0.9409
Epoch [80], last_lr: 0.00171, train_loss: 0.0009, val_loss: 0.3688, val_acc: 0.9417
Epoch [81], last_lr: 0.00154, train_loss: 0.0007, val_loss: 0.3812, val_acc: 0.9402
Epoch [82], last_lr: 0.00138, train_loss: 0.0008, val_loss: 0.3853, val_acc: 0.9401
Epoch [83], last_lr: 0.00123, train_loss: 0.0008, val_loss: 0.3786, val_acc: 0.9393
Epoch [84], last_lr: 0.00109, train_loss: 0.0004, val_loss: 0.3742, val_acc: 0.9399
Epoch [85], last_lr: 0.00095, train_loss: 0.0006, val_loss: 0.3742, val_acc: 0.9397
Epoch [86], last_lr: 0.00082, train_loss: 0.0003, val_loss: 0.3757, val_acc: 0.9397
Epoch [87], last_lr: 0.00071, train_loss: 0.0005, val_loss: 0.3737, val_acc: 0.9394
Epoch [88], last_lr: 0.00059, train_loss: 0.0004, val_loss: 0.3776, val_acc: 0.9403
Epoch [89], last_lr: 0.00049, train_loss: 0.0005, val_loss: 0.3771, val_acc: 0.9409
Epoch [90], last_lr: 0.00040, train_loss: 0.0003, val_loss: 0.3770, val_acc: 0.9418
Epoch [91], last_lr: 0.00032, train_loss: 0.0002, val_loss: 0.3748, val_acc: 0.9421
Epoch [92], last_lr: 0.00024, train_loss: 0.0003, val_loss: 0.3735, val_acc: 0.9420
Epoch [93], last_lr: 0.00018, train_loss: 0.0003, val_loss: 0.3739, val_acc: 0.9417
Epoch [94], last_lr: 0.00012, train_loss: 0.0002, val_loss: 0.3741, val_acc: 0.9414
Epoch [95], last_lr: 0.00008, train_loss: 0.0003, val_loss: 0.3742, val_acc: 0.9418
Epoch [96], last_lr: 0.00004, train_loss: 0.0002, val_loss: 0.3760, val_acc: 0.9427
Epoch [97], last_lr: 0.00002, train_loss: 0.0003, val_loss: 0.3758, val_acc: 0.9418
Epoch [98], last_lr: 0.00000, train_loss: 0.0002, val_loss: 0.3753, val_acc: 0.9420
Epoch [99], last_lr: 0.00000, train_loss: 0.0002, val_loss: 0.3739, val_acc: 0.9418
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

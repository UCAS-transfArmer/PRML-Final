Epoch [0], last_lr: 0.00043, train_loss: 2.1272, val_loss: 3.4926, val_acc: 0.1957
Epoch [1], last_lr: 0.00051, train_loss: 1.8768, val_loss: 1.9316, val_acc: 0.2779
Epoch [2], last_lr: 0.00064, train_loss: 1.7645, val_loss: 1.9644, val_acc: 0.3216
Epoch [3], last_lr: 0.00082, train_loss: 1.6758, val_loss: 2.1395, val_acc: 0.3425
Epoch [4], last_lr: 0.00104, train_loss: 1.6039, val_loss: 1.7279, val_acc: 0.3709
Epoch [5], last_lr: 0.00132, train_loss: 1.5195, val_loss: 1.7385, val_acc: 0.3538
Epoch [6], last_lr: 0.00163, train_loss: 1.4442, val_loss: 2.0461, val_acc: 0.3869
Epoch [7], last_lr: 0.00199, train_loss: 1.3553, val_loss: 1.5639, val_acc: 0.4986
Epoch [8], last_lr: 0.00238, train_loss: 1.2767, val_loss: 2.4493, val_acc: 0.4271
Epoch [9], last_lr: 0.00280, train_loss: 1.2117, val_loss: 1.5528, val_acc: 0.4962
Epoch [10], last_lr: 0.00325, train_loss: 1.1441, val_loss: 1.7729, val_acc: 0.5042
Epoch [11], last_lr: 0.00372, train_loss: 1.0994, val_loss: 1.4113, val_acc: 0.5555
Epoch [12], last_lr: 0.00421, train_loss: 1.0487, val_loss: 1.5825, val_acc: 0.4951
Epoch [13], last_lr: 0.00470, train_loss: 1.0048, val_loss: 2.8297, val_acc: 0.4337
Epoch [14], last_lr: 0.00521, train_loss: 0.9954, val_loss: 2.0827, val_acc: 0.4877
Epoch [15], last_lr: 0.00571, train_loss: 0.9428, val_loss: 1.5811, val_acc: 0.5556
Epoch [16], last_lr: 0.00620, train_loss: 0.9064, val_loss: 1.2658, val_acc: 0.5976
Epoch [17], last_lr: 0.00669, train_loss: 0.8790, val_loss: 1.4068, val_acc: 0.6050
Epoch [18], last_lr: 0.00716, train_loss: 0.8420, val_loss: 0.9807, val_acc: 0.6800
Epoch [19], last_lr: 0.00761, train_loss: 0.8104, val_loss: 1.3830, val_acc: 0.6305
Epoch [20], last_lr: 0.00803, train_loss: 0.8008, val_loss: 1.1940, val_acc: 0.6482
Epoch [21], last_lr: 0.00842, train_loss: 0.7618, val_loss: 2.0553, val_acc: 0.5366
Epoch [22], last_lr: 0.00877, train_loss: 0.7341, val_loss: 1.1911, val_acc: 0.6501
Epoch [23], last_lr: 0.00909, train_loss: 0.7170, val_loss: 1.0147, val_acc: 0.6822
Epoch [24], last_lr: 0.00936, train_loss: 0.6804, val_loss: 1.2937, val_acc: 0.6191
Epoch [25], last_lr: 0.00959, train_loss: 0.6802, val_loss: 1.3443, val_acc: 0.6549
Epoch [26], last_lr: 0.00977, train_loss: 0.6398, val_loss: 0.8129, val_acc: 0.7405
Epoch [27], last_lr: 0.00990, train_loss: 0.6177, val_loss: 1.1236, val_acc: 0.6715
Epoch [28], last_lr: 0.00997, train_loss: 0.6196, val_loss: 1.6652, val_acc: 0.6226
Epoch [29], last_lr: 0.01000, train_loss: 0.5904, val_loss: 0.7432, val_acc: 0.7693
Epoch [30], last_lr: 0.00999, train_loss: 0.5510, val_loss: 1.0828, val_acc: 0.6638
Epoch [31], last_lr: 0.00998, train_loss: 0.5434, val_loss: 1.1597, val_acc: 0.6894
Epoch [32], last_lr: 0.00995, train_loss: 0.5141, val_loss: 0.6521, val_acc: 0.7837
Epoch [33], last_lr: 0.00992, train_loss: 0.5020, val_loss: 0.9653, val_acc: 0.7273
Epoch [34], last_lr: 0.00987, train_loss: 0.4900, val_loss: 0.7554, val_acc: 0.7636
Epoch [35], last_lr: 0.00982, train_loss: 0.4690, val_loss: 0.6981, val_acc: 0.7874
Epoch [36], last_lr: 0.00975, train_loss: 0.4555, val_loss: 0.8240, val_acc: 0.7694
Epoch [37], last_lr: 0.00968, train_loss: 0.4441, val_loss: 0.7824, val_acc: 0.7660
Epoch [38], last_lr: 0.00960, train_loss: 0.4206, val_loss: 0.8002, val_acc: 0.7677
Epoch [39], last_lr: 0.00950, train_loss: 0.4057, val_loss: 0.8128, val_acc: 0.7654
Epoch [40], last_lr: 0.00940, train_loss: 0.3973, val_loss: 0.8132, val_acc: 0.7570
Epoch [41], last_lr: 0.00929, train_loss: 0.3735, val_loss: 0.7560, val_acc: 0.7898
Epoch [42], last_lr: 0.00917, train_loss: 0.3672, val_loss: 0.5577, val_acc: 0.8276
Epoch [43], last_lr: 0.00904, train_loss: 0.3536, val_loss: 0.9292, val_acc: 0.7387
Epoch [44], last_lr: 0.00891, train_loss: 0.3434, val_loss: 0.6427, val_acc: 0.8135
Epoch [45], last_lr: 0.00876, train_loss: 0.3362, val_loss: 0.6516, val_acc: 0.8106
Epoch [46], last_lr: 0.00861, train_loss: 0.3320, val_loss: 0.6571, val_acc: 0.8088
Epoch [47], last_lr: 0.00845, train_loss: 0.3093, val_loss: 0.8163, val_acc: 0.7831
Epoch [48], last_lr: 0.00829, train_loss: 0.2974, val_loss: 0.5695, val_acc: 0.8280
Epoch [49], last_lr: 0.00811, train_loss: 0.2926, val_loss: 0.6152, val_acc: 0.8179
Epoch [50], last_lr: 0.00794, train_loss: 0.2915, val_loss: 0.5094, val_acc: 0.8451
Epoch [51], last_lr: 0.00775, train_loss: 0.2710, val_loss: 0.5990, val_acc: 0.8240
Epoch [52], last_lr: 0.00756, train_loss: 0.2691, val_loss: 0.4980, val_acc: 0.8449
Epoch [53], last_lr: 0.00737, train_loss: 0.2540, val_loss: 0.5595, val_acc: 0.8295
Epoch [54], last_lr: 0.00717, train_loss: 0.2455, val_loss: 0.5996, val_acc: 0.8267
Epoch [55], last_lr: 0.00696, train_loss: 0.2405, val_loss: 0.5929, val_acc: 0.8309
Epoch [56], last_lr: 0.00675, train_loss: 0.2312, val_loss: 0.5473, val_acc: 0.8399
Epoch [57], last_lr: 0.00654, train_loss: 0.2241, val_loss: 0.6072, val_acc: 0.8277
Epoch [58], last_lr: 0.00633, train_loss: 0.2242, val_loss: 0.4917, val_acc: 0.8581
Epoch [59], last_lr: 0.00611, train_loss: 0.2005, val_loss: 0.5335, val_acc: 0.8487
Epoch [60], last_lr: 0.00589, train_loss: 0.1868, val_loss: 0.5426, val_acc: 0.8560
Epoch [61], last_lr: 0.00567, train_loss: 0.1824, val_loss: 0.5351, val_acc: 0.8483
Epoch [62], last_lr: 0.00544, train_loss: 0.1871, val_loss: 0.6143, val_acc: 0.8359
Epoch [63], last_lr: 0.00522, train_loss: 0.1782, val_loss: 0.5349, val_acc: 0.8488
Epoch [64], last_lr: 0.00500, train_loss: 0.1608, val_loss: 0.5423, val_acc: 0.8527
Epoch [65], last_lr: 0.00477, train_loss: 0.1547, val_loss: 0.5690, val_acc: 0.8488
Epoch [66], last_lr: 0.00455, train_loss: 0.1373, val_loss: 0.5811, val_acc: 0.8464
Epoch [67], last_lr: 0.00432, train_loss: 0.1356, val_loss: 0.5449, val_acc: 0.8610
Epoch [68], last_lr: 0.00410, train_loss: 0.1360, val_loss: 0.5149, val_acc: 0.8564
Epoch [69], last_lr: 0.00388, train_loss: 0.1207, val_loss: 0.5120, val_acc: 0.8610
Epoch [70], last_lr: 0.00367, train_loss: 0.1165, val_loss: 0.5774, val_acc: 0.8567
Epoch [71], last_lr: 0.00345, train_loss: 0.1051, val_loss: 0.5110, val_acc: 0.8691
Epoch [72], last_lr: 0.00324, train_loss: 0.0993, val_loss: 0.5579, val_acc: 0.8617
Epoch [73], last_lr: 0.00303, train_loss: 0.0922, val_loss: 0.5282, val_acc: 0.8684
Epoch [74], last_lr: 0.00283, train_loss: 0.0896, val_loss: 0.5484, val_acc: 0.8669
Epoch [75], last_lr: 0.00263, train_loss: 0.0801, val_loss: 0.5222, val_acc: 0.8754
Epoch [76], last_lr: 0.00243, train_loss: 0.0702, val_loss: 0.5759, val_acc: 0.8715
Epoch [77], last_lr: 0.00224, train_loss: 0.0670, val_loss: 0.5412, val_acc: 0.8764
Epoch [78], last_lr: 0.00206, train_loss: 0.0643, val_loss: 0.5752, val_acc: 0.8708
Epoch [79], last_lr: 0.00188, train_loss: 0.0571, val_loss: 0.5332, val_acc: 0.8799
Epoch [80], last_lr: 0.00171, train_loss: 0.0497, val_loss: 0.5396, val_acc: 0.8779
Epoch [81], last_lr: 0.00154, train_loss: 0.0477, val_loss: 0.5845, val_acc: 0.8741
Epoch [82], last_lr: 0.00138, train_loss: 0.0418, val_loss: 0.5943, val_acc: 0.8762
Epoch [83], last_lr: 0.00123, train_loss: 0.0384, val_loss: 0.6013, val_acc: 0.8777
Epoch [84], last_lr: 0.00109, train_loss: 0.0361, val_loss: 0.5807, val_acc: 0.8832
Epoch [85], last_lr: 0.00095, train_loss: 0.0313, val_loss: 0.5850, val_acc: 0.8814
Epoch [86], last_lr: 0.00082, train_loss: 0.0292, val_loss: 0.5666, val_acc: 0.8861
Epoch [87], last_lr: 0.00071, train_loss: 0.0257, val_loss: 0.5855, val_acc: 0.8827
Epoch [88], last_lr: 0.00059, train_loss: 0.0237, val_loss: 0.5928, val_acc: 0.8827
Epoch [89], last_lr: 0.00049, train_loss: 0.0210, val_loss: 0.5970, val_acc: 0.8828
Epoch [90], last_lr: 0.00040, train_loss: 0.0202, val_loss: 0.5935, val_acc: 0.8838
Epoch [91], last_lr: 0.00032, train_loss: 0.0174, val_loss: 0.5971, val_acc: 0.8834
Epoch [92], last_lr: 0.00024, train_loss: 0.0161, val_loss: 0.6130, val_acc: 0.8831
Epoch [93], last_lr: 0.00018, train_loss: 0.0169, val_loss: 0.6083, val_acc: 0.8838
Epoch [94], last_lr: 0.00012, train_loss: 0.0153, val_loss: 0.6154, val_acc: 0.8845
Epoch [95], last_lr: 0.00008, train_loss: 0.0139, val_loss: 0.6145, val_acc: 0.8849
Epoch [96], last_lr: 0.00004, train_loss: 0.0140, val_loss: 0.6140, val_acc: 0.8841
Epoch [97], last_lr: 0.00002, train_loss: 0.0141, val_loss: 0.6146, val_acc: 0.8853
Epoch [98], last_lr: 0.00000, train_loss: 0.0129, val_loss: 0.6151, val_acc: 0.8848
Epoch [99], last_lr: 0.00000, train_loss: 0.0136, val_loss: 0.6167, val_acc: 0.8847
Saved final model to ./saves/cnn_cifar10_final_ep100_step4900.pth

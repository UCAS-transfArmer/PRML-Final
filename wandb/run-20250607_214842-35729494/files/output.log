Epoch [0], last_lr: 0.00263, train_loss: 2.2382, val_loss: 2.5037, val_acc: 0.1997
Epoch [1], last_lr: 0.00302, train_loss: 1.8809, val_loss: 1.8292, val_acc: 0.3135
Epoch [2], last_lr: 0.00366, train_loss: 1.6865, val_loss: 1.5870, val_acc: 0.3970
Epoch [3], last_lr: 0.00456, train_loss: 1.5037, val_loss: 1.4161, val_acc: 0.4787
Epoch [4], last_lr: 0.00569, train_loss: 1.3112, val_loss: 1.3829, val_acc: 0.5159
Epoch [5], last_lr: 0.00704, train_loss: 1.1738, val_loss: 1.1881, val_acc: 0.5799
Epoch [6], last_lr: 0.00861, train_loss: 1.0355, val_loss: 1.0617, val_acc: 0.6262
Epoch [7], last_lr: 0.01037, train_loss: 0.9255, val_loss: 1.0533, val_acc: 0.6518
Epoch [8], last_lr: 0.01230, train_loss: 0.8314, val_loss: 0.8662, val_acc: 0.7000
Epoch [9], last_lr: 0.01439, train_loss: 0.7552, val_loss: 0.7792, val_acc: 0.7254
Epoch [10], last_lr: 0.01661, train_loss: 0.6856, val_loss: 0.8046, val_acc: 0.7277
Epoch [11], last_lr: 0.01893, train_loss: 0.6140, val_loss: 1.0480, val_acc: 0.6892
Epoch [12], last_lr: 0.02133, train_loss: 0.5528, val_loss: 0.9163, val_acc: 0.7126
Epoch [13], last_lr: 0.02379, train_loss: 0.4920, val_loss: 0.7499, val_acc: 0.7632
Epoch [14], last_lr: 0.02628, train_loss: 0.4408, val_loss: 0.5865, val_acc: 0.8063
Epoch [15], last_lr: 0.02876, train_loss: 0.4047, val_loss: 0.5580, val_acc: 0.8101
Epoch [16], last_lr: 0.03122, train_loss: 0.3739, val_loss: 0.5446, val_acc: 0.8205
Epoch [17], last_lr: 0.03362, train_loss: 0.3405, val_loss: 0.4732, val_acc: 0.8483
Epoch [18], last_lr: 0.03594, train_loss: 0.3226, val_loss: 0.4798, val_acc: 0.8421
Epoch [19], last_lr: 0.03815, train_loss: 0.2987, val_loss: 0.8566, val_acc: 0.7765
Epoch [20], last_lr: 0.04024, train_loss: 0.2833, val_loss: 0.6233, val_acc: 0.8143
Epoch [21], last_lr: 0.04217, train_loss: 0.2686, val_loss: 0.4408, val_acc: 0.8579
Epoch [22], last_lr: 0.04393, train_loss: 0.2477, val_loss: 0.6098, val_acc: 0.8193
Epoch [23], last_lr: 0.04549, train_loss: 0.2355, val_loss: 0.4658, val_acc: 0.8556
Epoch [24], last_lr: 0.04684, train_loss: 0.2152, val_loss: 0.6174, val_acc: 0.8240
Epoch [25], last_lr: 0.04796, train_loss: 0.2040, val_loss: 0.5109, val_acc: 0.8536
Epoch [26], last_lr: 0.04885, train_loss: 0.2013, val_loss: 0.5923, val_acc: 0.8314
Epoch [27], last_lr: 0.04949, train_loss: 0.1830, val_loss: 0.4424, val_acc: 0.8784
Epoch [28], last_lr: 0.04987, train_loss: 0.1723, val_loss: 0.6623, val_acc: 0.8200
Epoch [29], last_lr: 0.05000, train_loss: 0.1613, val_loss: 0.4542, val_acc: 0.8750
Epoch [30], last_lr: 0.04997, train_loss: 0.1499, val_loss: 0.5585, val_acc: 0.8511
Epoch [31], last_lr: 0.04990, train_loss: 0.1379, val_loss: 0.4443, val_acc: 0.8737
Epoch [32], last_lr: 0.04977, train_loss: 0.1340, val_loss: 0.4060, val_acc: 0.8840
Epoch [33], last_lr: 0.04959, train_loss: 0.1223, val_loss: 0.4064, val_acc: 0.8907
Epoch [34], last_lr: 0.04937, train_loss: 0.1142, val_loss: 0.5823, val_acc: 0.8524
Epoch [35], last_lr: 0.04909, train_loss: 0.1091, val_loss: 0.4753, val_acc: 0.8741
Epoch [36], last_lr: 0.04877, train_loss: 0.0992, val_loss: 0.4584, val_acc: 0.8777
Epoch [37], last_lr: 0.04840, train_loss: 0.1021, val_loss: 0.4911, val_acc: 0.8699
Epoch [38], last_lr: 0.04798, train_loss: 0.0957, val_loss: 0.3800, val_acc: 0.9010
Epoch [39], last_lr: 0.04751, train_loss: 0.0896, val_loss: 0.4786, val_acc: 0.8888
Epoch [40], last_lr: 0.04700, train_loss: 0.0818, val_loss: 0.3813, val_acc: 0.9044
Epoch [41], last_lr: 0.04645, train_loss: 0.0715, val_loss: 0.5133, val_acc: 0.8825
Epoch [42], last_lr: 0.04585, train_loss: 0.0750, val_loss: 0.5788, val_acc: 0.8736
Epoch [43], last_lr: 0.04521, train_loss: 0.0776, val_loss: 0.4534, val_acc: 0.8920
Epoch [44], last_lr: 0.04453, train_loss: 0.0647, val_loss: 0.4022, val_acc: 0.9031
Epoch [45], last_lr: 0.04381, train_loss: 0.0621, val_loss: 0.4774, val_acc: 0.8912
Epoch [46], last_lr: 0.04305, train_loss: 0.0610, val_loss: 0.4599, val_acc: 0.9014
Epoch [47], last_lr: 0.04226, train_loss: 0.0565, val_loss: 0.3710, val_acc: 0.9162
Epoch [48], last_lr: 0.04143, train_loss: 0.0478, val_loss: 0.4030, val_acc: 0.9066
Epoch [49], last_lr: 0.04057, train_loss: 0.0498, val_loss: 0.3909, val_acc: 0.9100
Epoch [50], last_lr: 0.03968, train_loss: 0.0444, val_loss: 0.4093, val_acc: 0.9068
Epoch [51], last_lr: 0.03875, train_loss: 0.0419, val_loss: 0.4566, val_acc: 0.9039
Epoch [52], last_lr: 0.03780, train_loss: 0.0393, val_loss: 0.4081, val_acc: 0.9147
Epoch [53], last_lr: 0.03683, train_loss: 0.0450, val_loss: 0.5596, val_acc: 0.8917
Epoch [54], last_lr: 0.03583, train_loss: 0.0350, val_loss: 0.4123, val_acc: 0.9163
Epoch [55], last_lr: 0.03480, train_loss: 0.0361, val_loss: 0.4105, val_acc: 0.9154
Epoch [56], last_lr: 0.03376, train_loss: 0.0282, val_loss: 0.3723, val_acc: 0.9251
Epoch [57], last_lr: 0.03270, train_loss: 0.0297, val_loss: 0.4210, val_acc: 0.9138
Epoch [58], last_lr: 0.03163, train_loss: 0.0236, val_loss: 0.3622, val_acc: 0.9263
Epoch [59], last_lr: 0.03054, train_loss: 0.0229, val_loss: 0.3661, val_acc: 0.9225
Epoch [60], last_lr: 0.02944, train_loss: 0.0230, val_loss: 0.4306, val_acc: 0.9171
Epoch [61], last_lr: 0.02833, train_loss: 0.0190, val_loss: 0.4164, val_acc: 0.9194
Epoch [62], last_lr: 0.02722, train_loss: 0.0171, val_loss: 0.3917, val_acc: 0.9277
Epoch [63], last_lr: 0.02610, train_loss: 0.0165, val_loss: 0.4129, val_acc: 0.9250
Epoch [64], last_lr: 0.02498, train_loss: 0.0167, val_loss: 0.3702, val_acc: 0.9292
Epoch [65], last_lr: 0.02386, train_loss: 0.0126, val_loss: 0.3551, val_acc: 0.9319
Epoch [66], last_lr: 0.02274, train_loss: 0.0102, val_loss: 0.4315, val_acc: 0.9276
Epoch [67], last_lr: 0.02162, train_loss: 0.0115, val_loss: 0.4032, val_acc: 0.9289
Epoch [68], last_lr: 0.02051, train_loss: 0.0107, val_loss: 0.4081, val_acc: 0.9276
Epoch [69], last_lr: 0.01941, train_loss: 0.0108, val_loss: 0.3927, val_acc: 0.9294
Epoch [70], last_lr: 0.01833, train_loss: 0.0093, val_loss: 0.3836, val_acc: 0.9333
Epoch [71], last_lr: 0.01725, train_loss: 0.0069, val_loss: 0.3902, val_acc: 0.9341
Epoch [72], last_lr: 0.01619, train_loss: 0.0058, val_loss: 0.4099, val_acc: 0.9310
Epoch [73], last_lr: 0.01515, train_loss: 0.0056, val_loss: 0.3957, val_acc: 0.9348
Epoch [74], last_lr: 0.01413, train_loss: 0.0046, val_loss: 0.3788, val_acc: 0.9364
Epoch [75], last_lr: 0.01313, train_loss: 0.0035, val_loss: 0.3940, val_acc: 0.9351
Epoch [76], last_lr: 0.01216, train_loss: 0.0028, val_loss: 0.4017, val_acc: 0.9368
Epoch [77], last_lr: 0.01121, train_loss: 0.0025, val_loss: 0.4007, val_acc: 0.9391
Epoch [78], last_lr: 0.01029, train_loss: 0.0024, val_loss: 0.4015, val_acc: 0.9387
Epoch [79], last_lr: 0.00940, train_loss: 0.0021, val_loss: 0.4063, val_acc: 0.9396
Epoch [80], last_lr: 0.00853, train_loss: 0.0017, val_loss: 0.3967, val_acc: 0.9404
Epoch [81], last_lr: 0.00771, train_loss: 0.0012, val_loss: 0.4024, val_acc: 0.9389
Epoch [82], last_lr: 0.00691, train_loss: 0.0007, val_loss: 0.4022, val_acc: 0.9417
Epoch [83], last_lr: 0.00616, train_loss: 0.0010, val_loss: 0.4104, val_acc: 0.9412
Epoch [84], last_lr: 0.00544, train_loss: 0.0008, val_loss: 0.4116, val_acc: 0.9420
Epoch [85], last_lr: 0.00476, train_loss: 0.0009, val_loss: 0.4096, val_acc: 0.9405
Epoch [86], last_lr: 0.00412, train_loss: 0.0007, val_loss: 0.4089, val_acc: 0.9406
Epoch [87], last_lr: 0.00353, train_loss: 0.0007, val_loss: 0.4157, val_acc: 0.9413
Epoch [88], last_lr: 0.00297, train_loss: 0.0007, val_loss: 0.4155, val_acc: 0.9401
Epoch [89], last_lr: 0.00247, train_loss: 0.0005, val_loss: 0.4142, val_acc: 0.9410
Epoch [90], last_lr: 0.00200, train_loss: 0.0005, val_loss: 0.4142, val_acc: 0.9421
Epoch [91], last_lr: 0.00159, train_loss: 0.0004, val_loss: 0.4128, val_acc: 0.9419
Epoch [92], last_lr: 0.00122, train_loss: 0.0006, val_loss: 0.4134, val_acc: 0.9413
Epoch [93], last_lr: 0.00090, train_loss: 0.0005, val_loss: 0.4125, val_acc: 0.9423
Epoch [94], last_lr: 0.00062, train_loss: 0.0004, val_loss: 0.4133, val_acc: 0.9415
Epoch [95], last_lr: 0.00040, train_loss: 0.0004, val_loss: 0.4142, val_acc: 0.9415
Epoch [96], last_lr: 0.00022, train_loss: 0.0004, val_loss: 0.4146, val_acc: 0.9418
Epoch [97], last_lr: 0.00010, train_loss: 0.0003, val_loss: 0.4149, val_acc: 0.9419
Epoch [98], last_lr: 0.00002, train_loss: 0.0003, val_loss: 0.4148, val_acc: 0.9407
Epoch [99], last_lr: 0.00000, train_loss: 0.0005, val_loss: 0.4150, val_acc: 0.9418
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

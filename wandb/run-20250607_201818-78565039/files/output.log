Epoch [0], last_lr: 0.00158, train_loss: 1.8779, val_loss: 1.9306, val_acc: 0.3234
Epoch [1], last_lr: 0.00181, train_loss: 1.4800, val_loss: 1.4469, val_acc: 0.4711
Epoch [2], last_lr: 0.00220, train_loss: 1.2482, val_loss: 1.2757, val_acc: 0.5351
Epoch [3], last_lr: 0.00273, train_loss: 1.0480, val_loss: 1.2030, val_acc: 0.5921
Epoch [4], last_lr: 0.00341, train_loss: 0.9307, val_loss: 0.9305, val_acc: 0.6678
Epoch [5], last_lr: 0.00423, train_loss: 0.8290, val_loss: 1.0274, val_acc: 0.6564
Epoch [6], last_lr: 0.00516, train_loss: 0.7482, val_loss: 1.0509, val_acc: 0.6491
Epoch [7], last_lr: 0.00622, train_loss: 0.6741, val_loss: 1.0163, val_acc: 0.6920
Epoch [8], last_lr: 0.00738, train_loss: 0.5904, val_loss: 0.8571, val_acc: 0.7248
Epoch [9], last_lr: 0.00863, train_loss: 0.5459, val_loss: 0.7754, val_acc: 0.7511
Epoch [10], last_lr: 0.00996, train_loss: 0.4995, val_loss: 0.8665, val_acc: 0.7271
Epoch [11], last_lr: 0.01136, train_loss: 0.4437, val_loss: 0.7144, val_acc: 0.7859
Epoch [12], last_lr: 0.01280, train_loss: 0.4062, val_loss: 0.5575, val_acc: 0.8212
Epoch [13], last_lr: 0.01427, train_loss: 0.3778, val_loss: 0.5342, val_acc: 0.8250
Epoch [14], last_lr: 0.01577, train_loss: 0.3639, val_loss: 0.6358, val_acc: 0.8014
Epoch [15], last_lr: 0.01726, train_loss: 0.3338, val_loss: 0.4693, val_acc: 0.8452
Epoch [16], last_lr: 0.01873, train_loss: 0.3057, val_loss: 0.5512, val_acc: 0.8285
Epoch [17], last_lr: 0.02017, train_loss: 0.2893, val_loss: 0.5390, val_acc: 0.8386
Epoch [18], last_lr: 0.02156, train_loss: 0.2768, val_loss: 0.4731, val_acc: 0.8534
Epoch [19], last_lr: 0.02289, train_loss: 0.2526, val_loss: 0.6176, val_acc: 0.8241
Epoch [20], last_lr: 0.02414, train_loss: 0.2323, val_loss: 0.4066, val_acc: 0.8691
Epoch [21], last_lr: 0.02530, train_loss: 0.2331, val_loss: 0.4344, val_acc: 0.8569
Epoch [22], last_lr: 0.02636, train_loss: 0.2127, val_loss: 0.4998, val_acc: 0.8560
Epoch [23], last_lr: 0.02729, train_loss: 0.1938, val_loss: 0.3931, val_acc: 0.8777
Epoch [24], last_lr: 0.02810, train_loss: 0.1853, val_loss: 0.4038, val_acc: 0.8788
Epoch [25], last_lr: 0.02878, train_loss: 0.1779, val_loss: 0.4058, val_acc: 0.8761
Epoch [26], last_lr: 0.02931, train_loss: 0.1675, val_loss: 0.5078, val_acc: 0.8650
Epoch [27], last_lr: 0.02969, train_loss: 0.1590, val_loss: 0.4853, val_acc: 0.8651
Epoch [28], last_lr: 0.02992, train_loss: 0.1427, val_loss: 0.4764, val_acc: 0.8600
Epoch [29], last_lr: 0.03000, train_loss: 0.1359, val_loss: 0.4109, val_acc: 0.8843
Epoch [30], last_lr: 0.02998, train_loss: 0.1279, val_loss: 0.3874, val_acc: 0.8911
Epoch [31], last_lr: 0.02994, train_loss: 0.1192, val_loss: 0.3734, val_acc: 0.8952
Epoch [32], last_lr: 0.02986, train_loss: 0.1075, val_loss: 0.5620, val_acc: 0.8574
Epoch [33], last_lr: 0.02976, train_loss: 0.1077, val_loss: 0.4701, val_acc: 0.8768
Epoch [34], last_lr: 0.02962, train_loss: 0.0995, val_loss: 0.5735, val_acc: 0.8663
Epoch [35], last_lr: 0.02946, train_loss: 0.0960, val_loss: 0.7542, val_acc: 0.8428
Epoch [36], last_lr: 0.02926, train_loss: 0.0913, val_loss: 0.3841, val_acc: 0.8967
Epoch [37], last_lr: 0.02904, train_loss: 0.0788, val_loss: 0.3725, val_acc: 0.9101
Epoch [38], last_lr: 0.02879, train_loss: 0.0763, val_loss: 0.5071, val_acc: 0.8789
Epoch [39], last_lr: 0.02851, train_loss: 0.0748, val_loss: 0.4261, val_acc: 0.9018
Epoch [40], last_lr: 0.02820, train_loss: 0.0682, val_loss: 0.4059, val_acc: 0.8971
Epoch [41], last_lr: 0.02787, train_loss: 0.0641, val_loss: 0.3842, val_acc: 0.9123
Epoch [42], last_lr: 0.02751, train_loss: 0.0615, val_loss: 0.4490, val_acc: 0.8913
Epoch [43], last_lr: 0.02713, train_loss: 0.0522, val_loss: 0.3909, val_acc: 0.9087
Epoch [44], last_lr: 0.02672, train_loss: 0.0553, val_loss: 0.3967, val_acc: 0.9096
Epoch [45], last_lr: 0.02629, train_loss: 0.0512, val_loss: 0.4244, val_acc: 0.9069
Epoch [46], last_lr: 0.02583, train_loss: 0.0510, val_loss: 0.5714, val_acc: 0.8817
Epoch [47], last_lr: 0.02536, train_loss: 0.0459, val_loss: 0.4167, val_acc: 0.9125
Epoch [48], last_lr: 0.02486, train_loss: 0.0436, val_loss: 0.4321, val_acc: 0.9108
Epoch [49], last_lr: 0.02434, train_loss: 0.0472, val_loss: 0.4213, val_acc: 0.9140
Epoch [50], last_lr: 0.02381, train_loss: 0.0378, val_loss: 0.4187, val_acc: 0.9130
Epoch [51], last_lr: 0.02325, train_loss: 0.0408, val_loss: 0.4234, val_acc: 0.9159
Epoch [52], last_lr: 0.02268, train_loss: 0.0348, val_loss: 0.4476, val_acc: 0.9087
Epoch [53], last_lr: 0.02210, train_loss: 0.0330, val_loss: 0.3901, val_acc: 0.9215
Epoch [54], last_lr: 0.02150, train_loss: 0.0272, val_loss: 0.4070, val_acc: 0.9208
Epoch [55], last_lr: 0.02088, train_loss: 0.0254, val_loss: 0.3939, val_acc: 0.9181
Epoch [56], last_lr: 0.02026, train_loss: 0.0251, val_loss: 0.3792, val_acc: 0.9245
Epoch [57], last_lr: 0.01962, train_loss: 0.0233, val_loss: 0.4342, val_acc: 0.9179
Epoch [58], last_lr: 0.01898, train_loss: 0.0234, val_loss: 0.4592, val_acc: 0.9172
Epoch [59], last_lr: 0.01832, train_loss: 0.0224, val_loss: 0.3830, val_acc: 0.9228
Epoch [60], last_lr: 0.01766, train_loss: 0.0206, val_loss: 0.3962, val_acc: 0.9248
Epoch [61], last_lr: 0.01700, train_loss: 0.0189, val_loss: 0.3931, val_acc: 0.9255
Epoch [62], last_lr: 0.01633, train_loss: 0.0155, val_loss: 0.4278, val_acc: 0.9239
Epoch [63], last_lr: 0.01566, train_loss: 0.0139, val_loss: 0.4262, val_acc: 0.9249
Epoch [64], last_lr: 0.01499, train_loss: 0.0135, val_loss: 0.3981, val_acc: 0.9264
Epoch [65], last_lr: 0.01431, train_loss: 0.0122, val_loss: 0.3835, val_acc: 0.9306
Epoch [66], last_lr: 0.01364, train_loss: 0.0100, val_loss: 0.4762, val_acc: 0.9200
Epoch [67], last_lr: 0.01297, train_loss: 0.0103, val_loss: 0.3982, val_acc: 0.9325
Epoch [68], last_lr: 0.01231, train_loss: 0.0089, val_loss: 0.4194, val_acc: 0.9298
Epoch [69], last_lr: 0.01165, train_loss: 0.0082, val_loss: 0.4190, val_acc: 0.9298
Epoch [70], last_lr: 0.01100, train_loss: 0.0082, val_loss: 0.4470, val_acc: 0.9255
Epoch [71], last_lr: 0.01035, train_loss: 0.0071, val_loss: 0.4066, val_acc: 0.9315
Epoch [72], last_lr: 0.00972, train_loss: 0.0058, val_loss: 0.4016, val_acc: 0.9332
Epoch [73], last_lr: 0.00909, train_loss: 0.0038, val_loss: 0.4214, val_acc: 0.9338
Epoch [74], last_lr: 0.00848, train_loss: 0.0036, val_loss: 0.4116, val_acc: 0.9374
Epoch [75], last_lr: 0.00788, train_loss: 0.0035, val_loss: 0.3962, val_acc: 0.9353
Epoch [76], last_lr: 0.00729, train_loss: 0.0026, val_loss: 0.4092, val_acc: 0.9355
Epoch [77], last_lr: 0.00673, train_loss: 0.0019, val_loss: 0.4154, val_acc: 0.9348
Epoch [78], last_lr: 0.00617, train_loss: 0.0020, val_loss: 0.3951, val_acc: 0.9392
Epoch [79], last_lr: 0.00564, train_loss: 0.0015, val_loss: 0.4014, val_acc: 0.9382
Epoch [80], last_lr: 0.00512, train_loss: 0.0013, val_loss: 0.3977, val_acc: 0.9393
Epoch [81], last_lr: 0.00462, train_loss: 0.0011, val_loss: 0.3978, val_acc: 0.9388
Epoch [82], last_lr: 0.00415, train_loss: 0.0010, val_loss: 0.4110, val_acc: 0.9362
Epoch [83], last_lr: 0.00370, train_loss: 0.0010, val_loss: 0.4099, val_acc: 0.9385
Epoch [84], last_lr: 0.00326, train_loss: 0.0009, val_loss: 0.4097, val_acc: 0.9390
Epoch [85], last_lr: 0.00286, train_loss: 0.0006, val_loss: 0.4074, val_acc: 0.9396
Epoch [86], last_lr: 0.00247, train_loss: 0.0005, val_loss: 0.4033, val_acc: 0.9407
Epoch [87], last_lr: 0.00212, train_loss: 0.0004, val_loss: 0.4025, val_acc: 0.9407
Epoch [88], last_lr: 0.00178, train_loss: 0.0007, val_loss: 0.4130, val_acc: 0.9394
Epoch [89], last_lr: 0.00148, train_loss: 0.0003, val_loss: 0.4102, val_acc: 0.9392
Epoch [90], last_lr: 0.00120, train_loss: 0.0005, val_loss: 0.4103, val_acc: 0.9393
Epoch [91], last_lr: 0.00095, train_loss: 0.0004, val_loss: 0.4113, val_acc: 0.9391
Epoch [92], last_lr: 0.00073, train_loss: 0.0004, val_loss: 0.4083, val_acc: 0.9405
Epoch [93], last_lr: 0.00054, train_loss: 0.0004, val_loss: 0.4077, val_acc: 0.9402
Epoch [94], last_lr: 0.00037, train_loss: 0.0003, val_loss: 0.4104, val_acc: 0.9403
Epoch [95], last_lr: 0.00024, train_loss: 0.0003, val_loss: 0.4091, val_acc: 0.9403
Epoch [96], last_lr: 0.00013, train_loss: 0.0003, val_loss: 0.4080, val_acc: 0.9394
Epoch [97], last_lr: 0.00006, train_loss: 0.0004, val_loss: 0.4102, val_acc: 0.9401
Epoch [98], last_lr: 0.00001, train_loss: 0.0003, val_loss: 0.4077, val_acc: 0.9402
Epoch [99], last_lr: 0.00000, train_loss: 0.0004, val_loss: 0.4083, val_acc: 0.9403
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

Epoch [0], last_lr: 0.00043, train_loss: 1.8347, val_loss: 1.8892, val_acc: 0.3375
Epoch [1], last_lr: 0.00051, train_loss: 1.4945, val_loss: 2.0905, val_acc: 0.3481
Epoch [2], last_lr: 0.00064, train_loss: 1.3099, val_loss: 1.7034, val_acc: 0.4671
Epoch [3], last_lr: 0.00082, train_loss: 1.1399, val_loss: 1.4804, val_acc: 0.5368
Epoch [4], last_lr: 0.00104, train_loss: 1.0170, val_loss: 1.5201, val_acc: 0.5575
Epoch [5], last_lr: 0.00132, train_loss: 0.9577, val_loss: 2.1139, val_acc: 0.4836
Epoch [6], last_lr: 0.00163, train_loss: 0.8949, val_loss: 3.3272, val_acc: 0.3799
Epoch [7], last_lr: 0.00199, train_loss: 0.8372, val_loss: 1.7288, val_acc: 0.5536
Epoch [8], last_lr: 0.00238, train_loss: 0.7797, val_loss: 1.6697, val_acc: 0.5724
Epoch [9], last_lr: 0.00280, train_loss: 0.7495, val_loss: 1.0276, val_acc: 0.6854
Epoch [10], last_lr: 0.00325, train_loss: 0.6881, val_loss: 0.9654, val_acc: 0.7054
Epoch [11], last_lr: 0.00372, train_loss: 0.6602, val_loss: 0.9490, val_acc: 0.7192
Epoch [12], last_lr: 0.00421, train_loss: 0.6299, val_loss: 1.1750, val_acc: 0.6789
Epoch [13], last_lr: 0.00470, train_loss: 0.6088, val_loss: 0.8742, val_acc: 0.7315
Epoch [14], last_lr: 0.00521, train_loss: 0.5780, val_loss: 1.1420, val_acc: 0.6876
Epoch [15], last_lr: 0.00571, train_loss: 0.5425, val_loss: 0.8089, val_acc: 0.7593
Epoch [16], last_lr: 0.00620, train_loss: 0.5145, val_loss: 0.8992, val_acc: 0.7388
Epoch [17], last_lr: 0.00669, train_loss: 0.4931, val_loss: 0.6933, val_acc: 0.7825
Epoch [18], last_lr: 0.00716, train_loss: 0.4645, val_loss: 0.8318, val_acc: 0.7654
Epoch [19], last_lr: 0.00761, train_loss: 0.4508, val_loss: 0.6750, val_acc: 0.7920
Epoch [20], last_lr: 0.00803, train_loss: 0.4384, val_loss: 0.7045, val_acc: 0.7858
Epoch [21], last_lr: 0.00842, train_loss: 0.4126, val_loss: 0.7821, val_acc: 0.7686
Epoch [22], last_lr: 0.00877, train_loss: 0.3912, val_loss: 0.9500, val_acc: 0.7422
Epoch [23], last_lr: 0.00909, train_loss: 0.3810, val_loss: 0.7697, val_acc: 0.7824
Epoch [24], last_lr: 0.00936, train_loss: 0.3589, val_loss: 0.7825, val_acc: 0.7792
Epoch [25], last_lr: 0.00959, train_loss: 0.3529, val_loss: 0.5576, val_acc: 0.8302
Epoch [26], last_lr: 0.00977, train_loss: 0.3250, val_loss: 0.7283, val_acc: 0.7891
Epoch [27], last_lr: 0.00990, train_loss: 0.3201, val_loss: 0.5145, val_acc: 0.8420
Epoch [28], last_lr: 0.00997, train_loss: 0.2983, val_loss: 0.6172, val_acc: 0.8192
Epoch [29], last_lr: 0.01000, train_loss: 0.2923, val_loss: 0.6187, val_acc: 0.8214
Epoch [30], last_lr: 0.00999, train_loss: 0.2784, val_loss: 0.4299, val_acc: 0.8662
Epoch [31], last_lr: 0.00998, train_loss: 0.2598, val_loss: 0.6019, val_acc: 0.8308
Epoch [32], last_lr: 0.00995, train_loss: 0.2546, val_loss: 0.4485, val_acc: 0.8635
Epoch [33], last_lr: 0.00992, train_loss: 0.2398, val_loss: 0.5291, val_acc: 0.8456
Epoch [34], last_lr: 0.00987, train_loss: 0.2220, val_loss: 0.5139, val_acc: 0.8474
Epoch [35], last_lr: 0.00982, train_loss: 0.2150, val_loss: 0.4419, val_acc: 0.8664
Epoch [36], last_lr: 0.00975, train_loss: 0.2104, val_loss: 0.4748, val_acc: 0.8537
Epoch [37], last_lr: 0.00968, train_loss: 0.2036, val_loss: 0.4309, val_acc: 0.8722
Epoch [38], last_lr: 0.00960, train_loss: 0.1845, val_loss: 0.4063, val_acc: 0.8779
Epoch [39], last_lr: 0.00950, train_loss: 0.1796, val_loss: 0.4220, val_acc: 0.8733
Epoch [40], last_lr: 0.00940, train_loss: 0.1738, val_loss: 0.4629, val_acc: 0.8743
Epoch [41], last_lr: 0.00929, train_loss: 0.1649, val_loss: 0.6053, val_acc: 0.8470
Epoch [42], last_lr: 0.00917, train_loss: 0.1540, val_loss: 0.4246, val_acc: 0.8793
Epoch [43], last_lr: 0.00904, train_loss: 0.1555, val_loss: 0.4292, val_acc: 0.8836
Epoch [44], last_lr: 0.00891, train_loss: 0.1439, val_loss: 0.5653, val_acc: 0.8495
Epoch [45], last_lr: 0.00876, train_loss: 0.1402, val_loss: 0.3849, val_acc: 0.8881
Epoch [46], last_lr: 0.00861, train_loss: 0.1349, val_loss: 0.5151, val_acc: 0.8631
Epoch [47], last_lr: 0.00845, train_loss: 0.1207, val_loss: 0.4873, val_acc: 0.8766
Epoch [48], last_lr: 0.00829, train_loss: 0.1209, val_loss: 0.4479, val_acc: 0.8839
Epoch [49], last_lr: 0.00811, train_loss: 0.1144, val_loss: 0.6361, val_acc: 0.8467
Epoch [50], last_lr: 0.00794, train_loss: 0.1104, val_loss: 0.4885, val_acc: 0.8769
Epoch [51], last_lr: 0.00775, train_loss: 0.0976, val_loss: 0.4438, val_acc: 0.8876
Epoch [52], last_lr: 0.00756, train_loss: 0.1041, val_loss: 0.4061, val_acc: 0.8958
Epoch [53], last_lr: 0.00737, train_loss: 0.0901, val_loss: 0.4672, val_acc: 0.8823
Epoch [54], last_lr: 0.00717, train_loss: 0.0914, val_loss: 0.4192, val_acc: 0.8864
Epoch [55], last_lr: 0.00696, train_loss: 0.0766, val_loss: 0.4116, val_acc: 0.8942
Epoch [56], last_lr: 0.00675, train_loss: 0.0767, val_loss: 0.4119, val_acc: 0.8998
Epoch [57], last_lr: 0.00654, train_loss: 0.0748, val_loss: 0.4104, val_acc: 0.9023
Epoch [58], last_lr: 0.00633, train_loss: 0.0670, val_loss: 0.4135, val_acc: 0.8991
Epoch [59], last_lr: 0.00611, train_loss: 0.0648, val_loss: 0.4766, val_acc: 0.8864
Epoch [60], last_lr: 0.00589, train_loss: 0.0611, val_loss: 0.4248, val_acc: 0.8968
Epoch [61], last_lr: 0.00567, train_loss: 0.0574, val_loss: 0.4643, val_acc: 0.8939
Epoch [62], last_lr: 0.00544, train_loss: 0.0538, val_loss: 0.4081, val_acc: 0.9064
Epoch [63], last_lr: 0.00522, train_loss: 0.0509, val_loss: 0.4387, val_acc: 0.8986
Epoch [64], last_lr: 0.00500, train_loss: 0.0469, val_loss: 0.4053, val_acc: 0.9070
Epoch [65], last_lr: 0.00477, train_loss: 0.0399, val_loss: 0.4062, val_acc: 0.9091
Epoch [66], last_lr: 0.00455, train_loss: 0.0412, val_loss: 0.3795, val_acc: 0.9100
Epoch [67], last_lr: 0.00432, train_loss: 0.0333, val_loss: 0.4501, val_acc: 0.9022
Epoch [68], last_lr: 0.00410, train_loss: 0.0342, val_loss: 0.4134, val_acc: 0.9085
Epoch [69], last_lr: 0.00388, train_loss: 0.0294, val_loss: 0.4068, val_acc: 0.9097
Epoch [70], last_lr: 0.00367, train_loss: 0.0283, val_loss: 0.4171, val_acc: 0.9100
Epoch [71], last_lr: 0.00345, train_loss: 0.0257, val_loss: 0.4261, val_acc: 0.9079
Epoch [72], last_lr: 0.00324, train_loss: 0.0188, val_loss: 0.4173, val_acc: 0.9093
Epoch [73], last_lr: 0.00303, train_loss: 0.0162, val_loss: 0.4490, val_acc: 0.9117
Epoch [74], last_lr: 0.00283, train_loss: 0.0168, val_loss: 0.4477, val_acc: 0.9101
Epoch [75], last_lr: 0.00263, train_loss: 0.0153, val_loss: 0.4296, val_acc: 0.9149
Epoch [76], last_lr: 0.00243, train_loss: 0.0146, val_loss: 0.4363, val_acc: 0.9148
Epoch [77], last_lr: 0.00224, train_loss: 0.0138, val_loss: 0.4416, val_acc: 0.9155
Epoch [78], last_lr: 0.00206, train_loss: 0.0123, val_loss: 0.4423, val_acc: 0.9152
Epoch [79], last_lr: 0.00188, train_loss: 0.0090, val_loss: 0.4303, val_acc: 0.9171
Epoch [80], last_lr: 0.00171, train_loss: 0.0062, val_loss: 0.4243, val_acc: 0.9202
Epoch [81], last_lr: 0.00154, train_loss: 0.0065, val_loss: 0.4402, val_acc: 0.9200
Epoch [82], last_lr: 0.00138, train_loss: 0.0054, val_loss: 0.4485, val_acc: 0.9209
Epoch [83], last_lr: 0.00123, train_loss: 0.0048, val_loss: 0.4375, val_acc: 0.9193
Epoch [84], last_lr: 0.00109, train_loss: 0.0036, val_loss: 0.4348, val_acc: 0.9239
Epoch [85], last_lr: 0.00095, train_loss: 0.0034, val_loss: 0.4339, val_acc: 0.9213
Epoch [86], last_lr: 0.00082, train_loss: 0.0029, val_loss: 0.4455, val_acc: 0.9216
Epoch [87], last_lr: 0.00071, train_loss: 0.0025, val_loss: 0.4433, val_acc: 0.9240
Epoch [88], last_lr: 0.00059, train_loss: 0.0022, val_loss: 0.4420, val_acc: 0.9241
Epoch [89], last_lr: 0.00049, train_loss: 0.0025, val_loss: 0.4456, val_acc: 0.9231
Epoch [90], last_lr: 0.00040, train_loss: 0.0017, val_loss: 0.4444, val_acc: 0.9234
Epoch [91], last_lr: 0.00032, train_loss: 0.0018, val_loss: 0.4457, val_acc: 0.9247
Epoch [92], last_lr: 0.00024, train_loss: 0.0017, val_loss: 0.4454, val_acc: 0.9238
Epoch [93], last_lr: 0.00018, train_loss: 0.0015, val_loss: 0.4450, val_acc: 0.9246
Epoch [94], last_lr: 0.00012, train_loss: 0.0014, val_loss: 0.4467, val_acc: 0.9245
Epoch [95], last_lr: 0.00008, train_loss: 0.0017, val_loss: 0.4461, val_acc: 0.9244
Epoch [96], last_lr: 0.00004, train_loss: 0.0015, val_loss: 0.4497, val_acc: 0.9243
Epoch [97], last_lr: 0.00002, train_loss: 0.0014, val_loss: 0.4456, val_acc: 0.9244
Epoch [98], last_lr: 0.00000, train_loss: 0.0012, val_loss: 0.4500, val_acc: 0.9245
Epoch [99], last_lr: 0.00000, train_loss: 0.0013, val_loss: 0.4482, val_acc: 0.9247
Saved final model to ./saves/cnn_cifar10_final_ep100_step4900.pth

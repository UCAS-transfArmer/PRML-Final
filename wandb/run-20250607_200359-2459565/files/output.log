Epoch [0], last_lr: 0.00053, train_loss: 1.6756, val_loss: 1.5036, val_acc: 0.4611
Epoch [1], last_lr: 0.00060, train_loss: 1.2085, val_loss: 1.2911, val_acc: 0.5452
Epoch [2], last_lr: 0.00073, train_loss: 0.9614, val_loss: 0.9977, val_acc: 0.6541
Epoch [3], last_lr: 0.00091, train_loss: 0.8138, val_loss: 0.9821, val_acc: 0.6690
Epoch [4], last_lr: 0.00114, train_loss: 0.6970, val_loss: 1.2209, val_acc: 0.6427
Epoch [5], last_lr: 0.00141, train_loss: 0.6109, val_loss: 0.8716, val_acc: 0.7043
Epoch [6], last_lr: 0.00172, train_loss: 0.5422, val_loss: 0.8178, val_acc: 0.7406
Epoch [7], last_lr: 0.00207, train_loss: 0.4898, val_loss: 0.6864, val_acc: 0.7833
Epoch [8], last_lr: 0.00246, train_loss: 0.4497, val_loss: 0.6253, val_acc: 0.8096
Epoch [9], last_lr: 0.00288, train_loss: 0.4149, val_loss: 1.0663, val_acc: 0.7144
Epoch [10], last_lr: 0.00332, train_loss: 0.3838, val_loss: 0.9585, val_acc: 0.7109
Epoch [11], last_lr: 0.00379, train_loss: 0.3672, val_loss: 0.8487, val_acc: 0.7609
Epoch [12], last_lr: 0.00427, train_loss: 0.3424, val_loss: 0.7272, val_acc: 0.7884
Epoch [13], last_lr: 0.00476, train_loss: 0.3255, val_loss: 0.7144, val_acc: 0.7885
Epoch [14], last_lr: 0.00526, train_loss: 0.2949, val_loss: 0.7124, val_acc: 0.7986
Epoch [15], last_lr: 0.00575, train_loss: 0.2783, val_loss: 0.4750, val_acc: 0.8509
Epoch [16], last_lr: 0.00624, train_loss: 0.2629, val_loss: 0.6201, val_acc: 0.8208
Epoch [17], last_lr: 0.00672, train_loss: 0.2581, val_loss: 0.5008, val_acc: 0.8400
Epoch [18], last_lr: 0.00719, train_loss: 0.2380, val_loss: 0.4261, val_acc: 0.8639
Epoch [19], last_lr: 0.00763, train_loss: 0.2226, val_loss: 0.4631, val_acc: 0.8541
Epoch [20], last_lr: 0.00805, train_loss: 0.2179, val_loss: 0.5176, val_acc: 0.8434
Epoch [21], last_lr: 0.00843, train_loss: 0.1984, val_loss: 0.4120, val_acc: 0.8754
Epoch [22], last_lr: 0.00879, train_loss: 0.1835, val_loss: 0.4841, val_acc: 0.8606
Epoch [23], last_lr: 0.00910, train_loss: 0.1677, val_loss: 0.6448, val_acc: 0.8372
Epoch [24], last_lr: 0.00937, train_loss: 0.1722, val_loss: 0.4584, val_acc: 0.8619
Epoch [25], last_lr: 0.00959, train_loss: 0.1540, val_loss: 0.5366, val_acc: 0.8630
Epoch [26], last_lr: 0.00977, train_loss: 0.1444, val_loss: 0.3508, val_acc: 0.8939
Epoch [27], last_lr: 0.00990, train_loss: 0.1342, val_loss: 0.3807, val_acc: 0.8911
Epoch [28], last_lr: 0.00997, train_loss: 0.1252, val_loss: 0.5368, val_acc: 0.8641
Epoch [29], last_lr: 0.01000, train_loss: 0.1179, val_loss: 0.5266, val_acc: 0.8648
Epoch [30], last_lr: 0.00999, train_loss: 0.1156, val_loss: 0.4166, val_acc: 0.8858
Epoch [31], last_lr: 0.00998, train_loss: 0.1058, val_loss: 0.3813, val_acc: 0.8990
Epoch [32], last_lr: 0.00995, train_loss: 0.0917, val_loss: 0.4231, val_acc: 0.8912
Epoch [33], last_lr: 0.00992, train_loss: 0.0921, val_loss: 0.4449, val_acc: 0.8836
Epoch [34], last_lr: 0.00987, train_loss: 0.0807, val_loss: 0.4485, val_acc: 0.8938
Epoch [35], last_lr: 0.00982, train_loss: 0.0741, val_loss: 0.5110, val_acc: 0.8773
Epoch [36], last_lr: 0.00975, train_loss: 0.0764, val_loss: 0.3929, val_acc: 0.9047
Epoch [37], last_lr: 0.00968, train_loss: 0.0718, val_loss: 0.4084, val_acc: 0.8982
Epoch [38], last_lr: 0.00960, train_loss: 0.0662, val_loss: 0.3721, val_acc: 0.9106
Epoch [39], last_lr: 0.00950, train_loss: 0.0706, val_loss: 0.4022, val_acc: 0.8994
Epoch [40], last_lr: 0.00940, train_loss: 0.0506, val_loss: 0.4016, val_acc: 0.9057
Epoch [41], last_lr: 0.00929, train_loss: 0.0487, val_loss: 0.4186, val_acc: 0.9085
Epoch [42], last_lr: 0.00917, train_loss: 0.0549, val_loss: 0.4307, val_acc: 0.9024
Epoch [43], last_lr: 0.00904, train_loss: 0.0491, val_loss: 0.3856, val_acc: 0.9103
Epoch [44], last_lr: 0.00891, train_loss: 0.0434, val_loss: 0.4548, val_acc: 0.9056
Epoch [45], last_lr: 0.00876, train_loss: 0.0494, val_loss: 0.4595, val_acc: 0.8985
Epoch [46], last_lr: 0.00861, train_loss: 0.0415, val_loss: 0.4384, val_acc: 0.9077
Epoch [47], last_lr: 0.00845, train_loss: 0.0418, val_loss: 0.4158, val_acc: 0.9111
Epoch [48], last_lr: 0.00829, train_loss: 0.0405, val_loss: 0.4246, val_acc: 0.9095
Epoch [49], last_lr: 0.00811, train_loss: 0.0338, val_loss: 0.3928, val_acc: 0.9155
Epoch [50], last_lr: 0.00794, train_loss: 0.0331, val_loss: 0.3961, val_acc: 0.9163
Epoch [51], last_lr: 0.00775, train_loss: 0.0281, val_loss: 0.3780, val_acc: 0.9233
Epoch [52], last_lr: 0.00756, train_loss: 0.0263, val_loss: 0.3807, val_acc: 0.9214
Epoch [53], last_lr: 0.00737, train_loss: 0.0295, val_loss: 0.4141, val_acc: 0.9164
Epoch [54], last_lr: 0.00717, train_loss: 0.0294, val_loss: 0.3493, val_acc: 0.9243
Epoch [55], last_lr: 0.00696, train_loss: 0.0223, val_loss: 0.3414, val_acc: 0.9294
Epoch [56], last_lr: 0.00675, train_loss: 0.0195, val_loss: 0.4033, val_acc: 0.9221
Epoch [57], last_lr: 0.00654, train_loss: 0.0194, val_loss: 0.4079, val_acc: 0.9190
Epoch [58], last_lr: 0.00633, train_loss: 0.0172, val_loss: 0.3832, val_acc: 0.9278
Epoch [59], last_lr: 0.00611, train_loss: 0.0166, val_loss: 0.3834, val_acc: 0.9276
Epoch [60], last_lr: 0.00589, train_loss: 0.0161, val_loss: 0.3870, val_acc: 0.9261
Epoch [61], last_lr: 0.00567, train_loss: 0.0140, val_loss: 0.4358, val_acc: 0.9250
Epoch [62], last_lr: 0.00544, train_loss: 0.0131, val_loss: 0.4142, val_acc: 0.9282
Epoch [63], last_lr: 0.00522, train_loss: 0.0099, val_loss: 0.4136, val_acc: 0.9285
Epoch [64], last_lr: 0.00500, train_loss: 0.0105, val_loss: 0.4015, val_acc: 0.9283
Epoch [65], last_lr: 0.00477, train_loss: 0.0118, val_loss: 0.4059, val_acc: 0.9299
Epoch [66], last_lr: 0.00455, train_loss: 0.0084, val_loss: 0.4074, val_acc: 0.9313
Epoch [67], last_lr: 0.00432, train_loss: 0.0062, val_loss: 0.3758, val_acc: 0.9344
Epoch [68], last_lr: 0.00410, train_loss: 0.0052, val_loss: 0.3692, val_acc: 0.9374
Epoch [69], last_lr: 0.00388, train_loss: 0.0056, val_loss: 0.3861, val_acc: 0.9340
Epoch [70], last_lr: 0.00367, train_loss: 0.0051, val_loss: 0.3821, val_acc: 0.9341
Epoch [71], last_lr: 0.00345, train_loss: 0.0037, val_loss: 0.3733, val_acc: 0.9328
Epoch [72], last_lr: 0.00324, train_loss: 0.0026, val_loss: 0.3728, val_acc: 0.9378
Epoch [73], last_lr: 0.00303, train_loss: 0.0029, val_loss: 0.3891, val_acc: 0.9365
Epoch [74], last_lr: 0.00283, train_loss: 0.0030, val_loss: 0.4081, val_acc: 0.9350
Epoch [75], last_lr: 0.00263, train_loss: 0.0017, val_loss: 0.4264, val_acc: 0.9334
Epoch [76], last_lr: 0.00243, train_loss: 0.0020, val_loss: 0.3884, val_acc: 0.9377
Epoch [77], last_lr: 0.00224, train_loss: 0.0027, val_loss: 0.4001, val_acc: 0.9376
Epoch [78], last_lr: 0.00206, train_loss: 0.0015, val_loss: 0.3896, val_acc: 0.9392
Epoch [79], last_lr: 0.00188, train_loss: 0.0013, val_loss: 0.3841, val_acc: 0.9392
Epoch [80], last_lr: 0.00171, train_loss: 0.0012, val_loss: 0.3836, val_acc: 0.9393
Epoch [81], last_lr: 0.00154, train_loss: 0.0008, val_loss: 0.3823, val_acc: 0.9403
Epoch [82], last_lr: 0.00138, train_loss: 0.0007, val_loss: 0.3848, val_acc: 0.9397
Epoch [83], last_lr: 0.00123, train_loss: 0.0006, val_loss: 0.3827, val_acc: 0.9405
Epoch [84], last_lr: 0.00109, train_loss: 0.0005, val_loss: 0.3853, val_acc: 0.9403
Epoch [85], last_lr: 0.00095, train_loss: 0.0005, val_loss: 0.3878, val_acc: 0.9394
Epoch [86], last_lr: 0.00082, train_loss: 0.0005, val_loss: 0.3883, val_acc: 0.9408
Epoch [87], last_lr: 0.00071, train_loss: 0.0004, val_loss: 0.3870, val_acc: 0.9403
Epoch [88], last_lr: 0.00059, train_loss: 0.0003, val_loss: 0.3896, val_acc: 0.9402
Epoch [89], last_lr: 0.00049, train_loss: 0.0005, val_loss: 0.3896, val_acc: 0.9402
Epoch [90], last_lr: 0.00040, train_loss: 0.0003, val_loss: 0.3892, val_acc: 0.9398
Epoch [91], last_lr: 0.00032, train_loss: 0.0003, val_loss: 0.3885, val_acc: 0.9408
Epoch [92], last_lr: 0.00024, train_loss: 0.0003, val_loss: 0.3877, val_acc: 0.9409
Epoch [93], last_lr: 0.00018, train_loss: 0.0003, val_loss: 0.3865, val_acc: 0.9405
Epoch [94], last_lr: 0.00012, train_loss: 0.0005, val_loss: 0.3881, val_acc: 0.9404
Epoch [95], last_lr: 0.00008, train_loss: 0.0004, val_loss: 0.3851, val_acc: 0.9406
Epoch [96], last_lr: 0.00004, train_loss: 0.0003, val_loss: 0.3862, val_acc: 0.9408
Epoch [97], last_lr: 0.00002, train_loss: 0.0003, val_loss: 0.3876, val_acc: 0.9405
Epoch [98], last_lr: 0.00000, train_loss: 0.0002, val_loss: 0.3863, val_acc: 0.9410
Epoch [99], last_lr: 0.00000, train_loss: 0.0003, val_loss: 0.3852, val_acc: 0.9411
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

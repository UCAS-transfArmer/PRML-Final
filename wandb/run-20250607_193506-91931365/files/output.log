Epoch [0], last_lr: 0.00043, train_loss: 1.6467, val_loss: 1.4575, val_acc: 0.4633
Epoch [1], last_lr: 0.00051, train_loss: 1.1841, val_loss: 1.0570, val_acc: 0.6260
Epoch [2], last_lr: 0.00064, train_loss: 0.9420, val_loss: 0.9825, val_acc: 0.6635
Epoch [3], last_lr: 0.00082, train_loss: 0.7883, val_loss: 0.9290, val_acc: 0.6871
Epoch [4], last_lr: 0.00104, train_loss: 0.6804, val_loss: 1.1264, val_acc: 0.6748
Epoch [5], last_lr: 0.00132, train_loss: 0.5888, val_loss: 0.9042, val_acc: 0.7218
Epoch [6], last_lr: 0.00163, train_loss: 0.5181, val_loss: 0.9700, val_acc: 0.7110
Epoch [7], last_lr: 0.00199, train_loss: 0.4737, val_loss: 0.6122, val_acc: 0.7938
Epoch [8], last_lr: 0.00238, train_loss: 0.4262, val_loss: 0.7234, val_acc: 0.7706
Epoch [9], last_lr: 0.00280, train_loss: 0.4075, val_loss: 0.8288, val_acc: 0.7645
Epoch [10], last_lr: 0.00325, train_loss: 0.3733, val_loss: 0.6742, val_acc: 0.7853
Epoch [11], last_lr: 0.00372, train_loss: 0.3520, val_loss: 0.5876, val_acc: 0.8143
Epoch [12], last_lr: 0.00421, train_loss: 0.3280, val_loss: 0.5963, val_acc: 0.8127
Epoch [13], last_lr: 0.00470, train_loss: 0.3049, val_loss: 0.6773, val_acc: 0.8060
Epoch [14], last_lr: 0.00521, train_loss: 0.2817, val_loss: 0.6150, val_acc: 0.8153
Epoch [15], last_lr: 0.00571, train_loss: 0.2651, val_loss: 0.7209, val_acc: 0.8047
Epoch [16], last_lr: 0.00620, train_loss: 0.2624, val_loss: 0.4741, val_acc: 0.8469
Epoch [17], last_lr: 0.00669, train_loss: 0.2384, val_loss: 0.4913, val_acc: 0.8543
Epoch [18], last_lr: 0.00716, train_loss: 0.2229, val_loss: 0.4789, val_acc: 0.8552
Epoch [19], last_lr: 0.00761, train_loss: 0.2137, val_loss: 0.5215, val_acc: 0.8413
Epoch [20], last_lr: 0.00803, train_loss: 0.2028, val_loss: 0.5449, val_acc: 0.8396
Epoch [21], last_lr: 0.00842, train_loss: 0.1905, val_loss: 0.4253, val_acc: 0.8729
Epoch [22], last_lr: 0.00877, train_loss: 0.1753, val_loss: 0.4320, val_acc: 0.8732
Epoch [23], last_lr: 0.00909, train_loss: 0.1683, val_loss: 0.5908, val_acc: 0.8443
Epoch [24], last_lr: 0.00936, train_loss: 0.1525, val_loss: 0.3596, val_acc: 0.8898
Epoch [25], last_lr: 0.00959, train_loss: 0.1397, val_loss: 0.4264, val_acc: 0.8744
Epoch [26], last_lr: 0.00977, train_loss: 0.1384, val_loss: 0.4098, val_acc: 0.8864
Epoch [27], last_lr: 0.00990, train_loss: 0.1284, val_loss: 0.3759, val_acc: 0.8925
Epoch [28], last_lr: 0.00997, train_loss: 0.1156, val_loss: 0.4493, val_acc: 0.8797
Epoch [29], last_lr: 0.01000, train_loss: 0.1135, val_loss: 0.3630, val_acc: 0.8976
Epoch [30], last_lr: 0.00999, train_loss: 0.1009, val_loss: 0.5598, val_acc: 0.8600
Epoch [31], last_lr: 0.00998, train_loss: 0.0923, val_loss: 0.3950, val_acc: 0.8985
Epoch [32], last_lr: 0.00995, train_loss: 0.0899, val_loss: 0.3639, val_acc: 0.8974
Epoch [33], last_lr: 0.00992, train_loss: 0.0824, val_loss: 0.4139, val_acc: 0.8923
Epoch [34], last_lr: 0.00987, train_loss: 0.0799, val_loss: 0.3999, val_acc: 0.8984
Epoch [35], last_lr: 0.00982, train_loss: 0.0715, val_loss: 0.5026, val_acc: 0.8822
Epoch [36], last_lr: 0.00975, train_loss: 0.0754, val_loss: 0.3572, val_acc: 0.9087
Epoch [37], last_lr: 0.00968, train_loss: 0.0669, val_loss: 0.3894, val_acc: 0.9033
Epoch [38], last_lr: 0.00960, train_loss: 0.0574, val_loss: 0.3302, val_acc: 0.9173
Epoch [39], last_lr: 0.00950, train_loss: 0.0520, val_loss: 0.5009, val_acc: 0.8956
Epoch [40], last_lr: 0.00940, train_loss: 0.0570, val_loss: 0.3926, val_acc: 0.9078
Epoch [41], last_lr: 0.00929, train_loss: 0.0501, val_loss: 0.3665, val_acc: 0.9129
Epoch [42], last_lr: 0.00917, train_loss: 0.0451, val_loss: 0.4808, val_acc: 0.8935
Epoch [43], last_lr: 0.00904, train_loss: 0.0476, val_loss: 0.3856, val_acc: 0.9137
Epoch [44], last_lr: 0.00891, train_loss: 0.0412, val_loss: 0.5365, val_acc: 0.8981
Epoch [45], last_lr: 0.00876, train_loss: 0.0407, val_loss: 0.3816, val_acc: 0.9161
Epoch [46], last_lr: 0.00861, train_loss: 0.0425, val_loss: 0.3744, val_acc: 0.9120
Epoch [47], last_lr: 0.00845, train_loss: 0.0359, val_loss: 0.4100, val_acc: 0.9160
Epoch [48], last_lr: 0.00829, train_loss: 0.0364, val_loss: 0.4068, val_acc: 0.9174
Epoch [49], last_lr: 0.00811, train_loss: 0.0329, val_loss: 0.3696, val_acc: 0.9211
Epoch [50], last_lr: 0.00794, train_loss: 0.0270, val_loss: 0.3770, val_acc: 0.9175
Epoch [51], last_lr: 0.00775, train_loss: 0.0272, val_loss: 0.3741, val_acc: 0.9216
Epoch [52], last_lr: 0.00756, train_loss: 0.0310, val_loss: 0.3677, val_acc: 0.9198
Epoch [53], last_lr: 0.00737, train_loss: 0.0268, val_loss: 0.3837, val_acc: 0.9205
Epoch [54], last_lr: 0.00717, train_loss: 0.0236, val_loss: 0.3504, val_acc: 0.9237
Epoch [55], last_lr: 0.00696, train_loss: 0.0174, val_loss: 0.3748, val_acc: 0.9253
Epoch [56], last_lr: 0.00675, train_loss: 0.0181, val_loss: 0.4523, val_acc: 0.9176
Epoch [57], last_lr: 0.00654, train_loss: 0.0199, val_loss: 0.4221, val_acc: 0.9217
Epoch [58], last_lr: 0.00633, train_loss: 0.0176, val_loss: 0.3811, val_acc: 0.9279
Epoch [59], last_lr: 0.00611, train_loss: 0.0184, val_loss: 0.3456, val_acc: 0.9317
Epoch [60], last_lr: 0.00589, train_loss: 0.0132, val_loss: 0.3577, val_acc: 0.9312
Epoch [61], last_lr: 0.00567, train_loss: 0.0131, val_loss: 0.3679, val_acc: 0.9310
Epoch [62], last_lr: 0.00544, train_loss: 0.0116, val_loss: 0.3809, val_acc: 0.9268
Epoch [63], last_lr: 0.00522, train_loss: 0.0091, val_loss: 0.3840, val_acc: 0.9297
Epoch [64], last_lr: 0.00500, train_loss: 0.0096, val_loss: 0.3770, val_acc: 0.9306
Epoch [65], last_lr: 0.00477, train_loss: 0.0069, val_loss: 0.3679, val_acc: 0.9322
Epoch [66], last_lr: 0.00455, train_loss: 0.0055, val_loss: 0.3661, val_acc: 0.9363
Epoch [67], last_lr: 0.00432, train_loss: 0.0055, val_loss: 0.3686, val_acc: 0.9334
Epoch [68], last_lr: 0.00410, train_loss: 0.0051, val_loss: 0.3667, val_acc: 0.9379
Epoch [69], last_lr: 0.00388, train_loss: 0.0045, val_loss: 0.3926, val_acc: 0.9322
Epoch [70], last_lr: 0.00367, train_loss: 0.0046, val_loss: 0.3859, val_acc: 0.9352
Epoch [71], last_lr: 0.00345, train_loss: 0.0039, val_loss: 0.3940, val_acc: 0.9331
Epoch [72], last_lr: 0.00324, train_loss: 0.0038, val_loss: 0.3611, val_acc: 0.9383
Epoch [73], last_lr: 0.00303, train_loss: 0.0026, val_loss: 0.3548, val_acc: 0.9382
Epoch [74], last_lr: 0.00283, train_loss: 0.0021, val_loss: 0.3640, val_acc: 0.9394
Epoch [75], last_lr: 0.00263, train_loss: 0.0018, val_loss: 0.3654, val_acc: 0.9390
Epoch [76], last_lr: 0.00243, train_loss: 0.0012, val_loss: 0.3710, val_acc: 0.9391
Epoch [77], last_lr: 0.00224, train_loss: 0.0013, val_loss: 0.3712, val_acc: 0.9393
Epoch [78], last_lr: 0.00206, train_loss: 0.0013, val_loss: 0.3605, val_acc: 0.9410
Epoch [79], last_lr: 0.00188, train_loss: 0.0010, val_loss: 0.3672, val_acc: 0.9416
Epoch [80], last_lr: 0.00171, train_loss: 0.0010, val_loss: 0.3636, val_acc: 0.9413
Epoch [81], last_lr: 0.00154, train_loss: 0.0008, val_loss: 0.3651, val_acc: 0.9403
Epoch [82], last_lr: 0.00138, train_loss: 0.0007, val_loss: 0.3659, val_acc: 0.9399
Epoch [83], last_lr: 0.00123, train_loss: 0.0006, val_loss: 0.3639, val_acc: 0.9406
Epoch [84], last_lr: 0.00109, train_loss: 0.0005, val_loss: 0.3634, val_acc: 0.9412
Epoch [85], last_lr: 0.00095, train_loss: 0.0004, val_loss: 0.3639, val_acc: 0.9416
Epoch [86], last_lr: 0.00082, train_loss: 0.0004, val_loss: 0.3622, val_acc: 0.9419
Epoch [87], last_lr: 0.00071, train_loss: 0.0003, val_loss: 0.3637, val_acc: 0.9417
Epoch [88], last_lr: 0.00059, train_loss: 0.0004, val_loss: 0.3605, val_acc: 0.9418
Epoch [89], last_lr: 0.00049, train_loss: 0.0005, val_loss: 0.3608, val_acc: 0.9426
Epoch [90], last_lr: 0.00040, train_loss: 0.0004, val_loss: 0.3600, val_acc: 0.9433
Epoch [91], last_lr: 0.00032, train_loss: 0.0003, val_loss: 0.3602, val_acc: 0.9439
Epoch [92], last_lr: 0.00024, train_loss: 0.0003, val_loss: 0.3618, val_acc: 0.9430
Epoch [93], last_lr: 0.00018, train_loss: 0.0004, val_loss: 0.3612, val_acc: 0.9437
Epoch [94], last_lr: 0.00012, train_loss: 0.0002, val_loss: 0.3614, val_acc: 0.9442
Epoch [95], last_lr: 0.00008, train_loss: 0.0003, val_loss: 0.3617, val_acc: 0.9435
Epoch [96], last_lr: 0.00004, train_loss: 0.0003, val_loss: 0.3617, val_acc: 0.9440
Epoch [97], last_lr: 0.00002, train_loss: 0.0002, val_loss: 0.3620, val_acc: 0.9433
Epoch [98], last_lr: 0.00000, train_loss: 0.0002, val_loss: 0.3620, val_acc: 0.9435
Epoch [99], last_lr: 0.00000, train_loss: 0.0003, val_loss: 0.3608, val_acc: 0.9436
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

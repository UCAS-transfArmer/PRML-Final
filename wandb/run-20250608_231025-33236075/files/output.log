Epoch [0], last_lr: 0.00043, train_loss: 1.8625, val_loss: 1.6950, val_acc: 0.3733
Epoch [1], last_lr: 0.00051, train_loss: 1.3509, val_loss: 1.3090, val_acc: 0.5368
Epoch [2], last_lr: 0.00064, train_loss: 1.0454, val_loss: 1.0950, val_acc: 0.6133
Epoch [3], last_lr: 0.00082, train_loss: 0.8388, val_loss: 1.0739, val_acc: 0.6397
Epoch [4], last_lr: 0.00104, train_loss: 0.6966, val_loss: 0.8408, val_acc: 0.7087
Epoch [5], last_lr: 0.00132, train_loss: 0.5736, val_loss: 1.0522, val_acc: 0.6713
Epoch [6], last_lr: 0.00163, train_loss: 0.4925, val_loss: 0.9943, val_acc: 0.6793
Epoch [7], last_lr: 0.00199, train_loss: 0.4228, val_loss: 1.1505, val_acc: 0.7049
Epoch [8], last_lr: 0.00238, train_loss: 0.3687, val_loss: 1.1362, val_acc: 0.7028
Epoch [9], last_lr: 0.00280, train_loss: 0.3169, val_loss: 0.8803, val_acc: 0.7444
Epoch [10], last_lr: 0.00325, train_loss: 0.2787, val_loss: 1.0039, val_acc: 0.7331
Epoch [11], last_lr: 0.00372, train_loss: 0.2513, val_loss: 1.1071, val_acc: 0.7219
Epoch [12], last_lr: 0.00421, train_loss: 0.2151, val_loss: 0.9370, val_acc: 0.7631
Epoch [13], last_lr: 0.00470, train_loss: 0.1760, val_loss: 1.3248, val_acc: 0.7301
Epoch [14], last_lr: 0.00521, train_loss: 0.1685, val_loss: 1.6301, val_acc: 0.6845
Epoch [15], last_lr: 0.00571, train_loss: 0.1482, val_loss: 0.8703, val_acc: 0.7831
Epoch [16], last_lr: 0.00620, train_loss: 0.1346, val_loss: 0.6830, val_acc: 0.8157
Epoch [17], last_lr: 0.00669, train_loss: 0.1009, val_loss: 0.7824, val_acc: 0.8156
Epoch [18], last_lr: 0.00716, train_loss: 0.1091, val_loss: 0.8999, val_acc: 0.7938
Epoch [19], last_lr: 0.00761, train_loss: 0.0811, val_loss: 0.7360, val_acc: 0.8204
Epoch [20], last_lr: 0.00803, train_loss: 0.0876, val_loss: 0.9868, val_acc: 0.7915
Epoch [21], last_lr: 0.00842, train_loss: 0.0755, val_loss: 1.1470, val_acc: 0.7721
Epoch [22], last_lr: 0.00877, train_loss: 0.0650, val_loss: 0.7988, val_acc: 0.8179
Epoch [23], last_lr: 0.00909, train_loss: 0.0600, val_loss: 0.9799, val_acc: 0.8086
Epoch [24], last_lr: 0.00936, train_loss: 0.0518, val_loss: 1.0831, val_acc: 0.7755
Epoch [25], last_lr: 0.00959, train_loss: 0.0476, val_loss: 0.7798, val_acc: 0.8308
Epoch [26], last_lr: 0.00977, train_loss: 0.0603, val_loss: 0.8142, val_acc: 0.8272
Epoch [27], last_lr: 0.00990, train_loss: 0.0467, val_loss: 0.9145, val_acc: 0.8211
Epoch [28], last_lr: 0.00997, train_loss: 0.0298, val_loss: 0.6705, val_acc: 0.8564
Epoch [29], last_lr: 0.01000, train_loss: 0.0250, val_loss: 1.0714, val_acc: 0.8130
Epoch [30], last_lr: 0.00999, train_loss: 0.0432, val_loss: 0.8822, val_acc: 0.8199
Epoch [31], last_lr: 0.00998, train_loss: 0.0269, val_loss: 0.7385, val_acc: 0.8539
Epoch [32], last_lr: 0.00995, train_loss: 0.0168, val_loss: 0.6923, val_acc: 0.8658
Epoch [33], last_lr: 0.00992, train_loss: 0.0171, val_loss: 1.1402, val_acc: 0.8220
Epoch [34], last_lr: 0.00987, train_loss: 0.0289, val_loss: 0.7315, val_acc: 0.8584
Epoch [35], last_lr: 0.00982, train_loss: 0.0239, val_loss: 0.7182, val_acc: 0.8607
Epoch [36], last_lr: 0.00975, train_loss: 0.0164, val_loss: 0.8490, val_acc: 0.8442
Epoch [37], last_lr: 0.00968, train_loss: 0.0119, val_loss: 0.6935, val_acc: 0.8684
Epoch [38], last_lr: 0.00960, train_loss: 0.0087, val_loss: 0.8382, val_acc: 0.8558
Epoch [39], last_lr: 0.00950, train_loss: 0.0103, val_loss: 0.7419, val_acc: 0.8633
Epoch [40], last_lr: 0.00940, train_loss: 0.0138, val_loss: 0.9149, val_acc: 0.8388
Epoch [41], last_lr: 0.00929, train_loss: 0.0180, val_loss: 0.9357, val_acc: 0.8470
Epoch [42], last_lr: 0.00917, train_loss: 0.0220, val_loss: 0.7721, val_acc: 0.8550
Epoch [43], last_lr: 0.00904, train_loss: 0.0172, val_loss: 0.8437, val_acc: 0.8411
Epoch [44], last_lr: 0.00891, train_loss: 0.0122, val_loss: 0.7887, val_acc: 0.8581
Epoch [45], last_lr: 0.00876, train_loss: 0.0114, val_loss: 0.7184, val_acc: 0.8706
Epoch [46], last_lr: 0.00861, train_loss: 0.0091, val_loss: 0.6998, val_acc: 0.8720
Epoch [47], last_lr: 0.00845, train_loss: 0.0069, val_loss: 0.7240, val_acc: 0.8718
Epoch [48], last_lr: 0.00829, train_loss: 0.0040, val_loss: 0.7844, val_acc: 0.8727
Epoch [49], last_lr: 0.00811, train_loss: 0.0021, val_loss: 0.7365, val_acc: 0.8753
Epoch [50], last_lr: 0.00794, train_loss: 0.0019, val_loss: 0.7127, val_acc: 0.8832
Epoch [51], last_lr: 0.00775, train_loss: 0.0010, val_loss: 0.6973, val_acc: 0.8851
Epoch [52], last_lr: 0.00756, train_loss: 0.0007, val_loss: 0.7250, val_acc: 0.8829
Epoch [53], last_lr: 0.00737, train_loss: 0.0003, val_loss: 0.7117, val_acc: 0.8886
Epoch [54], last_lr: 0.00717, train_loss: 0.0001, val_loss: 0.6995, val_acc: 0.8907
Epoch [55], last_lr: 0.00696, train_loss: 0.0000, val_loss: 0.6981, val_acc: 0.8903
Epoch [56], last_lr: 0.00675, train_loss: 0.0000, val_loss: 0.7017, val_acc: 0.8904
Epoch [57], last_lr: 0.00654, train_loss: 0.0000, val_loss: 0.7007, val_acc: 0.8912
Epoch [58], last_lr: 0.00633, train_loss: 0.0000, val_loss: 0.7005, val_acc: 0.8921
Epoch [59], last_lr: 0.00611, train_loss: 0.0000, val_loss: 0.7001, val_acc: 0.8907
Epoch [60], last_lr: 0.00589, train_loss: 0.0000, val_loss: 0.6994, val_acc: 0.8917
Epoch [61], last_lr: 0.00567, train_loss: 0.0000, val_loss: 0.7012, val_acc: 0.8906
Epoch [62], last_lr: 0.00544, train_loss: 0.0000, val_loss: 0.7015, val_acc: 0.8914
Epoch [63], last_lr: 0.00522, train_loss: 0.0000, val_loss: 0.7038, val_acc: 0.8917
Epoch [64], last_lr: 0.00500, train_loss: 0.0000, val_loss: 0.7041, val_acc: 0.8906
Epoch [65], last_lr: 0.00477, train_loss: 0.0000, val_loss: 0.7052, val_acc: 0.8916
Epoch [66], last_lr: 0.00455, train_loss: 0.0000, val_loss: 0.7057, val_acc: 0.8911
Epoch [67], last_lr: 0.00432, train_loss: 0.0000, val_loss: 0.7069, val_acc: 0.8922
Epoch [68], last_lr: 0.00410, train_loss: 0.0000, val_loss: 0.7051, val_acc: 0.8914
Epoch [69], last_lr: 0.00388, train_loss: 0.0000, val_loss: 0.7054, val_acc: 0.8913
Epoch [70], last_lr: 0.00367, train_loss: 0.0000, val_loss: 0.7064, val_acc: 0.8912
Epoch [71], last_lr: 0.00345, train_loss: 0.0000, val_loss: 0.7058, val_acc: 0.8916
Epoch [72], last_lr: 0.00324, train_loss: 0.0000, val_loss: 0.7088, val_acc: 0.8916
Epoch [73], last_lr: 0.00303, train_loss: 0.0000, val_loss: 0.7099, val_acc: 0.8915
Epoch [74], last_lr: 0.00283, train_loss: 0.0000, val_loss: 0.7084, val_acc: 0.8914
Epoch [75], last_lr: 0.00263, train_loss: 0.0000, val_loss: 0.7095, val_acc: 0.8919
Epoch [76], last_lr: 0.00243, train_loss: 0.0000, val_loss: 0.7093, val_acc: 0.8919
Epoch [77], last_lr: 0.00224, train_loss: 0.0000, val_loss: 0.7105, val_acc: 0.8915
Epoch [78], last_lr: 0.00206, train_loss: 0.0000, val_loss: 0.7112, val_acc: 0.8914
Epoch [79], last_lr: 0.00188, train_loss: 0.0000, val_loss: 0.7100, val_acc: 0.8913
Epoch [80], last_lr: 0.00171, train_loss: 0.0000, val_loss: 0.7077, val_acc: 0.8914
Epoch [81], last_lr: 0.00154, train_loss: 0.0000, val_loss: 0.7114, val_acc: 0.8918
Epoch [82], last_lr: 0.00138, train_loss: 0.0000, val_loss: 0.7123, val_acc: 0.8917
Epoch [83], last_lr: 0.00123, train_loss: 0.0000, val_loss: 0.7103, val_acc: 0.8919
Epoch [84], last_lr: 0.00109, train_loss: 0.0000, val_loss: 0.7100, val_acc: 0.8922
Epoch [85], last_lr: 0.00095, train_loss: 0.0000, val_loss: 0.7125, val_acc: 0.8919
Epoch [86], last_lr: 0.00082, train_loss: 0.0000, val_loss: 0.7114, val_acc: 0.8917
Epoch [87], last_lr: 0.00071, train_loss: 0.0000, val_loss: 0.7119, val_acc: 0.8918
Epoch [88], last_lr: 0.00059, train_loss: 0.0000, val_loss: 0.7136, val_acc: 0.8920
Epoch [89], last_lr: 0.00049, train_loss: 0.0000, val_loss: 0.7119, val_acc: 0.8915
Epoch [90], last_lr: 0.00040, train_loss: 0.0000, val_loss: 0.7098, val_acc: 0.8921
Epoch [91], last_lr: 0.00032, train_loss: 0.0000, val_loss: 0.7104, val_acc: 0.8919
Epoch [92], last_lr: 0.00024, train_loss: 0.0000, val_loss: 0.7111, val_acc: 0.8921
Epoch [93], last_lr: 0.00018, train_loss: 0.0000, val_loss: 0.7125, val_acc: 0.8912
Epoch [94], last_lr: 0.00012, train_loss: 0.0000, val_loss: 0.7118, val_acc: 0.8924
Epoch [95], last_lr: 0.00008, train_loss: 0.0000, val_loss: 0.7114, val_acc: 0.8921
Epoch [96], last_lr: 0.00004, train_loss: 0.0000, val_loss: 0.7104, val_acc: 0.8913
Epoch [97], last_lr: 0.00002, train_loss: 0.0000, val_loss: 0.7125, val_acc: 0.8911
Epoch [98], last_lr: 0.00000, train_loss: 0.0000, val_loss: 0.7121, val_acc: 0.8919
Epoch [99], last_lr: 0.00000, train_loss: 0.0000, val_loss: 0.7099, val_acc: 0.8918
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

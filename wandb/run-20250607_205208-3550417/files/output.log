Epoch [0], last_lr: 0.00053, train_loss: 2.0680, val_loss: 2.1597, val_acc: 0.2628
Epoch [1], last_lr: 0.00060, train_loss: 1.5900, val_loss: 1.5349, val_acc: 0.4214
Epoch [2], last_lr: 0.00073, train_loss: 1.3156, val_loss: 1.2624, val_acc: 0.5367
Epoch [3], last_lr: 0.00091, train_loss: 1.1168, val_loss: 1.1317, val_acc: 0.5976
Epoch [4], last_lr: 0.00114, train_loss: 0.9600, val_loss: 1.0908, val_acc: 0.6161
Epoch [5], last_lr: 0.00141, train_loss: 0.8422, val_loss: 0.9513, val_acc: 0.6767
Epoch [6], last_lr: 0.00172, train_loss: 0.7291, val_loss: 0.7677, val_acc: 0.7313
Epoch [7], last_lr: 0.00207, train_loss: 0.6487, val_loss: 0.9016, val_acc: 0.7103
Epoch [8], last_lr: 0.00246, train_loss: 0.5725, val_loss: 0.9465, val_acc: 0.7122
Epoch [9], last_lr: 0.00288, train_loss: 0.5186, val_loss: 0.7687, val_acc: 0.7453
Epoch [10], last_lr: 0.00332, train_loss: 0.4831, val_loss: 0.9409, val_acc: 0.7394
Epoch [11], last_lr: 0.00379, train_loss: 0.4525, val_loss: 0.4940, val_acc: 0.8383
Epoch [12], last_lr: 0.00427, train_loss: 0.4061, val_loss: 0.9646, val_acc: 0.7406
Epoch [13], last_lr: 0.00476, train_loss: 0.3897, val_loss: 1.0411, val_acc: 0.7220
Epoch [14], last_lr: 0.00526, train_loss: 0.3516, val_loss: 0.7893, val_acc: 0.7653
Epoch [15], last_lr: 0.00575, train_loss: 0.3273, val_loss: 0.5822, val_acc: 0.8219
Epoch [16], last_lr: 0.00624, train_loss: 0.3031, val_loss: 0.4592, val_acc: 0.8501
Epoch [17], last_lr: 0.00672, train_loss: 0.2990, val_loss: 0.5704, val_acc: 0.8300
Epoch [18], last_lr: 0.00719, train_loss: 0.2752, val_loss: 0.6591, val_acc: 0.7934
Epoch [19], last_lr: 0.00763, train_loss: 0.2615, val_loss: 0.6692, val_acc: 0.8022
Epoch [20], last_lr: 0.00805, train_loss: 0.2451, val_loss: 0.5836, val_acc: 0.8222
Epoch [21], last_lr: 0.00843, train_loss: 0.2277, val_loss: 0.5979, val_acc: 0.8248
Epoch [22], last_lr: 0.00879, train_loss: 0.2142, val_loss: 0.4196, val_acc: 0.8670
Epoch [23], last_lr: 0.00910, train_loss: 0.2058, val_loss: 0.4507, val_acc: 0.8643
Epoch [24], last_lr: 0.00937, train_loss: 0.1866, val_loss: 0.5365, val_acc: 0.8465
Epoch [25], last_lr: 0.00959, train_loss: 0.1784, val_loss: 0.4716, val_acc: 0.8628
Epoch [26], last_lr: 0.00977, train_loss: 0.1723, val_loss: 0.3920, val_acc: 0.8802
Epoch [27], last_lr: 0.00990, train_loss: 0.1534, val_loss: 0.5337, val_acc: 0.8562
Epoch [28], last_lr: 0.00997, train_loss: 0.1463, val_loss: 0.4356, val_acc: 0.8778
Epoch [29], last_lr: 0.01000, train_loss: 0.1324, val_loss: 0.4720, val_acc: 0.8781
Epoch [30], last_lr: 0.00999, train_loss: 0.1272, val_loss: 0.3788, val_acc: 0.8949
Epoch [31], last_lr: 0.00998, train_loss: 0.1157, val_loss: 0.5146, val_acc: 0.8719
Epoch [32], last_lr: 0.00995, train_loss: 0.1084, val_loss: 0.4131, val_acc: 0.8878
Epoch [33], last_lr: 0.00992, train_loss: 0.1028, val_loss: 0.4522, val_acc: 0.8784
Epoch [34], last_lr: 0.00987, train_loss: 0.0991, val_loss: 0.4687, val_acc: 0.8878
Epoch [35], last_lr: 0.00982, train_loss: 0.0875, val_loss: 0.3660, val_acc: 0.9041
Epoch [36], last_lr: 0.00975, train_loss: 0.0876, val_loss: 0.4341, val_acc: 0.8937
Epoch [37], last_lr: 0.00968, train_loss: 0.0777, val_loss: 0.4009, val_acc: 0.8947
Epoch [38], last_lr: 0.00960, train_loss: 0.0712, val_loss: 0.4041, val_acc: 0.8987
Epoch [39], last_lr: 0.00950, train_loss: 0.0754, val_loss: 0.3720, val_acc: 0.9043
Epoch [40], last_lr: 0.00940, train_loss: 0.0642, val_loss: 0.4339, val_acc: 0.8970
Epoch [41], last_lr: 0.00929, train_loss: 0.0611, val_loss: 0.4304, val_acc: 0.9009
Epoch [42], last_lr: 0.00917, train_loss: 0.0613, val_loss: 0.4380, val_acc: 0.8914
Epoch [43], last_lr: 0.00904, train_loss: 0.0536, val_loss: 0.3465, val_acc: 0.9125
Epoch [44], last_lr: 0.00891, train_loss: 0.0540, val_loss: 0.3756, val_acc: 0.9128
Epoch [45], last_lr: 0.00876, train_loss: 0.0441, val_loss: 0.4109, val_acc: 0.9061
Epoch [46], last_lr: 0.00861, train_loss: 0.0432, val_loss: 0.3735, val_acc: 0.9156
Epoch [47], last_lr: 0.00845, train_loss: 0.0428, val_loss: 0.3644, val_acc: 0.9172
Epoch [48], last_lr: 0.00829, train_loss: 0.0423, val_loss: 0.4167, val_acc: 0.9045
Epoch [49], last_lr: 0.00811, train_loss: 0.0388, val_loss: 0.4222, val_acc: 0.9097
Epoch [50], last_lr: 0.00794, train_loss: 0.0352, val_loss: 0.3656, val_acc: 0.9198
Epoch [51], last_lr: 0.00775, train_loss: 0.0318, val_loss: 0.4626, val_acc: 0.9065
Epoch [52], last_lr: 0.00756, train_loss: 0.0318, val_loss: 0.4582, val_acc: 0.9095
Epoch [53], last_lr: 0.00737, train_loss: 0.0311, val_loss: 0.4187, val_acc: 0.9124
Epoch [54], last_lr: 0.00717, train_loss: 0.0271, val_loss: 0.3530, val_acc: 0.9198
Epoch [55], last_lr: 0.00696, train_loss: 0.0222, val_loss: 0.3683, val_acc: 0.9239
Epoch [56], last_lr: 0.00675, train_loss: 0.0221, val_loss: 0.4393, val_acc: 0.9155
Epoch [57], last_lr: 0.00654, train_loss: 0.0227, val_loss: 0.4245, val_acc: 0.9146
Epoch [58], last_lr: 0.00633, train_loss: 0.0198, val_loss: 0.3968, val_acc: 0.9208
Epoch [59], last_lr: 0.00611, train_loss: 0.0186, val_loss: 0.4031, val_acc: 0.9196
Epoch [60], last_lr: 0.00589, train_loss: 0.0165, val_loss: 0.3466, val_acc: 0.9278
Epoch [61], last_lr: 0.00567, train_loss: 0.0137, val_loss: 0.3960, val_acc: 0.9228
Epoch [62], last_lr: 0.00544, train_loss: 0.0131, val_loss: 0.4312, val_acc: 0.9246
Epoch [63], last_lr: 0.00522, train_loss: 0.0112, val_loss: 0.4646, val_acc: 0.9195
Epoch [64], last_lr: 0.00500, train_loss: 0.0107, val_loss: 0.4059, val_acc: 0.9249
Epoch [65], last_lr: 0.00477, train_loss: 0.0089, val_loss: 0.3932, val_acc: 0.9282
Epoch [66], last_lr: 0.00455, train_loss: 0.0076, val_loss: 0.4020, val_acc: 0.9307
Epoch [67], last_lr: 0.00432, train_loss: 0.0071, val_loss: 0.4029, val_acc: 0.9317
Epoch [68], last_lr: 0.00410, train_loss: 0.0079, val_loss: 0.4234, val_acc: 0.9264
Epoch [69], last_lr: 0.00388, train_loss: 0.0060, val_loss: 0.3906, val_acc: 0.9320
Epoch [70], last_lr: 0.00367, train_loss: 0.0056, val_loss: 0.3914, val_acc: 0.9326
Epoch [71], last_lr: 0.00345, train_loss: 0.0053, val_loss: 0.4046, val_acc: 0.9328
Epoch [72], last_lr: 0.00324, train_loss: 0.0041, val_loss: 0.4021, val_acc: 0.9345
Epoch [73], last_lr: 0.00303, train_loss: 0.0044, val_loss: 0.4101, val_acc: 0.9332
Epoch [74], last_lr: 0.00283, train_loss: 0.0030, val_loss: 0.4034, val_acc: 0.9353
Epoch [75], last_lr: 0.00263, train_loss: 0.0021, val_loss: 0.3816, val_acc: 0.9383
Epoch [76], last_lr: 0.00243, train_loss: 0.0022, val_loss: 0.3908, val_acc: 0.9345
Epoch [77], last_lr: 0.00224, train_loss: 0.0019, val_loss: 0.3936, val_acc: 0.9365
Epoch [78], last_lr: 0.00206, train_loss: 0.0015, val_loss: 0.3841, val_acc: 0.9381
Epoch [79], last_lr: 0.00188, train_loss: 0.0015, val_loss: 0.3943, val_acc: 0.9375
Epoch [80], last_lr: 0.00171, train_loss: 0.0012, val_loss: 0.4090, val_acc: 0.9371
Epoch [81], last_lr: 0.00154, train_loss: 0.0012, val_loss: 0.4032, val_acc: 0.9360
Epoch [82], last_lr: 0.00138, train_loss: 0.0013, val_loss: 0.3998, val_acc: 0.9375
Epoch [83], last_lr: 0.00123, train_loss: 0.0009, val_loss: 0.3897, val_acc: 0.9391
Epoch [84], last_lr: 0.00109, train_loss: 0.0009, val_loss: 0.3940, val_acc: 0.9398
Epoch [85], last_lr: 0.00095, train_loss: 0.0006, val_loss: 0.3953, val_acc: 0.9387
Epoch [86], last_lr: 0.00082, train_loss: 0.0005, val_loss: 0.3981, val_acc: 0.9398
Epoch [87], last_lr: 0.00071, train_loss: 0.0005, val_loss: 0.4055, val_acc: 0.9402
Epoch [88], last_lr: 0.00059, train_loss: 0.0004, val_loss: 0.4038, val_acc: 0.9400
Epoch [89], last_lr: 0.00049, train_loss: 0.0003, val_loss: 0.4014, val_acc: 0.9397
Epoch [90], last_lr: 0.00040, train_loss: 0.0002, val_loss: 0.4012, val_acc: 0.9395
Epoch [91], last_lr: 0.00032, train_loss: 0.0003, val_loss: 0.4021, val_acc: 0.9392
Epoch [92], last_lr: 0.00024, train_loss: 0.0003, val_loss: 0.4008, val_acc: 0.9397
Epoch [93], last_lr: 0.00018, train_loss: 0.0004, val_loss: 0.4010, val_acc: 0.9389
Epoch [94], last_lr: 0.00012, train_loss: 0.0003, val_loss: 0.4010, val_acc: 0.9394
Epoch [95], last_lr: 0.00008, train_loss: 0.0004, val_loss: 0.3999, val_acc: 0.9399
Epoch [96], last_lr: 0.00004, train_loss: 0.0004, val_loss: 0.4003, val_acc: 0.9392
Epoch [97], last_lr: 0.00002, train_loss: 0.0002, val_loss: 0.4012, val_acc: 0.9391
Epoch [98], last_lr: 0.00000, train_loss: 0.0002, val_loss: 0.4017, val_acc: 0.9394
Epoch [99], last_lr: 0.00000, train_loss: 0.0003, val_loss: 0.4004, val_acc: 0.9392
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

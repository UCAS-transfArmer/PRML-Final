Epoch [0], last_lr: 0.00043, train_loss: 1.8687, val_loss: 1.8151, val_acc: 0.3648
Epoch [1], last_lr: 0.00051, train_loss: 1.4145, val_loss: 1.4087, val_acc: 0.4866
Epoch [2], last_lr: 0.00064, train_loss: 1.1648, val_loss: 1.6543, val_acc: 0.4837
Epoch [3], last_lr: 0.00082, train_loss: 1.0081, val_loss: 1.3560, val_acc: 0.5690
Epoch [4], last_lr: 0.00104, train_loss: 0.9261, val_loss: 1.3977, val_acc: 0.5779
Epoch [5], last_lr: 0.00132, train_loss: 0.8343, val_loss: 1.4013, val_acc: 0.5979
Epoch [6], last_lr: 0.00163, train_loss: 0.7860, val_loss: 1.3378, val_acc: 0.6201
Epoch [7], last_lr: 0.00199, train_loss: 0.7312, val_loss: 2.4204, val_acc: 0.4723
Epoch [8], last_lr: 0.00238, train_loss: 0.6687, val_loss: 1.4423, val_acc: 0.6232
Epoch [9], last_lr: 0.00280, train_loss: 0.6233, val_loss: 1.0524, val_acc: 0.6736
Epoch [10], last_lr: 0.00325, train_loss: 0.5674, val_loss: 1.3481, val_acc: 0.6375
Epoch [11], last_lr: 0.00372, train_loss: 0.5334, val_loss: 1.2401, val_acc: 0.6639
Epoch [12], last_lr: 0.00421, train_loss: 0.5063, val_loss: 1.2892, val_acc: 0.6503
Epoch [13], last_lr: 0.00470, train_loss: 0.4656, val_loss: 0.7285, val_acc: 0.7813
Epoch [14], last_lr: 0.00521, train_loss: 0.4532, val_loss: 1.9538, val_acc: 0.5955
Epoch [15], last_lr: 0.00571, train_loss: 0.4299, val_loss: 0.7876, val_acc: 0.7629
Epoch [16], last_lr: 0.00620, train_loss: 0.4098, val_loss: 0.6906, val_acc: 0.7871
Epoch [17], last_lr: 0.00669, train_loss: 0.3764, val_loss: 0.7843, val_acc: 0.7864
Epoch [18], last_lr: 0.00716, train_loss: 0.3561, val_loss: 0.7533, val_acc: 0.7866
Epoch [19], last_lr: 0.00761, train_loss: 0.3234, val_loss: 0.7027, val_acc: 0.7963
Epoch [20], last_lr: 0.00803, train_loss: 0.2986, val_loss: 0.8152, val_acc: 0.7596
Epoch [21], last_lr: 0.00842, train_loss: 0.2901, val_loss: 1.2211, val_acc: 0.7011
Epoch [22], last_lr: 0.00877, train_loss: 0.2730, val_loss: 0.8279, val_acc: 0.7743
Epoch [23], last_lr: 0.00909, train_loss: 0.2539, val_loss: 0.7537, val_acc: 0.7944
Epoch [24], last_lr: 0.00936, train_loss: 0.2236, val_loss: 0.5748, val_acc: 0.8365
Epoch [25], last_lr: 0.00959, train_loss: 0.2035, val_loss: 0.7864, val_acc: 0.7930
Epoch [26], last_lr: 0.00977, train_loss: 0.2041, val_loss: 0.8869, val_acc: 0.7876
Epoch [27], last_lr: 0.00990, train_loss: 0.1790, val_loss: 0.6273, val_acc: 0.8308
Epoch [28], last_lr: 0.00997, train_loss: 0.1603, val_loss: 0.6937, val_acc: 0.8173
Epoch [29], last_lr: 0.01000, train_loss: 0.1463, val_loss: 0.6522, val_acc: 0.8332
Epoch [30], last_lr: 0.00999, train_loss: 0.1350, val_loss: 0.6729, val_acc: 0.8288
Epoch [31], last_lr: 0.00998, train_loss: 0.1265, val_loss: 0.7581, val_acc: 0.8254
Epoch [32], last_lr: 0.00995, train_loss: 0.1135, val_loss: 0.5603, val_acc: 0.8557
Epoch [33], last_lr: 0.00992, train_loss: 0.1005, val_loss: 0.7028, val_acc: 0.8270
Epoch [34], last_lr: 0.00987, train_loss: 0.0928, val_loss: 0.6515, val_acc: 0.8411
Epoch [35], last_lr: 0.00982, train_loss: 0.1028, val_loss: 0.8105, val_acc: 0.8155
Epoch [36], last_lr: 0.00975, train_loss: 0.0834, val_loss: 0.6157, val_acc: 0.8471
Epoch [37], last_lr: 0.00968, train_loss: 0.0676, val_loss: 0.8258, val_acc: 0.8240
Epoch [38], last_lr: 0.00960, train_loss: 0.0734, val_loss: 0.6738, val_acc: 0.8512
Epoch [39], last_lr: 0.00950, train_loss: 0.0679, val_loss: 0.8939, val_acc: 0.8188
Epoch [40], last_lr: 0.00940, train_loss: 0.0552, val_loss: 0.6222, val_acc: 0.8559
Epoch [41], last_lr: 0.00929, train_loss: 0.0536, val_loss: 0.7355, val_acc: 0.8490
Epoch [42], last_lr: 0.00917, train_loss: 0.0526, val_loss: 0.6270, val_acc: 0.8621
Epoch [43], last_lr: 0.00904, train_loss: 0.0539, val_loss: 0.6575, val_acc: 0.8569
Epoch [44], last_lr: 0.00891, train_loss: 0.0395, val_loss: 0.6000, val_acc: 0.8695
Epoch [45], last_lr: 0.00876, train_loss: 0.0401, val_loss: 0.6903, val_acc: 0.8526
Epoch [46], last_lr: 0.00861, train_loss: 0.0433, val_loss: 0.6691, val_acc: 0.8619
Epoch [47], last_lr: 0.00845, train_loss: 0.0306, val_loss: 0.7389, val_acc: 0.8580
Epoch [48], last_lr: 0.00829, train_loss: 0.0225, val_loss: 0.8082, val_acc: 0.8491
Epoch [49], last_lr: 0.00811, train_loss: 0.0292, val_loss: 0.7486, val_acc: 0.8580
Epoch [50], last_lr: 0.00794, train_loss: 0.0308, val_loss: 0.8377, val_acc: 0.8428
Epoch [51], last_lr: 0.00775, train_loss: 0.0328, val_loss: 0.7740, val_acc: 0.8505
Epoch [52], last_lr: 0.00756, train_loss: 0.0299, val_loss: 0.6597, val_acc: 0.8606
Epoch [53], last_lr: 0.00737, train_loss: 0.0233, val_loss: 0.6571, val_acc: 0.8713
Epoch [54], last_lr: 0.00717, train_loss: 0.0128, val_loss: 0.6389, val_acc: 0.8810
Epoch [55], last_lr: 0.00696, train_loss: 0.0111, val_loss: 0.6994, val_acc: 0.8723
Epoch [56], last_lr: 0.00675, train_loss: 0.0140, val_loss: 0.7109, val_acc: 0.8694
Epoch [57], last_lr: 0.00654, train_loss: 0.0218, val_loss: 0.7573, val_acc: 0.8625
Epoch [58], last_lr: 0.00633, train_loss: 0.0183, val_loss: 0.6920, val_acc: 0.8739
Epoch [59], last_lr: 0.00611, train_loss: 0.0121, val_loss: 0.6865, val_acc: 0.8711
Epoch [60], last_lr: 0.00589, train_loss: 0.0103, val_loss: 0.6683, val_acc: 0.8800
Epoch [61], last_lr: 0.00567, train_loss: 0.0074, val_loss: 0.7525, val_acc: 0.8713
Epoch [62], last_lr: 0.00544, train_loss: 0.0049, val_loss: 0.6876, val_acc: 0.8807
Epoch [63], last_lr: 0.00522, train_loss: 0.0049, val_loss: 0.7195, val_acc: 0.8816
Epoch [64], last_lr: 0.00500, train_loss: 0.0046, val_loss: 0.7571, val_acc: 0.8779
Epoch [65], last_lr: 0.00477, train_loss: 0.0034, val_loss: 0.7391, val_acc: 0.8807
Epoch [66], last_lr: 0.00455, train_loss: 0.0028, val_loss: 0.7236, val_acc: 0.8845
Epoch [67], last_lr: 0.00432, train_loss: 0.0017, val_loss: 0.7152, val_acc: 0.8901
Epoch [68], last_lr: 0.00410, train_loss: 0.0012, val_loss: 0.7080, val_acc: 0.8870
Epoch [69], last_lr: 0.00388, train_loss: 0.0006, val_loss: 0.6920, val_acc: 0.8916
Epoch [70], last_lr: 0.00367, train_loss: 0.0004, val_loss: 0.6789, val_acc: 0.8928
Epoch [71], last_lr: 0.00345, train_loss: 0.0001, val_loss: 0.6774, val_acc: 0.8946
Epoch [72], last_lr: 0.00324, train_loss: 0.0001, val_loss: 0.6819, val_acc: 0.8943
Epoch [73], last_lr: 0.00303, train_loss: 0.0001, val_loss: 0.6897, val_acc: 0.8929
Epoch [74], last_lr: 0.00283, train_loss: 0.0003, val_loss: 0.6872, val_acc: 0.8919
Epoch [75], last_lr: 0.00263, train_loss: 0.0001, val_loss: 0.6824, val_acc: 0.8935
Epoch [76], last_lr: 0.00243, train_loss: 0.0001, val_loss: 0.6859, val_acc: 0.8931
Epoch [77], last_lr: 0.00224, train_loss: 0.0000, val_loss: 0.6827, val_acc: 0.8944
Epoch [78], last_lr: 0.00206, train_loss: 0.0000, val_loss: 0.6843, val_acc: 0.8944
Epoch [79], last_lr: 0.00188, train_loss: 0.0000, val_loss: 0.6844, val_acc: 0.8947
Epoch [80], last_lr: 0.00171, train_loss: 0.0000, val_loss: 0.6867, val_acc: 0.8952
Epoch [81], last_lr: 0.00154, train_loss: 0.0000, val_loss: 0.6895, val_acc: 0.8950
Epoch [82], last_lr: 0.00138, train_loss: 0.0000, val_loss: 0.6868, val_acc: 0.8952
Epoch [83], last_lr: 0.00123, train_loss: 0.0000, val_loss: 0.6896, val_acc: 0.8956
Epoch [84], last_lr: 0.00109, train_loss: 0.0000, val_loss: 0.6857, val_acc: 0.8958
Epoch [85], last_lr: 0.00095, train_loss: 0.0000, val_loss: 0.6892, val_acc: 0.8951
Epoch [86], last_lr: 0.00082, train_loss: 0.0000, val_loss: 0.6875, val_acc: 0.8951
Epoch [87], last_lr: 0.00071, train_loss: 0.0000, val_loss: 0.6909, val_acc: 0.8959
Epoch [88], last_lr: 0.00059, train_loss: 0.0000, val_loss: 0.6896, val_acc: 0.8966
Epoch [89], last_lr: 0.00049, train_loss: 0.0000, val_loss: 0.6896, val_acc: 0.8955
Epoch [90], last_lr: 0.00040, train_loss: 0.0000, val_loss: 0.6859, val_acc: 0.8960
Epoch [91], last_lr: 0.00032, train_loss: 0.0000, val_loss: 0.6894, val_acc: 0.8964
Epoch [92], last_lr: 0.00024, train_loss: 0.0000, val_loss: 0.6920, val_acc: 0.8954
Epoch [93], last_lr: 0.00018, train_loss: 0.0000, val_loss: 0.6910, val_acc: 0.8964
Epoch [94], last_lr: 0.00012, train_loss: 0.0000, val_loss: 0.6890, val_acc: 0.8964
Epoch [95], last_lr: 0.00008, train_loss: 0.0000, val_loss: 0.6880, val_acc: 0.8960
Epoch [96], last_lr: 0.00004, train_loss: 0.0000, val_loss: 0.6883, val_acc: 0.8962
Epoch [97], last_lr: 0.00002, train_loss: 0.0000, val_loss: 0.6887, val_acc: 0.8961
Epoch [98], last_lr: 0.00000, train_loss: 0.0000, val_loss: 0.6896, val_acc: 0.8959
Epoch [99], last_lr: 0.00000, train_loss: 0.0000, val_loss: 0.6883, val_acc: 0.8963
Saved final model to ./saves/cnn_cifar10_final_ep100_step4900.pth

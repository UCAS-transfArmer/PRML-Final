Epoch [0], last_lr: 0.00631, train_loss: 2.5442, val_loss: 2.2768, val_acc: 0.1619
Epoch [1], last_lr: 0.00725, train_loss: 2.0448, val_loss: 2.0622, val_acc: 0.2340
Epoch [2], last_lr: 0.00879, train_loss: 1.8098, val_loss: 1.7012, val_acc: 0.3569
Epoch [3], last_lr: 0.01093, train_loss: 1.6003, val_loss: 1.6025, val_acc: 0.4027
Epoch [4], last_lr: 0.01365, train_loss: 1.4465, val_loss: 1.3968, val_acc: 0.4933
Epoch [5], last_lr: 0.01690, train_loss: 1.2722, val_loss: 1.2222, val_acc: 0.5559
Epoch [6], last_lr: 0.02066, train_loss: 1.1239, val_loss: 1.1303, val_acc: 0.5954
Epoch [7], last_lr: 0.02488, train_loss: 0.9813, val_loss: 1.0179, val_acc: 0.6428
Epoch [8], last_lr: 0.02953, train_loss: 0.8885, val_loss: 0.9912, val_acc: 0.6641
Epoch [9], last_lr: 0.03454, train_loss: 0.7878, val_loss: 0.8953, val_acc: 0.7004
Epoch [10], last_lr: 0.03986, train_loss: 0.7067, val_loss: 0.9213, val_acc: 0.6920
Epoch [11], last_lr: 0.04543, train_loss: 0.6415, val_loss: 0.7854, val_acc: 0.7507
Epoch [12], last_lr: 0.05120, train_loss: 0.5714, val_loss: 0.7072, val_acc: 0.7659
Epoch [13], last_lr: 0.05710, train_loss: 0.5109, val_loss: 0.6065, val_acc: 0.7931
Epoch [14], last_lr: 0.06306, train_loss: 0.4561, val_loss: 0.9026, val_acc: 0.7313
Epoch [15], last_lr: 0.06902, train_loss: 0.4321, val_loss: 0.6955, val_acc: 0.7843
Epoch [16], last_lr: 0.07492, train_loss: 0.4022, val_loss: 0.7485, val_acc: 0.7736
Epoch [17], last_lr: 0.08068, train_loss: 0.3702, val_loss: 0.5463, val_acc: 0.8187
Epoch [18], last_lr: 0.08625, train_loss: 0.3524, val_loss: 0.8966, val_acc: 0.7597
Epoch [19], last_lr: 0.09157, train_loss: 0.3381, val_loss: 0.5654, val_acc: 0.8209
Epoch [20], last_lr: 0.09657, train_loss: 0.3087, val_loss: 0.4799, val_acc: 0.8468
Epoch [21], last_lr: 0.10121, train_loss: 0.2899, val_loss: 0.4929, val_acc: 0.8444
Epoch [22], last_lr: 0.10542, train_loss: 0.2729, val_loss: 0.4251, val_acc: 0.8723
Epoch [23], last_lr: 0.10917, train_loss: 0.2640, val_loss: 0.4546, val_acc: 0.8548
Epoch [24], last_lr: 0.11241, train_loss: 0.2549, val_loss: 0.4613, val_acc: 0.8516
Epoch [25], last_lr: 0.11511, train_loss: 0.2360, val_loss: 0.5577, val_acc: 0.8386
Epoch [26], last_lr: 0.11724, train_loss: 0.2295, val_loss: 0.5048, val_acc: 0.8460
Epoch [27], last_lr: 0.11878, train_loss: 0.2305, val_loss: 0.4960, val_acc: 0.8549
Epoch [28], last_lr: 0.11970, train_loss: 0.2020, val_loss: 0.4991, val_acc: 0.8547
Epoch [29], last_lr: 0.12000, train_loss: 0.1906, val_loss: 0.3679, val_acc: 0.8877
Epoch [30], last_lr: 0.11994, train_loss: 0.1859, val_loss: 0.4645, val_acc: 0.8736
Epoch [31], last_lr: 0.11975, train_loss: 0.1726, val_loss: 0.4249, val_acc: 0.8739
Epoch [32], last_lr: 0.11945, train_loss: 0.1657, val_loss: 0.4943, val_acc: 0.8733
Epoch [33], last_lr: 0.11903, train_loss: 0.1518, val_loss: 0.3977, val_acc: 0.8903
Epoch [34], last_lr: 0.11848, train_loss: 0.1586, val_loss: 0.4736, val_acc: 0.8741
Epoch [35], last_lr: 0.11782, train_loss: 0.1476, val_loss: 0.4344, val_acc: 0.8838
Epoch [36], last_lr: 0.11705, train_loss: 0.1267, val_loss: 0.6543, val_acc: 0.8537
Epoch [37], last_lr: 0.11615, train_loss: 0.1269, val_loss: 0.4585, val_acc: 0.8767
Epoch [38], last_lr: 0.11515, train_loss: 0.1260, val_loss: 0.3923, val_acc: 0.8937
Epoch [39], last_lr: 0.11403, train_loss: 0.1201, val_loss: 0.4330, val_acc: 0.8815
Epoch [40], last_lr: 0.11281, train_loss: 0.1123, val_loss: 0.3917, val_acc: 0.9006
Epoch [41], last_lr: 0.11148, train_loss: 0.1013, val_loss: 0.4261, val_acc: 0.8941
Epoch [42], last_lr: 0.11004, train_loss: 0.1068, val_loss: 0.4408, val_acc: 0.8936
Epoch [43], last_lr: 0.10851, train_loss: 0.0967, val_loss: 0.4828, val_acc: 0.8882
Epoch [44], last_lr: 0.10688, train_loss: 0.0858, val_loss: 0.4293, val_acc: 0.8964
Epoch [45], last_lr: 0.10515, train_loss: 0.0834, val_loss: 0.5936, val_acc: 0.8650
Epoch [46], last_lr: 0.10333, train_loss: 0.0848, val_loss: 0.4423, val_acc: 0.9005
Epoch [47], last_lr: 0.10142, train_loss: 0.0827, val_loss: 0.4318, val_acc: 0.8954
Epoch [48], last_lr: 0.09944, train_loss: 0.0702, val_loss: 0.4098, val_acc: 0.9068
Epoch [49], last_lr: 0.09737, train_loss: 0.0826, val_loss: 0.4186, val_acc: 0.9027
Epoch [50], last_lr: 0.09522, train_loss: 0.0655, val_loss: 0.4536, val_acc: 0.8925
Epoch [51], last_lr: 0.09301, train_loss: 0.0584, val_loss: 0.5775, val_acc: 0.8918
Epoch [52], last_lr: 0.09073, train_loss: 0.0588, val_loss: 0.4876, val_acc: 0.8950
Epoch [53], last_lr: 0.08838, train_loss: 0.0644, val_loss: 0.4548, val_acc: 0.8987
Epoch [54], last_lr: 0.08598, train_loss: 0.0548, val_loss: 0.4586, val_acc: 0.9012
Epoch [55], last_lr: 0.08353, train_loss: 0.0519, val_loss: 0.4362, val_acc: 0.9090
Epoch [56], last_lr: 0.08103, train_loss: 0.0434, val_loss: 0.4535, val_acc: 0.9047
Epoch [57], last_lr: 0.07849, train_loss: 0.0404, val_loss: 0.4406, val_acc: 0.9099
Epoch [58], last_lr: 0.07591, train_loss: 0.0396, val_loss: 0.4472, val_acc: 0.9117
Epoch [59], last_lr: 0.07330, train_loss: 0.0417, val_loss: 0.4294, val_acc: 0.9132
Epoch [60], last_lr: 0.07066, train_loss: 0.0388, val_loss: 0.4909, val_acc: 0.9114
Epoch [61], last_lr: 0.06800, train_loss: 0.0297, val_loss: 0.4324, val_acc: 0.9174
Epoch [62], last_lr: 0.06532, train_loss: 0.0302, val_loss: 0.4315, val_acc: 0.9216
Epoch [63], last_lr: 0.06264, train_loss: 0.0311, val_loss: 0.4309, val_acc: 0.9210
Epoch [64], last_lr: 0.05995, train_loss: 0.0259, val_loss: 0.3998, val_acc: 0.9241
Epoch [65], last_lr: 0.05725, train_loss: 0.0208, val_loss: 0.4073, val_acc: 0.9203
Epoch [66], last_lr: 0.05457, train_loss: 0.0208, val_loss: 0.4452, val_acc: 0.9197
Epoch [67], last_lr: 0.05189, train_loss: 0.0192, val_loss: 0.5006, val_acc: 0.9136
Epoch [68], last_lr: 0.04923, train_loss: 0.0159, val_loss: 0.3855, val_acc: 0.9267
Epoch [69], last_lr: 0.04660, train_loss: 0.0132, val_loss: 0.3778, val_acc: 0.9358
Epoch [70], last_lr: 0.04399, train_loss: 0.0120, val_loss: 0.3684, val_acc: 0.9340
Epoch [71], last_lr: 0.04141, train_loss: 0.0098, val_loss: 0.3790, val_acc: 0.9275
Epoch [72], last_lr: 0.03887, train_loss: 0.0104, val_loss: 0.4076, val_acc: 0.9312
Epoch [73], last_lr: 0.03637, train_loss: 0.0095, val_loss: 0.3938, val_acc: 0.9302
Epoch [74], last_lr: 0.03392, train_loss: 0.0069, val_loss: 0.3915, val_acc: 0.9327
Epoch [75], last_lr: 0.03152, train_loss: 0.0060, val_loss: 0.4167, val_acc: 0.9340
Epoch [76], last_lr: 0.02918, train_loss: 0.0062, val_loss: 0.3918, val_acc: 0.9337
Epoch [77], last_lr: 0.02690, train_loss: 0.0044, val_loss: 0.4069, val_acc: 0.9341
Epoch [78], last_lr: 0.02469, train_loss: 0.0037, val_loss: 0.3688, val_acc: 0.9360
Epoch [79], last_lr: 0.02255, train_loss: 0.0027, val_loss: 0.3742, val_acc: 0.9364
Epoch [80], last_lr: 0.02048, train_loss: 0.0021, val_loss: 0.3744, val_acc: 0.9394
Epoch [81], last_lr: 0.01850, train_loss: 0.0016, val_loss: 0.3763, val_acc: 0.9400
Epoch [82], last_lr: 0.01659, train_loss: 0.0016, val_loss: 0.3882, val_acc: 0.9390
Epoch [83], last_lr: 0.01478, train_loss: 0.0014, val_loss: 0.3870, val_acc: 0.9396
Epoch [84], last_lr: 0.01306, train_loss: 0.0010, val_loss: 0.3882, val_acc: 0.9388
Epoch [85], last_lr: 0.01143, train_loss: 0.0010, val_loss: 0.3797, val_acc: 0.9392
Epoch [86], last_lr: 0.00990, train_loss: 0.0009, val_loss: 0.3827, val_acc: 0.9409
Epoch [87], last_lr: 0.00847, train_loss: 0.0010, val_loss: 0.3841, val_acc: 0.9389
Epoch [88], last_lr: 0.00714, train_loss: 0.0008, val_loss: 0.3829, val_acc: 0.9400
Epoch [89], last_lr: 0.00592, train_loss: 0.0007, val_loss: 0.3851, val_acc: 0.9404
Epoch [90], last_lr: 0.00481, train_loss: 0.0008, val_loss: 0.3861, val_acc: 0.9406
Epoch [91], last_lr: 0.00381, train_loss: 0.0007, val_loss: 0.3846, val_acc: 0.9402
Epoch [92], last_lr: 0.00292, train_loss: 0.0006, val_loss: 0.3814, val_acc: 0.9400
Epoch [93], last_lr: 0.00215, train_loss: 0.0007, val_loss: 0.3817, val_acc: 0.9402
Epoch [94], last_lr: 0.00149, train_loss: 0.0004, val_loss: 0.3813, val_acc: 0.9400
Epoch [95], last_lr: 0.00096, train_loss: 0.0006, val_loss: 0.3812, val_acc: 0.9407
Epoch [96], last_lr: 0.00054, train_loss: 0.0006, val_loss: 0.3782, val_acc: 0.9408
Epoch [97], last_lr: 0.00024, train_loss: 0.0004, val_loss: 0.3800, val_acc: 0.9406
Epoch [98], last_lr: 0.00006, train_loss: 0.0005, val_loss: 0.3804, val_acc: 0.9407
Epoch [99], last_lr: 0.00000, train_loss: 0.0005, val_loss: 0.3788, val_acc: 0.9409
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth

Epoch [0], last_lr: 0.00043, train_loss: 1.5712, val_loss: 1.4806, val_acc: 0.4757
Epoch [1], last_lr: 0.00051, train_loss: 1.0538, val_loss: 1.0406, val_acc: 0.6194
Epoch [2], last_lr: 0.00064, train_loss: 0.8064, val_loss: 0.8727, val_acc: 0.6939
Epoch [3], last_lr: 0.00082, train_loss: 0.6356, val_loss: 0.9047, val_acc: 0.6966
Epoch [4], last_lr: 0.00104, train_loss: 0.5116, val_loss: 0.8701, val_acc: 0.7120
Epoch [5], last_lr: 0.00132, train_loss: 0.4174, val_loss: 1.7869, val_acc: 0.5803
Epoch [6], last_lr: 0.00163, train_loss: 0.3422, val_loss: 1.3601, val_acc: 0.6656
Epoch [7], last_lr: 0.00199, train_loss: 0.2864, val_loss: 0.8766, val_acc: 0.7555
Epoch [8], last_lr: 0.00238, train_loss: 0.2486, val_loss: 0.8730, val_acc: 0.7452
Epoch [9], last_lr: 0.00280, train_loss: 0.2237, val_loss: 0.9268, val_acc: 0.7563
Epoch [10], last_lr: 0.00325, train_loss: 0.1920, val_loss: 1.2549, val_acc: 0.6999
Epoch [11], last_lr: 0.00372, train_loss: 0.1558, val_loss: 0.8672, val_acc: 0.7778
Epoch [12], last_lr: 0.00421, train_loss: 0.1498, val_loss: 1.0395, val_acc: 0.7542
Epoch [13], last_lr: 0.00470, train_loss: 0.1224, val_loss: 1.1160, val_acc: 0.7483
Epoch [14], last_lr: 0.00521, train_loss: 0.1136, val_loss: 0.9130, val_acc: 0.7788
Epoch [15], last_lr: 0.00571, train_loss: 0.1104, val_loss: 1.8105, val_acc: 0.6668
Epoch [16], last_lr: 0.00620, train_loss: 0.1064, val_loss: 1.3309, val_acc: 0.7302
Epoch [17], last_lr: 0.00669, train_loss: 0.0769, val_loss: 1.3457, val_acc: 0.7473
Epoch [18], last_lr: 0.00716, train_loss: 0.0741, val_loss: 1.0069, val_acc: 0.7720
Epoch [19], last_lr: 0.00761, train_loss: 0.0759, val_loss: 1.0363, val_acc: 0.7767
Epoch [20], last_lr: 0.00803, train_loss: 0.0584, val_loss: 0.9660, val_acc: 0.7979
Epoch [21], last_lr: 0.00842, train_loss: 0.0679, val_loss: 1.0863, val_acc: 0.7717
Epoch [22], last_lr: 0.00877, train_loss: 0.0618, val_loss: 0.9740, val_acc: 0.8015
Epoch [23], last_lr: 0.00909, train_loss: 0.0536, val_loss: 0.7638, val_acc: 0.8223
Epoch [24], last_lr: 0.00936, train_loss: 0.0430, val_loss: 0.8812, val_acc: 0.8133
Epoch [25], last_lr: 0.00959, train_loss: 0.0393, val_loss: 1.0478, val_acc: 0.7948
Epoch [26], last_lr: 0.00977, train_loss: 0.0432, val_loss: 0.8209, val_acc: 0.8283
Epoch [27], last_lr: 0.00990, train_loss: 0.0392, val_loss: 0.8156, val_acc: 0.8294
Epoch [28], last_lr: 0.00997, train_loss: 0.0318, val_loss: 0.9030, val_acc: 0.8242
Epoch [29], last_lr: 0.01000, train_loss: 0.0287, val_loss: 0.9011, val_acc: 0.8259
Epoch [30], last_lr: 0.00999, train_loss: 0.0236, val_loss: 0.9897, val_acc: 0.8137
Epoch [31], last_lr: 0.00998, train_loss: 0.0262, val_loss: 0.8524, val_acc: 0.8389
Epoch [32], last_lr: 0.00995, train_loss: 0.0192, val_loss: 0.7633, val_acc: 0.8497
Epoch [33], last_lr: 0.00992, train_loss: 0.0175, val_loss: 0.8463, val_acc: 0.8433
Epoch [34], last_lr: 0.00987, train_loss: 0.0281, val_loss: 0.9529, val_acc: 0.8147
Epoch [35], last_lr: 0.00982, train_loss: 0.0246, val_loss: 0.7389, val_acc: 0.8466
Epoch [36], last_lr: 0.00975, train_loss: 0.0174, val_loss: 0.8369, val_acc: 0.8440
Epoch [37], last_lr: 0.00968, train_loss: 0.0121, val_loss: 0.8547, val_acc: 0.8423
Epoch [38], last_lr: 0.00960, train_loss: 0.0071, val_loss: 0.7800, val_acc: 0.8549
Epoch [39], last_lr: 0.00950, train_loss: 0.0026, val_loss: 0.7202, val_acc: 0.8666
Epoch [40], last_lr: 0.00940, train_loss: 0.0010, val_loss: 0.7062, val_acc: 0.8749
Epoch [41], last_lr: 0.00929, train_loss: 0.0004, val_loss: 0.6727, val_acc: 0.8794
Epoch [42], last_lr: 0.00917, train_loss: 0.0001, val_loss: 0.6742, val_acc: 0.8786
Epoch [43], last_lr: 0.00904, train_loss: 0.0001, val_loss: 0.6751, val_acc: 0.8799
Epoch [44], last_lr: 0.00891, train_loss: 0.0000, val_loss: 0.6771, val_acc: 0.8799
Epoch [45], last_lr: 0.00876, train_loss: 0.0000, val_loss: 0.6807, val_acc: 0.8793
Epoch [46], last_lr: 0.00861, train_loss: 0.0000, val_loss: 0.6800, val_acc: 0.8808
Epoch [47], last_lr: 0.00845, train_loss: 0.0000, val_loss: 0.6823, val_acc: 0.8803
Epoch [48], last_lr: 0.00829, train_loss: 0.0000, val_loss: 0.6825, val_acc: 0.8809
Epoch [49], last_lr: 0.00811, train_loss: 0.0000, val_loss: 0.6831, val_acc: 0.8799
Epoch [50], last_lr: 0.00794, train_loss: 0.0000, val_loss: 0.6846, val_acc: 0.8811
Epoch [51], last_lr: 0.00775, train_loss: 0.0000, val_loss: 0.6871, val_acc: 0.8808
Epoch [52], last_lr: 0.00756, train_loss: 0.0000, val_loss: 0.6875, val_acc: 0.8808
Epoch [53], last_lr: 0.00737, train_loss: 0.0000, val_loss: 0.6884, val_acc: 0.8808
Epoch [54], last_lr: 0.00717, train_loss: 0.0000, val_loss: 0.6891, val_acc: 0.8803
Epoch [55], last_lr: 0.00696, train_loss: 0.0000, val_loss: 0.6889, val_acc: 0.8813
Epoch [56], last_lr: 0.00675, train_loss: 0.0000, val_loss: 0.6913, val_acc: 0.8809
Epoch [57], last_lr: 0.00654, train_loss: 0.0000, val_loss: 0.6920, val_acc: 0.8823
Epoch [58], last_lr: 0.00633, train_loss: 0.0000, val_loss: 0.6918, val_acc: 0.8813
Epoch [59], last_lr: 0.00611, train_loss: 0.0000, val_loss: 0.6942, val_acc: 0.8809
Epoch [60], last_lr: 0.00589, train_loss: 0.0000, val_loss: 0.6940, val_acc: 0.8816
Epoch [61], last_lr: 0.00567, train_loss: 0.0000, val_loss: 0.6949, val_acc: 0.8816
Epoch [62], last_lr: 0.00544, train_loss: 0.0000, val_loss: 0.6953, val_acc: 0.8821
Epoch [63], last_lr: 0.00522, train_loss: 0.0000, val_loss: 0.6977, val_acc: 0.8817
Epoch [64], last_lr: 0.00500, train_loss: 0.0000, val_loss: 0.6969, val_acc: 0.8814
Epoch [65], last_lr: 0.00477, train_loss: 0.0000, val_loss: 0.7001, val_acc: 0.8816
Epoch [66], last_lr: 0.00455, train_loss: 0.0000, val_loss: 0.6961, val_acc: 0.8819
Epoch [67], last_lr: 0.00432, train_loss: 0.0000, val_loss: 0.6967, val_acc: 0.8817
Epoch [68], last_lr: 0.00410, train_loss: 0.0000, val_loss: 0.6986, val_acc: 0.8811
Epoch [69], last_lr: 0.00388, train_loss: 0.0000, val_loss: 0.6981, val_acc: 0.8822
Epoch [70], last_lr: 0.00367, train_loss: 0.0000, val_loss: 0.6988, val_acc: 0.8818
Epoch [71], last_lr: 0.00345, train_loss: 0.0000, val_loss: 0.6997, val_acc: 0.8822
Epoch [72], last_lr: 0.00324, train_loss: 0.0000, val_loss: 0.7034, val_acc: 0.8816
Epoch [73], last_lr: 0.00303, train_loss: 0.0000, val_loss: 0.7005, val_acc: 0.8815
Epoch [74], last_lr: 0.00283, train_loss: 0.0000, val_loss: 0.7006, val_acc: 0.8821
Epoch [75], last_lr: 0.00263, train_loss: 0.0000, val_loss: 0.7027, val_acc: 0.8819
Epoch [76], last_lr: 0.00243, train_loss: 0.0000, val_loss: 0.7032, val_acc: 0.8822
Epoch [77], last_lr: 0.00224, train_loss: 0.0000, val_loss: 0.7031, val_acc: 0.8821
Epoch [78], last_lr: 0.00206, train_loss: 0.0000, val_loss: 0.7029, val_acc: 0.8811
Epoch [79], last_lr: 0.00188, train_loss: 0.0000, val_loss: 0.7027, val_acc: 0.8819
Epoch [80], last_lr: 0.00171, train_loss: 0.0000, val_loss: 0.7033, val_acc: 0.8822
Epoch [81], last_lr: 0.00154, train_loss: 0.0000, val_loss: 0.7044, val_acc: 0.8817
Epoch [82], last_lr: 0.00138, train_loss: 0.0000, val_loss: 0.7041, val_acc: 0.8822
Epoch [83], last_lr: 0.00123, train_loss: 0.0000, val_loss: 0.7041, val_acc: 0.8820
Epoch [84], last_lr: 0.00109, train_loss: 0.0000, val_loss: 0.7038, val_acc: 0.8817
Epoch [85], last_lr: 0.00095, train_loss: 0.0000, val_loss: 0.7050, val_acc: 0.8821
Epoch [86], last_lr: 0.00082, train_loss: 0.0000, val_loss: 0.7039, val_acc: 0.8814
Epoch [87], last_lr: 0.00071, train_loss: 0.0000, val_loss: 0.7045, val_acc: 0.8826
Epoch [88], last_lr: 0.00059, train_loss: 0.0000, val_loss: 0.7031, val_acc: 0.8816
Epoch [89], last_lr: 0.00049, train_loss: 0.0000, val_loss: 0.7050, val_acc: 0.8816
Epoch [90], last_lr: 0.00040, train_loss: 0.0000, val_loss: 0.7052, val_acc: 0.8823
Epoch [91], last_lr: 0.00032, train_loss: 0.0000, val_loss: 0.7048, val_acc: 0.8819
Epoch [92], last_lr: 0.00024, train_loss: 0.0000, val_loss: 0.7045, val_acc: 0.8816
Epoch [93], last_lr: 0.00018, train_loss: 0.0000, val_loss: 0.7031, val_acc: 0.8823
Epoch [94], last_lr: 0.00012, train_loss: 0.0000, val_loss: 0.7063, val_acc: 0.8823
Epoch [95], last_lr: 0.00008, train_loss: 0.0000, val_loss: 0.7055, val_acc: 0.8826
Epoch [96], last_lr: 0.00004, train_loss: 0.0000, val_loss: 0.7051, val_acc: 0.8817
Epoch [97], last_lr: 0.00002, train_loss: 0.0000, val_loss: 0.7054, val_acc: 0.8818
Epoch [98], last_lr: 0.00000, train_loss: 0.0000, val_loss: 0.7059, val_acc: 0.8822
Epoch [99], last_lr: 0.00000, train_loss: 0.0000, val_loss: 0.7066, val_acc: 0.8822
Saved final model to ./saves/resnet_cifar10_final_ep100_step4900.pth
